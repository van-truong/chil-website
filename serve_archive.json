{"2020":{"highlights":"ACM CHIL 2020 was held virtually on July 23rd and 24th. It featured 23 research talks from accepted papers, 23 workshop spotlights, and 15 participants in the doctoral symposium.\n\n### Keynotes\n\n- Yoshua Bengio - <a href=\"https://slideslive.com/38931907/machine-learning-challenges-in-the-fight-for-social-good-the-covid19-case\" target=\"_blank\" rel=\"noopener\">_Machine Learning Challenges in the Fight for Social Good - the Covid-19 Case_</a>\n- Elaine Nsoesie - <a href=\"https://slideslive.com/38931908/digital-platforms-public-health-in-africa\" target=\"_blank\" rel=\"noopener\">_Digital Platforms & Public Health in Africa_</a>\n- Sherri Rose - <a href=\"https://slideslive.com/38931910/machine-learning-in-health-care-too-important-to-be-a-toy-example\" target=\"_blank\" rel=\"noopener\">_Machine Learning in Health Care: Too Important to Be a Toy Example_</a>\n- Ruslan Salakhutdinov - <a href=\"https://slideslive.com/38931911/incorporating-domain-knowledge-into-deep-learning-models\" target=\"_blank\" rel=\"noopener\">_Incorporating Domain Knowledge into Deep Learning Models_</a>\n- Nigam Shah - <a href=\"https://slideslive.com/38931909/a-framework-for-shaping-the-future-of-ai-in-healthcare \" target=\"_blank\" rel=\"noopener\">_A framework for shaping the future of AI in healthcare_</a>\n\n### Tutorials\n\n- A Tour of Survival Analysis, from Classical to Modern - George H. Chen, Jeremy C. Weiss\n- Population and public health: challenges and opportunities - Vishwali Mhasawade, Yuan Zhao, Rumi Chunara\n- Public Health Datasets for Deep Learning: Challenges and Opportunities - Ziad Obermeyer, Katy Haynes, Amy Pitelka, Josh Risley, Katie Lin\n- State of the Art Deep Learning in Medical Imaging - Joseph Paul Cohen\n- Analyzing critical care data, from speculation to publication, starring MIMIC-IV (part 1) - Alistair Johnson\n\n\n### Papers\n\nProceedings from the 2020 ACM CHIL Conference are available at the ACM Digital Library: <a href=\"https://dl.acm.org/doi/proceedings/10.1145/3368555\" target=\"_blank\" rel=\"noopener\">https://dl.acm.org/doi/proceedings/10.1145/3368555</a>\n\n### Governing Board\n\n###### **General Chair**\n- Dr. Marzyeh Ghassemi of the University of Toronto and the Vector Institute\n###### **Logistics Chair**\n- Tasmie Sarker of the University of Toronto and the Vector Institute\n###### **Program Chair**\n- Dr. Tristan Naumann of Microsoft Research Seattle\n- Dr. Danielle Belgrave of Microsoft Research Cambridge, UK\n- Dr. Adrian Dalca of MIT and Harvard Medical School\n###### **Proceedings Chair**\n- Dr. Brett Beaulieu-Jones of Harvard Medical School\n- Sam Finlayson of Harvard University and MIT\n- Emily Alsentzer of Harvard University and MIT\n###### **Communications Chair**\n- Dr. Stephanie Hyland of Microsoft Research Cambridge, UK\n- Dr. Shalmali Joshi of the Vector Institute\n- Bret Nestor of the University of Toronto and the Vector Institute\n###### **Finance Chair**\n- Dr. Joyce Ho of Emory University\n- Dr. Laura Rosella of the University of Toronto\n###### **Tutorial Chair**\n- Ahmed Nasir of Trillium Health Partners\n- Dr. Andrew Beam of Harvard University\n- Irene Chen of MIT\n###### **Consortium Chair**\n- Dr. Leo Celi of MIT\n- Matthew McDermott of MIT\n###### **Virtual Chair**\n- Dr. Tom Pollard of MIT\n- Dr. Alistair Johnson of MIT\n\n### Executive Committee\n- Dr. Marzyeh Ghassemi of University of Toronto, Vector Institute\n- Dr. Tristan Naumann of Microsoft Research Seattle\n- Dr. Joyce Ho of Emory University\n- Dr. Leo Celi of MIT\n- Dr. Shalmali Joshi of the Vector Institute\n- Dr. Andrew Beam of Harvard University\n- Dr. Ziad Obermeyer of University of California, Berkeley\n- Dr. Oluwasanmi Koyejo of University of Illinois at Urbana-Champaign\n- Dr. Avi Goldfarb of Rotman School of Management, University of Toronto\n- Dr. Laura Rosella of Dalla Lana School of Public Health, University of Toronto\n- Dr. Adrian Dalca of MIT and Harvard Medical School\n- Dr. Rajesh Ranganath of NYU\n- Irene Chen of MIT\n- Matthew McDermott of MIT\n- Dr. Katherine Heller at Duke University\n- Dr. Uri Shalit of Technion\n- Dr. Stephanie Hyland of Microsoft Research Cambridge, UK\n- Dr. Danielle Belgrave of Microsoft Research Cambridge, UK\n- Dr. Shakir Mohamed of DeepMind\n- Dr. Alistair Johnson of MIT\n- Dr. Tom Pollard of MIT\n- Dr. Alan Karthikesalingam of Google Health UK\n\n### Steering Committee\n- Dr. Nigam Shah of Stanford University\n- Dr. Stephen Friend of Oxford University\n- Dr. Samantha Kleinberg of Stevens Institute of Technology\n- Dr. Anna Goldenberg of The Hospital for Sick Children Research Institute\n- Dr. Lucila Ohno-Machado of University of California, San Diego\n- Dr. Noemie Elhadad of Columbia University\n\n### Sponsors\nWe thank the Association for Computing Machinery (ACM) for sponsoring CHIL 2020, as well as the following organizations for supporting the event:\n\n- Google\n- Health[at]Scale\n- Layer6\n- Apple\n- CIFAR\n- Imagia\n- Microsoft\n- Sun Life Financial\n- Creative Destruction Lab\n- Vector Institute\n","proceedings":[{"UID":"20P01","abstract":"A key impediment to reinforcement learning (RL) in real applications with limited, batch data is in defining a reward function that reflects what we implicitly know about reasonable behaviour for a task and allows for robust off-policy evaluation. In this work, we develop a method to identify an admissible set of reward functions for policies that (a) do not deviate too far in performance from prior behaviour, and (b) can be evaluated with high confidence, given only a collection of past trajectories. Together, these ensure that we avoid proposing unreasonable policies in high-risk settings. We demonstrate our approach to reward design on synthetic domains as well as in a critical care context, to guide the design of a reward function that consolidates clinical objectives to learn a policy for weaning patients from mechanical ventilation.","authors":"Niranjani Prasad|Barbara Engelhardt|Finale Doshi-Velez","doi_link":"http://dx.doi.org/10.1145/3368555.3384450","slideslive_active_date":"","slideslive_id":"38931912","title":"Defining admissible rewards for high-confidence policy evaluation in batch reinforcement learning"},{"UID":"20P02","abstract":"The abundance of modern health data provides many opportunities for the use of machine learning techniques to build better statistical models to improve clinical decision making. Predicting time-to-event distributions, also known as survival analysis, plays a key role in many clinical applications. We introduce a variational time-to-event prediction model, named Variational Survival Inference (VSI), which builds upon recent advances in distribution learning techniques and deep neural networks. VSI addresses the challenges of non-parametric distribution estimation by (i) relaxing the restrictive modeling assumptions made in classical models, and (ii) efficiently handling the censored observations, i.e., events that occur outside the observation window, all within the variational framework. To validate the effectiveness of our approach, an extensive set of experiments on both synthetic and real-world datasets is carried out, showing improved performance relative to competing solutions.","authors":"Zidi Xiu|Chenyang Tao|Ricardo Henao","doi_link":"http://dx.doi.org/10.1145/3368555.3384454","slideslive_active_date":"","slideslive_id":"38931913","title":"Variational learning of individual survival distributions"},{"UID":"20P03","abstract":"The dearth of prescribing guidelines for physicians is one key driver of the current opioid epidemic in the United States. In this work, we analyze medical and pharmaceutical claims data to draw insights on characteristics of patients who are more prone to adverse outcomes after an initial synthetic opioid prescription. Toward this end, we propose a generative model that allows discovery from observational data of subgroups that demonstrate an enhanced or diminished causal effect due to treatment. Our approach models these sub-populations as a mixture distribution, using sparsity to enhance interpretability, while jointly learning nonlinear predictors of the potential outcomes to better adjust for confounding. The approach leads to human interpretable insights on discovered subgroups, improving the practical utility for decision support.","authors":"Chirag Nagpal|Dennis Wei|Bhanukiran Vinzamuri|Monica Shekhar|Sara E. Berger|Subhro Das|Kush R. Varshney","doi_link":"http://dx.doi.org/10.1145/3368555.3384456","slideslive_active_date":"","slideslive_id":"38931914","title":"Interpretable subgroup discovery in treatment effect estimation with application to opioid prescribing guidelines"},{"UID":"20P04","abstract":"Adverse drug reactions (ADRs) are detrimental and unexpected clinical incidents caused by drug intake. The increasing availability of massive quantities of longitudinal event data such as electronic health records (EHRs) has redefined ADR discovery as a big data analytics problem, where data-hungry deep neural networks are especially suitable because of the abundance of the data. To this end, we introduce neural self-controlled case series (NSCCS), a deep learning framework for ADR discovery from EHRs. NSCCS rigorously follows a self-controlled case series design to adjust implicitly and efficiently for individual heterogeneity. In this way, NSCCS is robust to time-invariant confounding issues and thus more capable of identifying associations that reflect the underlying mechanism between various types of drugs and adverse conditions. We apply NSCCS to a large-scale real-world EHR dataset and empirically demonstrate its superior performance with comprehensive experiments on a benchmark ADR discovery task.","authors":"Wei Zhang|Zhaobin Kuang|Peggy Peissig|David Page","doi_link":"http://dx.doi.org/10.1145/3368555.3384459","slideslive_active_date":"","slideslive_id":"38931915","title":"Adverse drug reaction discovery from electronic health records with deep neural networks"},{"UID":"20P05","abstract":"Real-world predictive models in healthcare should be evaluated in terms of discrimination, the ability to differentiate between high and low risk events, and calibration, or the accuracy of the risk estimates. Unfortunately, calibration is often neglected and only discrimination is analyzed. Calibration is crucial for personalized medicine as they play an increasing role in the decision making process. Since random forest is a popular model for many healthcare applications, we propose CaliForest, a new calibrated random forest. Unlike existing calibration methodologies, CaliForest utilizes the out-of-bag samples to avoid the explicit construction of a calibration set. We evaluated CaliForest on two risk prediction tasks obtained from the publicly-available MIMIC-III database. Evaluation on these binary prediction tasks demonstrates that CaliForest can achieve the same discriminative power as random forest while obtaining a better-calibrated model evaluated across six different metrics. CaliForest will be published on the standard Python software repository and the code will be openly available on Github.","authors":"Yubin Park|Joyce C. Ho","doi_link":"http://dx.doi.org/10.1145/3368555.3384461","slideslive_active_date":"","slideslive_id":"38931916","title":"CaliForest: calibrated random forest for health data"},{"UID":"20P06","abstract":"Retinal effusions and cysts caused by the leakage of damaged macular vessels and choroid neovascularization are symptoms of many ophthalmic diseases. Optical coherence tomography (OCT), which provides clear 10-layer cross-sectional images of the retina, is widely used to screen various ophthalmic diseases. A large number of researchers have carried out relevant studies on deep learning technology to realize the semantic segmentation of lesion areas, such as effusion on OCT images, and achieved good results. However, in this field, problems of the low contrast of the lesion area and unevenness of lesion size limit the accuracy of the deep learning semantic segmentation model. In this paper, we propose a boundary multi-scale multi-task OCT segmentation network (BMM-Net) for these two challenges to segment the retinal edema area, subretinal fluid, and pigment epithelial detachment in OCT images. We propose a boundary extraction module, a multi-scale information perception module, and a classification module to capture accurate position and semantic information and collaboratively extract meaningful features. We train and verify on the AI Challenger competition dataset. The average Dice coefficient of the three lesion areas is 3.058% higher than the most commonly used model in the field of medical image segmentation and reaches 0.8222.","authors":"Ruru Zhang|Jiawen He|Shenda Shi|Haihong E|Zhonghong Ou|Meina Song","doi_link":"http://dx.doi.org/10.1145/3368555.3384447","slideslive_active_date":"","slideslive_id":"38931917","title":"BMM-Net: automatic segmentation of edema in optical coherence tomography based on boundary detection and multi-scale network"},{"UID":"20P07","abstract":"Conventional survival analysis approaches estimate risk scores or individualized time-to-event distributions conditioned on covariates. In practice, there is often great population-level phenotypic heterogeneity, resulting from (unknown) subpopulations with diverse risk profiles or survival distributions. As a result, there is an unmet need in survival analysis for identifying subpopulations with distinct risk profiles, while jointly accounting for accurate individualized time-to-event predictions. An approach that addresses this need is likely to improve the characterization of individual outcomes by leveraging regularities in subpopulations, thus accounting for population-level heterogeneity. In this paper, we propose a Bayesian nonparametrics approach that represents observations (subjects) in a clustered latent space, and encourages accurate time-to-event predictions and clusters (subpopulations) with distinct risk profiles. Experiments on real-world datasets show consistent improvements in predictive performance and interpretability relative to existing state-of-the-art survival analysis models.","authors":"Paidamoyo Chapfuwa|Chunyuan Li|Nikhil Mehta|Lawrence Carin|Ricardo Henao","doi_link":"http://dx.doi.org/10.1145/3368555.3384465","slideslive_active_date":"","slideslive_id":"38931918","title":"Survival cluster analysis"},{"UID":"20P08","abstract":"While deep learning has shown promise in the domain of disease classification from medical images, models based on state-of-the-art convolutional neural network architectures often exhibit performance loss due to dataset shift. Models trained using data from one hospital system achieve high predictive performance when tested on data from the same hospital, but perform significantly worse when they are tested in different hospital systems. Furthermore, even within a given hospital system, deep learning models have been shown to depend on hospital- and patient-level confounders rather than meaningful pathology to make classifications. In order for these models to be safely deployed, we would like to ensure that they do not use confounding variables to make their classification, and that they will work well even when tested on images from hospitals that were not included in the training data. We attempt to address this problem in the context of pneumonia classification from chest radiographs. We propose an approach based on adversarial optimization, which allows us to learn more robust models that do not depend on confounders. Specifically, we demonstrate improved out-of-hospital generalization performance of a pneumonia classifier by training a model that is invariant to the view position of chest radiographs (anterior-posterior vs. posterior-anterior). Our approach leads to better predictive performance on external hospital data than both a standard baseline and previously proposed methods to handle confounding, and also suggests a method for identifying models that may rely on confounders.","authors":"Joseph D. Janizek|Gabriel Erion|Alex J. DeGrave|Su-In Lee","doi_link":"http://dx.doi.org/10.1145/3368555.3384458","slideslive_active_date":"","slideslive_id":"38931919","title":"An adversarial approach for the robust classification of pneumonia from chest radiographs"},{"UID":"20P09","abstract":"Much work aims to explain a model's prediction on a static input. We consider explanations in a temporal setting where a stateful dynamical model produces a sequence of risk estimates given an input at each time step. When the estimated risk increases, the goal of the explanation is to attribute the increase to a few relevant inputs from the past.While our formal setup and techniques are general, we carry out an in-depth case study in a clinical setting. The goal here is to alert a clinician when a patient's risk of deterioration rises. The clinician then has to decide whether to intervene and adjust the treatment. Given a potentially long sequence of new events since she last saw the patient, a concise explanation helps her to quickly triage the alert.We develop methods to lift static attribution techniques to the dynamical setting, where we identify and address challenges specific to dynamics. We then experimentally assess the utility of different explanations of clinical alerts through expert evaluation.","authors":"Michaela Hardt|Alvin Rajkomar|Gerardo Flores|Andrew Dai|Michael Howell|Greg Corrado|Claire Cui|Moritz Hardt","doi_link":"http://dx.doi.org/10.1145/3368555.3384460","slideslive_active_date":"","slideslive_id":"38931920","title":"Explaining an increase in predicted risk for clinical alerts"},{"UID":"20P10","abstract":"We introduce SparseVM, a method that registers clinical-quality 3D MR scans both faster and more accurately than previously possible. Deformable alignment, or registration, of clinical scans is a fundamental task for many clinical neuroscience studies. However, most registration algorithms are designed for high-resolution research-quality scans. In contrast to research-quality scans, clinical scans are often sparse, missing up to 86% of the slices available in research-quality scans. Existing methods for registering these sparse images are either inaccurate or extremely slow. We present a learning-based registration method, SparseVM, that is more accurate and orders of magnitude faster than the most accurate clinical registration methods. To our knowledge, it is the first method to use deep learning specifically tailored to registering clinical images. We demonstrate our method on a clinically-acquired MRI dataset of stroke patients and on a simulated sparse MRI dataset. Our code is available as part of the VoxelMorph package at http://voxelmorph.mit.edu.","authors":"Kathleen Lewis|Natalia S. Rost|John Guttag|Adrian V. Dalca","doi_link":"http://dx.doi.org/10.1145/3368555.3384462","slideslive_active_date":"","slideslive_id":"38931921","title":"Fast learning-based registration of sparse 3D clinical images"},{"UID":"20P11","abstract":"Necrotizing enterocolitis (NEC) is a life-threatening intestinal disease that primarily affects preterm infants during their first weeks after birth. Mortality rates associated with NEC are 15-30%, and surviving infants are susceptible to multiple serious, long-term complications. The disease is sporadic and, with currently available tools, unpredictable. We are creating an early warning system that uses stool microbiome features, combined with clinical and demographic information, to identify infants at high risk of developing NEC. Our approach uses a multiple instance learning, neural network-based system that could be used to generate daily or weekly NEC predictions for premature infants. The approach was selected to effectively utilize sparse and weakly annotated datasets characteristic of stool microbiome analysis. Here we describe initial validation of our system, using clinical and microbiome data from a nested case-control study of 161 preterm infants. We show receiver-operator curve areas above 0.9, with 75% of dominant predictive samples for NEC-affected infants identified at least 24 hours prior to disease onset. Our results pave the way for development of a real-time early warning system for NEC using a limited set of basic clinical and demographic details combined with stool microbiome data.","authors":"Thomas Hooven|Yun Chao Lin|Ansaf Salleb-Aouissi","doi_link":"http://dx.doi.org/10.1145/3368555.3384466","slideslive_active_date":"","slideslive_id":"38931922","title":"Multiple instance learning for predicting necrotizing enterocolitis in premature infants using microbiome data"},{"UID":"20P12","abstract":"In this work, we examine the extent to which embeddings may encode marginalized populations differently, and how this may lead to a perpetuation of biases and worsened performance on clinical tasks. We pretrain deep embedding models (BERT) on medical notes from the MIMIC-III hospital dataset, and quantify potential disparities using two approaches. First, we identify dangerous latent relationships that are captured by the contextual word embeddings using a fill-in-the-blank method with text from real clinical notes and a log probability bias score quantification. Second, we evaluate performance gaps across different definitions of fairness on over 50 downstream clinical prediction tasks that include detection of acute and chronic conditions. We find that classifiers trained from BERT representations exhibit statistically significant differences in performance, often favoring the majority group with regards to gender, language, ethnicity, and insurance status. Finally, we explore shortcomings of using adversarial debiasing to obfuscate subgroup information in contextual word embeddings, and recommend best practices for such deep embedding models in clinical settings.","authors":"Haoran Zhang|Amy X. Lu|Mohamed Abdalla|Matthew McDermott|Marzyeh Ghassemi","doi_link":"http://dx.doi.org/10.1145/3368555.3384448","slideslive_active_date":"","slideslive_id":"38931923","title":"Hurtful words: quantifying biases in clinical contextual word embeddings"},{"UID":"20P13","abstract":"Single-cell RNA sequencing (scRNA-seq) has revolutionized bio-logical discovery, providing an unbiased picture of cellular heterogeneity in tissues. While scRNA-seq has been used extensively to provide insight into health and disease, it has not been used for disease prediction or diagnostics. Graph Attention Networks have proven to be versatile for a wide range of tasks by learning from both original features and graph structures. Here we present a graph attention model for predicting disease state from single-cell data on a large dataset of Multiple Sclerosis (MS) patients. MS is a disease of the central nervous system that is difficult to diagnose. We train our model on single-cell data obtained from blood and cerebrospinal fluid (CSF) for a cohort of seven MS patients and six healthy adults (HA), resulting in 66,667 individual cells. We achieve 92% accuracy in predicting MS, outperforming other state-of-the-art methods such as a graph convolutional network, random forest, and multi-layer perceptron. Further, we use the learned graph attention model to get insight into the features (cell types and genes) that are important for this prediction. The graph attention model also allow us to infer a new feature space for the cells that emphasizes the difference between the two conditions. Finally we use the attention weights to learn a new low-dimensional embedding which we visualize with PHATE and UMAP. To the best of our knowledge, this is the first effort to use graph attention, and deep learning in general, to predict disease state from single-cell data. We envision applying this method to single-cell data for other diseases.","authors":"Neal Ravindra|Arijit Sehanobish|Jenna L. Pappalardo|David A. Hafler|David van Dijk","doi_link":"http://dx.doi.org/10.1145/3368555.3384449","slideslive_active_date":"","slideslive_id":"38931924","title":"Disease state prediction from single-cell data using graph attention networks"},{"UID":"20P14","abstract":"The International Classification of Disease (ICD) is a widely used diagnostic ontology for the classification of health disorders and a valuable resource for healthcare analytics. However, ICD is an evolving ontology and subject to periodic revisions (e.g. ICD-9-CM to ICD-10-CM) resulting in the absence of complete cross-walks between versions. While clinical experts can create custom mappings across ICD versions, this process is both time-consuming and costly. We propose an automated solution that facilitates interoperability without sacrificing accuracy.Our solution leverages the SNOMED-CT ontology whereby medical concepts are organised in a directed acyclic graph. We use this to map ICD-9-CM to ICD-10-CM by associating codes to clinical concepts in the SNOMED graph using a nearest neighbors search in combination with natural language processing. To assess the impact of our method, the performance of a gradient boosted tree (XGBoost) developed to classify patients with Exocrine Pancreatic Insufficiency (EPI) disorder, was compared when using features constructed by our solution versus clinically-driven methods. This dataset comprised of 23, 204 EPI patients and 277, 324 non-EPI patients with data spanning from October 2011 to April 2017. Our algorithm generated clinical predictors with comparable stability across the ICD-9-CM to ICD-10-CM transition point when compared to ICD-9-CM/ICD-10-CM mappings generated by clinical experts. Preliminary modeling results showed highly similar performance for models based on the SNOMED mapping vs clinically defined mapping (71% precision at 20% recall for both models). Overall, the framework does not compromise on accuracy at the individual code level or at the model-level while obviating the need for time-consuming manual mapping.","authors":"Shaun Gupta|Frederik Dieleman|Patrick Long|Orla Doyle|Nadejda Leavitt","doi_link":"http://dx.doi.org/10.1145/3368555.3384453","slideslive_active_date":"","slideslive_id":"38931925","title":"Using SNOMED to automate clinical concept mapping"},{"UID":"20P15","abstract":"Systematic review (SR) is an essential process to identify, evaluate, and summarize the findings of all relevant individual studies concerning health-related questions. However, conducting a SR is labor-intensive, as identifying relevant studies is a daunting process that entails multiple researchers screening thousands of articles for relevance. In this paper, we propose MMiDaS-AE, a Multi-modal Missing Data aware Stacked Autoencoder, for semi-automating screening for SRs. We use a multi-modal view that exploits three representations, of: 1) documents, 2) topics, and 3) citation networks. Documents that contain similar words will be nearby in the document embedding space. Models can also exploit the relationship between documents and the associated SR MeSH terms to capture article relevancy. Finally, related works will likely share the same citations, and thus closely related articles would, intuitively, be trained to be close to each other in the embedding space. However, using all three learned representations as features directly result in an unwieldy number of parameters. Thus, motivated by recent work on multi-modal auto-encoders, we adopt a multi-modal stacked autoencoder that can learn a shared representation encoding all three representations in a compressed space. However, in practice one or more of these modalities may be missing for an article (e.g., if we cannot recover citation information). Therefore, we propose to learn to impute the shared representation even when specific inputs are missing. We find this new model significantly improves performance on a dataset consisting of 15 SRs compared to existing approaches.","authors":"Eric W. Lee|Byron C. Wallace|Karla I. Galaviz|Joyce C. Ho","doi_link":"http://dx.doi.org/10.1145/3368555.3384463","slideslive_active_date":"","slideslive_id":"38931926","title":"MMiDaS-AE: multi-modal missing data aware stacked autoencoder for biomedical abstract screening"},{"UID":"20P16","abstract":"Machine learning models for medical image analysis often suffer from poor performance on important subsets of a population that are not identified during training or testing. For example, overall performance of a cancer detection model may be high, but the model may still consistently miss a rare but aggressive cancer subtype. We refer to this problem as hidden stratification, and observe that it results from incompletely describing the meaningful variation in a dataset. While hidden stratification can substantially reduce the clinical efficacy of machine learning models, its effects remain difficult to measure. In this work, we assess the utility of several possible techniques for measuring hidden stratification effects, and characterize these effects both via synthetic experiments on the CIFAR-100 benchmark dataset and on multiple real-world medical imaging datasets. Using these measurement techniques, we find evidence that hidden stratification can occur in unidentified imaging subsets with low prevalence, low label quality, subtle distinguishing features, or spurious correlates, and that it can result in relative performance differences of over 20% on clinically important subsets. Finally, we discuss the clinical implications of our findings, and suggest that evaluation of hidden stratification should be a critical component of any machine learning deployment in medical imaging.","authors":"Luke Oakden-Rayner|Jared Dunnmon|Gustavo Carneiro|Christopher Re","doi_link":"http://dx.doi.org/10.1145/3368555.3384468","slideslive_active_date":"","slideslive_id":"38931927","title":"Hidden stratification causes clinically meaningful failures in machine learning for medical imaging"},{"UID":"20P17","abstract":"Automated assessment of rehabilitation exercises using machine learning has a potential to improve current rehabilitation practices. However, it is challenging to completely replicate therapist's decision making on the assessment of patients with various physical conditions. This paper describes an interactive machine learning approach that iteratively integrates a data-driven model with expert's knowledge to assess the quality of rehabilitation exercises. Among a large set of kinematic features of the exercise motions, our approach identifies the most salient features for assessment using reinforcement learning and generates a user-specific analysis to elicit feature relevance from a therapist for personalized rehabilitation assessment. While accommodating therapist's feedback on feature relevance, our approach can tune a generic assessment model into a personalized model. Specifically, our approach improves performance to predict assessment from 0.8279 to 0.9116 average F1-scores of three upper-limb rehabilitation exercises (p < 0.01). Our work demonstrates that machine learning models with feature selection can generate kinematic feature-based analysis as explanations on predictions of a model to elicit expert's knowledge of assessment, and how machine learning models can augment with expert's knowledge for personalized rehabilitation assessment.","authors":"Min Hun Lee|Daniel P. Siewiorek|Asim Smailagic|Alexandre Bernardino|Sergi Berm\u00fadez i Badia","doi_link":"http://dx.doi.org/10.1145/3368555.3384452","slideslive_active_date":"","slideslive_id":"38931928","title":"Interactive hybrid approach to combine machine and human intelligence for personalized rehabilitation assessment"},{"UID":"20P18","abstract":"Accurately extracting medical entities from social media is challenging because people use informal language with different expressions for the same concept, and they also make spelling mistakes. Previous work either focused on specific diseases (e.g., depression) or drugs (e.g., opioids) or, if working with a wide-set of medical entities, only tackled individual and small-scale benchmark datasets (e.g., AskaPatient). In this work, we first demonstrated how to accurately extract a wide variety of medical entities such as symptoms, diseases, and drug names on three benchmark datasets from varied social media sources, and then also validated this approach on a large-scale Reddit dataset.We first implemented a deep-learning method using contextual embeddings that upon two existing benchmark datasets, one containing annotated AskaPatient posts (CADEC) and the other containing annotated tweets (Micromed), outperformed existing state-of-the-art methods. Second, we created an additional benchmark dataset by annotating medical entities in 2K Reddit posts (made publicly available under the name of MedRed) and showed that our method also performs well on this new dataset.Finally, to demonstrate that our method accurately extracts a wide variety of medical entities on a large scale, we applied the model pre-trained on MedRed to half a million Reddit posts. The posts came from disease-specific subreddits so we could categorise them into 18 diseases based on the subreddit. We then trained a machine-learning classifier to predict the post's category solely from the extracted medical entities. The average F1 score across categories was .87. These results open up new cost-effective opportunities for modeling, tracking and even predicting health behavior at scale.","authors":"Sanja Scepanovic|Enrique Martin-Lopez|Daniele Quercia|Khan Baykaner","doi_link":"http://dx.doi.org/10.1145/3368555.3384467","slideslive_active_date":"","slideslive_id":"38931929","title":"Extracting medical entities from social media"},{"UID":"20P19","abstract":"While machine learning is rapidly being developed and deployed in health settings such as influenza prediction, there are critical challenges in using data from one environment to predict in another due to variability in features. Even within disease labels there can be differences (e.g. \"fever\" may mean something different reported in a doctor's office versus in an online app). Moreover, models are often built on passive, observational data which contain different distributions of population subgroups (e.g. men or women). Thus, there are two forms of instability between environments in this observational transport problem. We first harness substantive knowledge from health research to conceptualize the underlying causal structure of this problem in a health outcome prediction task. Based on sources of stability in the model and the task, we posit that we can combine environment and population information in a novel population-aware hierarchical Bayesian domain adaptation framework that harnesses multiple invariant components through population attributes when needed. We study the conditions under which invariant learning fails, leading to reliance on the environment-specific attributes. Experimental results for an influenza prediction task on four datasets gathered from different contexts show the model can improve prediction in the case of largely unlabelled target data from a new environment and different constituent population, by harnessing both environment and population invariant information. This work represents a novel, principled way to address a critical challenge by blending domain (health) knowledge and algorithmic innovation. The proposed approach will have significant impact in many social settings wherein who the data comes from and how it was generated, matters.","authors":"Vishwali Mhasawade|Nabeel Abdur Rehman|Rumi Chunara","doi_link":"http://dx.doi.org/10.1145/3368555.3384451","slideslive_active_date":"","slideslive_id":"38931930","title":"Population-aware hierarchical bayesian domain adaptation via multi-component invariant learning"},{"UID":"20P20","abstract":"Phenotyping electronic health records (EHR)focuses on defining meaningful patient groups (e.g., heart failure group and diabetes group) and identifying the temporal evolution of patients in those groups. Tensor factorization has been an effective tool for phenotyping. Most of the existing works assume either a static patient representation with aggregate data or only model temporal data. However, real EHR data contain both temporal (e.g., longitudinal clinical visits) and static information (e.g., patient demographics), which are difficult to model simultaneously. In this paper, we propose Temporal And Static TEnsor factorization (TASTE) that jointly models both static and temporal information to extract phenotypes.TASTE combines the PARAFAC2 model with non-negative matrix factorization to model a temporal and a static tensor. To fit the proposed model, we transform the original problem into simpler ones which are optimally solved in an alternating fashion. For each of the sub-problems, our proposed mathematical re-formulations lead to efficient sub-problem solvers. Comprehensive experiments on large EHR data from a heart failure (HF) study confirmed that TASTE is up to 14\u00d7 faster than several baselines and the resulting phenotypes were confirmed to be clinically meaningful by a cardiologist. Using 60 phenotypes extracted by TASTE, a simple logistic regression can achieve the same level of area under the curve (AUC) for HF prediction compared to a deep learning model using recurrent neural networks (RNN) with 345 features.","authors":"Ardavan Afshar|Ioakeim Perros|Haesun Park|Christopher deFilippi|Xiaowei Yan|Walter Stewart|Joyce Ho|Jimeng Sun","doi_link":"http://dx.doi.org/10.1145/3368555.3384464","slideslive_active_date":"","slideslive_id":"38931931","title":"TASTE: temporal and static tensor factorization for phenotyping electronic health records"},{"UID":"20P21","abstract":"In medicine, both ethical and monetary costs of incorrect predictions can be significant, and the complexity of the problems often necessitates increasingly complex models. Recent work has shown that changing just the random seed is enough for otherwise well-tuned deep neural networks to vary in their individual predicted probabilities. In light of this, we investigate the role of model uncertainty methods in the medical domain. Using RNN ensembles and various Bayesian RNNs, we show that population-level metrics, such as AUC-PR, AUC-ROC, log-likelihood, and calibration error, do not capture model uncertainty. Meanwhile, the presence of significant variability in patient-specific predictions and optimal decisions motivates the need for capturing model uncertainty. Understanding the uncertainty for individual patients is an area with clear clinical impact, such as determining when a model decision is likely to be brittle. We further show that RNNs with only Bayesian embeddings can be a more efficient way to capture model uncertainty compared to ensembles, and we analyze how model uncertainty is impacted across individual input features and patient subgroups.","authors":"Michael W. Dusenberry|Dustin Tran|Edward Choi|Jonas Kemp|Jeremy Nixon|Ghassen Jerfel|Katherine Heller|Andrew M. Dai","doi_link":"http://dx.doi.org/10.1145/3368555.3384457","slideslive_active_date":"","slideslive_id":"38931932","title":"Analyzing the role of model uncertainty for electronic health records"},{"UID":"20P22","abstract":"The ability of caregivers and investigators to share patient data is fundamental to many areas of clinical practice and biomedical research. Prior to sharing, it is often necessary to remove identifiers such as names, contact details, and dates in order to protect patient privacy. Deidentification, the process of removing identifiers, is challenging, however. High-quality annotated data for developing models is scarce; many target identifiers are highly heterogenous (for example, there are uncountable variations of patient names); and in practice anything less than perfect sensitivity may be considered a failure. Consequently, software for adequately deidentifying clinical data is not widely available. As a result patient data is often withheld when sharing would be beneficial, and identifiable patient data is often divulged when a deidentified version would suffice.In recent years, advances in machine learning methods have led to rapid performance improvements in natural language processing tasks, in particular with the advent of large-scale pretrained language models. In this paper we develop and evaluate an approach for deidentification of clinical notes based on a bidirectional transformer model. We propose human interpretable evaluation measures and demonstrate state of the art performance against modern baseline models. Finally, we highlight current challenges in deidentification, including the absence of clear annotation guidelines, lack of portability of models, and paucity of training data. Code to develop our model is open source and simple to install, allowing for broad reuse.","authors":"Alistair E. W. Johnson|Lucas Bulgarelli|Tom J. Pollard","doi_link":"http://dx.doi.org/10.1145/3368555.3384455","slideslive_active_date":"","slideslive_id":"38931933","title":"Deidentification of free-text medical records using pre-trained bidirectional transformers"},{"UID":"20P23","abstract":"Machine learning for healthcare researchers face challenges to progress and reproducibility due to a lack of standardized processing frameworks for public datasets. We present MIMIC-Extract, an open source pipeline for transforming the raw electronic health record (EHR) data of critical care patients from the publicly-available MIMIC-III database into data structures that are directly usable in common time-series prediction pipelines. MIMIC-Extract addresses three challenges in making complex EHR data accessible to the broader machine learning community. First, MIMIC-Extract transforms raw vital sign and laboratory measurements into usable hourly time series, performing essential steps such as unit conversion, outlier handling, and aggregation of semantically similar features to reduce missingness and improve robustness. Second, MIMIC-Extract extracts and makes prediction of clinically-relevant targets possible, including outcomes such as mortality and length-of-stay as well as comprehensive hourly intervention signals for ventilators, vasopressors, and fluid therapies. Finally, the pipeline emphasizes reproducibility and extensibility to future research questions. We demonstrate the pipeline's effectiveness by developing several benchmark tasks for outcome and intervention forecasting and assessing the performance of competitive models.","authors":"Shirly Wang|Matthew B. A. McDermott|Geeticka Chauhan|Marzyeh Ghassemi|Michael C. Hughes|Tristan Naumann","doi_link":"http://dx.doi.org/10.1145/3368555.3384469","slideslive_active_date":"","slideslive_id":"38931934","title":"MIMIC-Extract: a data extraction, preprocessing, and representation pipeline for MIMIC-III"}],"speakers":[{"UID":"20K01","abstract":"This talk outlines two Mila projects aimed at fighting the Covid-19 pandemic which are part of Mila's AI for Humanity mission. The first one is about discovering antivirals, either via repurposing several existing drugs using graph neural networks or via discovering new drug-like molecules using reinforcement learning and docking simulations to search in the molecular space. The second project is about using machine learning to provide early warning signals to people who are contagious -- especially if they don't realize that they are -- by exchanging information between phones of users who have had dangerous contacts with each other. This extends digital contact tracing by incorporating information about symptoms, medical condition and behavior (like wearing a mask) and relies on a sophisticated epidemiological model at the individual levels in which we can simulate different individual-level and society-level strategies.","bio":"Yoshua Bengio is Professor in the Computer Science and Operations Research departments at U. Montreal, founder and scientific director of Mila and of IVADO. He is a Fellow of the Royal Society of London and of the Royal Society of Canada, has received a Canada Research Chair and a Canada CIFAR AI Chair and is a recipient of the 2018 Turing Award for pioneering deep learning, is an officer of the Order of Canada, a member of the NeurIPS advisory board, co-founder and member of the board of the ICLR conference, and program director of the CIFAR program on Learning in Machines and Brains. His goal is to contribute to uncovering the principles giving rise to intelligence through learning, as well as favour the development of AI for the benefit of all.","image":"static/images/speakers/yoshua_bengio.png","institution":"University of Montreal","slideslive_active_date":"","slideslive_id":"38931907","speaker":"Yoshua Bengio","title":"Machine Learning Challenges in the Fight for Social Good - the Covid-19 Case","website":""},{"UID":"20K02","abstract":"Countries in Sub-Saharan Africa are facing a double burden of infectious and noncommunicable diseases. The burden of noncommunicable diseases such as, diabetes and hypertension, are expected to continue increasing. Digital data and tools that can be used to study the patterns of health and disease in populations offer opportunities for improving public health. Digital platforms such as, social media, search engines, and internet forums, have been widely accepted in Sub-Saharan Africa for health information seeking and sharing. These tools can be used to improve public health in Sub-Saharan Africa in three ways: (1) monitoring health information seeking and providing health education, (2) monitoring risk factors, and (3) monitoring disease incidence. However, in order for these tools to be effective, it is important to consider and incorporate into analytical processes the distinct social, cultural, and economic context in Sub-Saharan African countries.","bio":"Dr. Nsoesie is an Assistant Professor of Global Health at Boston University (BU) School of Public Health. She is also a BU Data Science Faculty Fellow as part of the BU Data Science Initiative at the Hariri Institute for Computing and a Data and Innovation Fellow at The Directorate of Science, Technology and Innovation (DSTI) in the Office of the President in Sierra Leone. Dr. Nsoesie applies data science methodologies to global health problems, using digital data and technology to improve health, particularly in the realm of surveillance of chronic and infectious diseases. She has worked with local public health departments in the United States and international organizations. She completed her postdoctoral studies at Harvard Medical School, and her PhD in Computational Epidemiology from the Genetics, Bioinformatics and Computational Biology program at Virginia Tech. She also has an MS in Statistics and a BS in Mathematics. She is the founder of Reth\u00e9 \u2013  an initiative focused on providing scientific writing tools and resources to student communities in Africa in order to increase representation in scientific publications. She has written for NPR, The Conversation, Public Health Post and Quartz. Dr. Nsoesie was born and raised in Cameroon.","image":"static/images/speakers/elaine_nsoesie.jpg","institution":"Boston University","slideslive_active_date":"","slideslive_id":"38931908","speaker":"Elaine Nsoesie","title":"Digital Platforms & Public Health in Africa","website":""},{"UID":"20K03","abstract":"The massive size of the health care sector make data science applications in this space particularly salient for social policy. An overarching theme of this keynote is that developing machine learning methodology tailored to specific substantive health problems and the associated electronic health data is critical given the stakes involved, rather than eschewing complexity in simplified scenarios that may no longer represent an actual real-world problem.","bio":"Sherri Rose, Ph.D. is an Associate Professor of Health Care Policy at Harvard Medical School and Co-Director of the Health Policy Data Science Lab. Her research in health policy focuses on risk adjustment, comparative effectiveness, and health program evaluation. Dr. Rose coauthored the first book on machine learning for causal inference and has published work across fields, including in Biometrics, JASA, PMLR,Journal of Health Economics, and NEJM. She currently serves as co-editor of the journal Biostatistics and is Chair-Elect of the American Statistical Association\u2019s Biometrics Section. Her honors include the ISPOR Bernie J. O\u2019Brien New Investigator Award for exceptional early career work in health economics and outcomes research and an NIH Director\u2019s New Innovator Award to develop machine learning estimators for generalizability in health policy.","image":"static/images/speakers/sherri_rose.png","institution":"Harvard Medical School","slideslive_active_date":"","slideslive_id":"38931910","speaker":"Sherri Rose","title":"Machine Learning in Health Care: Too Important to Be a Toy Example","website":""},{"UID":"20K04","abstract":"Details to be confirmed.","bio":"Dr. Ruslan Salakhutdinov is a UPMC professor of Computer Science at Carnegie Mellon University. He has served as an area chair for NIPS, ICML, CVPR, and ICLR. He holds a PhD from University of Toronto and completed postdoctoral training at Massachusetts Institute of Technology.","image":"static/images/speakers/ruslan_salakhutdinov.png","institution":"Carnegie Mellon University","slideslive_active_date":"","slideslive_id":"38931911","speaker":"Ruslan Salakhutdinov","title":"Incorporating Domain Knowledge into Deep Learning Models","website":""},{"UID":"20K05","abstract":"In this session we will explore strategies for, and issues involved in, bringing Artificial Intelligence (AI) technologies to the clinic, safely and ethically. We will discuss the characteristics of a sound data strategy for powering a machine learning (ML) health system. The session introduces a frame-work for analyzing the utility of ML models in healthcare and discusses the implicit assumptions in aligning incentives for AI guided healthcare actions.","bio":"Dr. Nigam Shah is Associate Professor of Medicine (Biomedical Informatics) at Stanford University, and serves as the Associate CIO for Data Science for Stanford Health Care. Dr. Shah\u2019s research focuses on combining machine learning and prior knowledge in medical ontologies to enable the learning health system. Dr. Shah was elected into the American College of Medical Informatics (ACMI) in 2015 and is inducted into the American Society for Clinical Investigation (ASCI) in 2016. He holds an MBBS from Baroda Medical College, India, a PhD from Penn State University and completed postdoctoral training at Stanford University.","image":"static/images/speakers/nigam_shah.png","institution":"Stanford University","slideslive_active_date":"","slideslive_id":"38931909","speaker":"Nigam Shah","title":"A framework for shaping the future of AI in healthcare","website":""}],"symposiums":[{"UID":"20S01","abstract":"Serena Jeblee's (University of Toronto, Expected Aug 2020) research focuses on clinical natural language processing (NLP), with a special focus on the extraction of a normalized Cause of Death (CoD) from verbal autopsy reports. This research would be especially impactful in low to middle income countries, where verbal autopsy reports are common, and physical autopsies or medically certified causes of death are less common. Serena approaches this problem by first extracting a temporally ordered list of symptoms from the verbal autopsy report, then uses these to construct a more accurate assessment of the overall CoD diagnosis. Serena's other work focuses on other clinical NLP tasks, including automatic extraction of pertinent information from provider-patient dialogs.","authors":"Serena Jeblee","slideslive_active_date":"","slideslive_id":"38931967","title":"Doctoral Symposium Talk: Serena Jeblee"},{"UID":"20S02","abstract":"Dr. Serifat Folorunso's (University of Ibadan, 2019) research focuses on augmented survival data analysis using modified generalized gamma mixture cure models (GGMCMs) for cancer research.  In particular, Dr. Folorunso's work examines generalizing traditional GGMCMs to better account for the acute-asymmetry in survival data by using a gamma link function. Dr. Folorunso's model demonstrated superior performance to a traditional GGMCM as well as other kinds of survival mixture-cure models on an ovarian cancer dataset from University College Hospital, Ibadan. Dr. Folorunso's has also investigated works examining additional aspects of survival models, as well as social determinants and impacts of neonatal health.","authors":"Serifat Folorunso","slideslive_active_date":"","slideslive_id":"38931968","title":"Doctoral Symposium Talk: Serifat Folorunso"},{"UID":"20S03","abstract":"Dr. Savannah Bergquist's (Harvard University, 2019) research focuses on accounting for missing not at random (MNAR) data in health contexts, specifically insurance plan payment policies and lung cancer staging from insurance claims data. In the former analyses, Dr. Bergquist's work uses missingness sensitive ML methods to examine the contribution of various current practices to problematic incentives in medicare plan payment policies, and to suggest improvement. In the latter research, Dr. Bergquist focuses on predicting a clinically meaningful lung cancer staging system using classification models. Dr. Bergquist also has examined other aspects of health insurance plan design and analysis.","authors":"Savannah Bergquist","slideslive_active_date":"","slideslive_id":"38931970","title":"Doctoral Symposium Talk: Savannah Bergquist"},{"UID":"20S04","abstract":"Paidamoyo Chapfuwa's (Duke University, Expected 2021) research focuses on bringing modern machine learning approaches to survival analysis, i.e, causal inference, generative modeling, and Bayesian nonparametric. In particular, Paidamoyo's work examines generative methods for high-performance (accurate, calibrated, uncertainty-aware predictions) survival models. Moreover, her work introduces an adversarial distribution matching approach and a novel covariate-conditional Kaplan-Meier estimator, accounting for the predictive uncertainty in survival model calibration. In  addition, her work also enables an interpretable time-to-event driven clustering method using a Bayesian nonparametric stick-breaking representation of the Dirichlet Process that represents patients in a clustered latent space. Recently,  Paidamoyo\u2019s work has explored a unified framework for individualized treatment effect estimation for survival outcomes from observation data.","authors":"Paidamoyo Chapfuwa","slideslive_active_date":"","slideslive_id":"38931971","title":"Doctoral Symposium Talk: Paidamoyo Chapfuwa"},{"UID":"20S05","abstract":"Primoz Kocbek's (University of Maribor, Expected 2021) research focuses on interpretability and the use of synthetic data in machine learning models processing electronic health record (EHR) data. In particular, Primoz's research examined and provided a more nuanced analysis of the kinds of interpretability enabled by various kinds of models, including classifications of models as providing local vs. global or model-dependent vs. model-agnostic interpretability. Primoz also hopes to extend his research in the future with the use of synthetic data as additional structure to data, primarily leveraging the natural graph structure of some subsets of EHR data to improve predictive power.","authors":"Primoz Kocbek","slideslive_active_date":"","slideslive_id":"38931972","title":"Doctoral Symposium Talk: Primoz Kocbek"},{"UID":"20S06","abstract":"Jill Furzer's (University of Toronto, Expected 2020) research focuses on combining ensemble learning methods with an economics causal inference tool-kit to predict mental health risk in childhood, assess drivers of marginal misdiagnosis, and understand long-term socioeconomic implications of missed, late or low-value diagnoses. Jill compares classic regression with regularized regression and gradient boosted trees to estimate latent mental health risk in childhood in a nationally representative longitudinal health survey dataset, and further examines how sensitive these models are to protected subgroup information, including gender, rural v. urban, and socioeconomic status. Jill's past research has further focused on modelling the cost-effectiveness of various pediatric oncology screening guidelines and treatments.","authors":"Jill Furzer","slideslive_active_date":"","slideslive_id":"38931974","title":"Doctoral Symposium Talk: Jill Furzer"},{"UID":"20S07","abstract":"Dr. Hasna Njah's (University of Sfax, 2019) research focuses on learning bayesian networks (BNs) for health applications in the context of high-dimensional data. In particular, Dr. Njah's research proposes a new kind of BN, called a Bayesian Network Abstraction (BNA) framework, which uses latent variables to ameliorate the computational and optimization difficulties imposed by high-dimensional data. The BNA framework first uses dependency-based feature clustering algorithms to cluster input variables, followed by learning to summarize each cluster in a separate latent variable, thereby realizing the entire network in a hierarchical clustering & summarization BN, with the overall system learned using the greedy equilibrium criteria and hierarchical expectation maximization. In other work, Dr. Njah has focused on applying BNs to protein-protein interaction data and gene regulatory networks. ","authors":"Hasna Njah","slideslive_active_date":"","slideslive_id":"38931976","title":"Doctoral Symposium Talk: Hasna Njah"},{"UID":"20S08","abstract":"Vinyas Harish's (University of Toronto, Expected MD/PhD 2025) research focuses on the ways in which machine learning can complement traditional epidemiological perspectives and methods applied at the population and clinical levels, with an emphasis on promoting health systems resilience in the context of emergencies. Vinyas explores these topics in several ways, including a qualitative study on the ethics of private sector ML4H collaborations with stakeholders across technical, ethics/governance, and clinical domains, an examination of the utility of pandemic preparedness indices through cluster analysis, and the high-resolution prediction of COVID-19 transmission using mobility data and environmental covariates. Historically, Vinyas has also examined medical device safety and feasibility testing as well as the efficacy of novel methods for teaching clinicians image-guided procedures.","authors":"Vinyas Harish","slideslive_active_date":"","slideslive_id":"38931977","title":"Doctoral Symposium Talk: Vinyas Harish"},{"UID":"20S09","abstract":"Haohan Wang's (Carnegie Mellon University, Expected 2021) research focuses on the systematic development of trustworthy machine learning (ML) systems that can be deployed to answer biomedical questions in the real-world scenarios, consistently responding over significant variations of the data. In particular, Haohan's work focuses on improving robustness of ML models to dataset shift, specifically towards the application of early prediction of Alzheimer's disease from genetic and imaging data. Haohan's methods focus on using a nuanced understanding of the data generative process in order to better account for expected distributional shifts, yielding more robust and interpretable models of Alzheimer's diagnosis. In other work, Haohan has also investigated the use of ML methods on genomic and transcriptomic data for biomedical applications.","authors":"Haohan Wang","slideslive_active_date":"","slideslive_id":"38931978","title":"Doctoral Symposium Talk: Haohan Wang"},{"UID":"20S10","abstract":"Mamadou Lamine MBOUP's (University of Thies, Expected 2022) research focuses on using ML methods over ultrasound data to perform early diagnosis and identification of liver damage within chronic liver disease patients and to classify said patients according to their severity. Especially in areas where chronic liver diseases, such as hepatitis, are prevalent, and liver cirrhosis and cancer are a significant health burden on the community, using ML methods to perform early diagnosis of these syndromes based on a low-cost modality like ultrasound would be extremely impactful. Mamdou's work investigates using supervised and unsupervised classical and deep learning methods to solve this problem, using data from a cohort of patients at the Aristide Le Dantec University Hospital Center. In past work, Mamadou has investigated algorithms for image compression, as well as investigated other health tasks in the cancer area.","authors":"Mamadou Lamine MBOUP","slideslive_active_date":"","slideslive_id":"38931979","title":"Doctoral Symposium Talk: Mamadou Lamine MBOUP"},{"UID":"20S11","abstract":"Tulika Kakati's (Tezpur University, Expected 2020) research focuses on gene expression analysis using ML to identify biomarkers across disease state and the cell cycle. Tulika's work has used novel clustering methods and identification of border genes for co-expression analysis, as well as developing novel deep learning approaches to the identification of differentially expressed genes via DEGnet, validating all models across a number of gene expression datasets. Tulika has also investigated improving the computational efficiency of these methods via distributed computing, specifically with regards to the application of their clustering algorithms.","authors":"Tulika Kakati","slideslive_active_date":"","slideslive_id":"38931980","title":"Doctoral Symposium Talk: Tulika Kakati"},{"UID":"20S12","abstract":"Nirvana Nursimulu's (University of Toronto, Expected 2021) research focuses on methods for computationally analyzing metabolic networks, with applications towards understanding pathogen growth in pursuit of drug development. Nirvana has examined the enzyme annotation problem, specifically focusing on producing methods that yield lower false positives than traditional similarity search metrics while considering full sequence diversity within enzyme classes. In addition, Nirvana has developed an automated pipeline for enzyme annotation and reconstruction of a metabolic model, focusing on increasing model coverage in order to yield more realistic simulations. In other work, Nirvana has also investigated more traditional microbiology across various pathogens.","authors":"Nirvana Nursimulu","slideslive_active_date":"","slideslive_id":"38931981","title":"Doctoral Symposium Talk: Nirvana Nursimulu"},{"UID":"20S13","abstract":"Rohit Bhattacharya's (Johns Hopkins University, Expected 2021) research focuses on the development of causal methods that correct for understudied but ubiquitous sources of bias that arise during the course of data analyses, including data dependence, non-ignorable missingness, and model misspecification, in the study of infectious diseases. Rohit approaches these problems by developing novel graphical modeling techniques that can detect and correct for such sources of bias while providing the investigator with clear and interpretable representations of the underlying data dependence or missingness process. In dealing with model misspecification, Rohit has recently developed algorithms that yield doubly robust and efficient semi-parametric estimators for a wide class of causal graphical models, despite the presence of unmeasured confounders. In other work, Rohit has performed several investigations in oncology applications.","authors":"Rohit Bhattacharya","slideslive_active_date":"","slideslive_id":"38931983","title":"Doctoral Symposium Talk: Rohit Bhattacharya"},{"UID":"20S14","abstract":"Kaspar M\u00e4rtens's (University of Oxford, Expected 2020) research focuses on enabling feature-level interpretability in non-linear latent variable models via a synthesis of statistical and machine learning techniques. In particular, Kaspar designs novel latent variable, non-linear dimensionality reduction models that allow for feature-level interpretability, focusing primarily on gaussian process latent variable models (GPLVMs) and variational autoencoders (VAEs), specifically augmenting these models with ideas from classical statistics, such as the functional analysis of variance (ANOVA) decomposition or probabilistic clustering algorithms. The results of these works are a class of models for flexible non-linear dimensionality reduction together with explainability, providing a mechanism to gain insights into what the model has learnt in terms of the observed features. In other work, Kaspar has examined genomic problems and applications of MCMC sampling.","authors":"Kaspar M\u00e4rtens","slideslive_active_date":"","slideslive_id":"38931984","title":"Doctoral Symposium Talk: Kaspar M\u00e4rtens"},{"UID":"20S15","abstract":"Luis Oala's (Fraunhofer Heinrich Hertz Institute, Expected 2021) research focuses on gaining a better understanding about the vulnerabilities of deep neural networks and finding tests to make these vulnerabilities visible, primarily through the lens of uncertainty quantification. Together with his research group, Luis has developed an effective and modular alarm system for image reconstruction DNNs. The alarm system, called Interval Neural Networks, allows for high-resolution error heatmaps during inference for use cases such as CT image reconstruction. As co-chair of the Working Group on Data and AI Solution Assessment Methods in the ITU/WHO Focus Group on AI4H (FG-AI4H), he also leads a group of interdisciplinary experts working towards a standardized assessment framework for the evaluation of health AIs","authors":"Luis Oala","slideslive_active_date":"","slideslive_id":"38931985","title":"Doctoral Symposium Talk: Luis Oala"}],"tutorials":[{"UID":"20T01","abstract":"Survival analysis is used for predicting time-to-event outcomes, such as how long a patient will stay in the hospital, or when the recurrence of a tumor will likely happen. This tutorial aims to go over the basics of survival analysis, how it is used in healthcare, and some of its recent methodological advances from the ML community. We will also discuss open challenges. NOTE: This tutorial has a corresponding notebook: <a href=\"https://sites.google.com/view/chil-survival\" target=\"_blank\">https://sites.google.com/view/chil-survival</a>.","authors":"George H. Chen|Jeremy C. Weiss","bio":"","rocketchat_id":"","slideslive_active_date":"","slideslive_id":"38931962","title":"A Tour of Survival Analysis, from Classical to Modern"},{"UID":"20T02","abstract":"In this tutorial, we will describe population and public health and their essential role in a comprehensive strategy to improve health. We will illustrate state of the art data and modeling approaches in population and public health. In doing so, we will identify overlaps with and open questions relevant to machine learning, causal inference and fairness.","authors":"Vishwali Mhasawade|Yuan Zhao|Rumi Chunara","bio":"","rocketchat_id":"","slideslive_active_date":"","slideslive_id":"38931964","title":"Population and public health: challenges and opportunities"},{"UID":"20T03","abstract":"With today's publicly available, de-identified clinical datasets, it is possible to ask questions  like, \u201cCan an algorithm read an electrocardiogram as well as a cardiologist can?\u201d However, other kinds of questions like, \u201cDoes this ECG relate to a later cardiac arrest?\u201d can\u2019t be answered with the limited public data available to us today. Research using private datasets gives us reason to be optimistic, but progress will be slow unless suitable de-identified datasets become open, allowing researchers to efficiently collaborate and compete. Learn about an effort underway at the University of Chicago, led by Ziad Obermeyer, Sendhil Mullainathan, and their team, to provide a secure and public \u201cImageNet for clinical data\u201d that balances the concerns of patients, healthcare institutions, and researchers.","authors":"Ziad Obermeyer|Katy Haynes|Amy Pitelka|Josh Risley|Katie Lin","bio":"","rocketchat_id":"","slideslive_active_date":"","slideslive_id":"38931961","title":"Public Health Datasets for Deep Learning: Challenges and Opportunities"},{"UID":"20T04","abstract":"This tutorial will be styled as a graduate lecture about medical imaging with deep learning. This will cover the background of popular medical image domains (chest X-ray and histology) as well as methods to tackle multi-modality/view, segmentation, and counting tasks. These methods will be covered in terms of architecture and objective function design. Also, a discussion about incorrect feature attribution and approaches to mitigate the issue. Prerequisites: basic knowledge of computer vision (CNNs) and machine learning (regression, gradient descent).","authors":"Joseph Paul Cohen","bio":"","rocketchat_id":"","slideslive_active_date":"","slideslive_id":"38931963","title":"State of the Art Deep Learning in Medical Imaging"},{"UID":"20T05","abstract":"Despite a wealth of data, only a small fraction of decisions in critical care are evidence based. In this tutorial we will start with the conception of an idea, solidify the hypothesis, operationalize the concepts involved, and execute the study in a reproducible and communicable fashion. We will run our study on MIMIC-IV, an update to MIMIC-III, and cover some of the exciting additions in the new database. This tutorial will be interactive and result in a study performed end-to-end in a Jupyter notebook. Technical expertise is not required, as we will form groups based on skill level.","authors":"Alistair Johnson","bio":"","rocketchat_id":"","slideslive_active_date":"","slideslive_id":"38931965","title":"Analyzing critical care data, from speculation to publication, starring MIMIC-IV (Part 1)"},{"UID":"20T06","abstract":"Despite a wealth of data, only a small fraction of decisions in critical care are evidence based. In this tutorial we will start with the conception of an idea, solidify the hypothesis, operationalize the concepts involved, and execute the study in a reproducible and communicable fashion. We will run our study on MIMIC-IV, an update to MIMIC-III, and cover some of the exciting additions in the new database. This tutorial will be interactive and result in a study performed end-to-end in a Jupyter notebook. Technical expertise is not required, as we will form groups based on skill level.","authors":"Alistair Johnson","bio":"","rocketchat_id":"","slideslive_active_date":"","slideslive_id":"38932058","title":"Analyzing critical care data, from speculation to publication, starring MIMIC-IV (Part 2)"}],"workshops":[{"UID":"20W01","abstract":"Small datasets form a significant portion of releasable data in high sensitivity domains such as healthcare. But, providing differential privacy for small dataset release is a hard task, where current state-of-the-art methods suffer from severe utility loss. As a solution, we propose DPRP (Differentially Private Data Release via Random Projections), a reconstruction based approach for releasing differentially private small datasets. DPRP has several key advantages over the state-of-the-art. Using seven diverse real-life clinical datasets, we show that DPRP outperforms the current state-of-the-art on a variety of tasks, under varying conditions, and for all privacy budgets.","authors":"Lovedeep Gondara|Ke Wang","slideslive_id":"38931935","title":"Differentially Private \"Small\" Dataset Release Using Random Projections"},{"UID":"20W03","abstract":"Reinforcement Learning (RL) has recently been applied to several problems in healthcare, with a particular focus in offline learning in observational data. RL relies on the use of latent states that embed sequential observations in such a way that the embedding is sufficient to approximately predict the next observation. but the appropriate construction of such states in healthcare settings is an open question, as the variation in steady-state human physiology is poorly-understood. In this work, we evaluate several information encoding schemes for offline RL using data from electronic health records (EHR). We use observations from septic patients in the MIMIC-III intensive care unit dataset, and evaluate the predictive performance of four embedding approaches in two tasks: predicting the next observation, and predicting a ``k-step'' look ahead or roll out. Our experiments highlight that the best performing state representation learning approaches utilize higher dimension recurrent neural architectures, and demonstrate that incorporating additional context with the state representation when predicting the next observation.","authors":"Taylor Killian|Jayakumar Subramanian|Mehdi Fatemi|Marzyeh Ghassemi","slideslive_id":"38931937","title":"Learning Representations for Prediction of Next Patient State"},{"UID":"20W04","abstract":"Capturing the inter-dependencies among multiple types of clinically-critical events is critical not only to accurate future event prediction, but also to better treatment planning. In this work, we propose a deep latent state-space generative model to capture the interactions among different types of correlated clinical events (e.g., kidney failure, mortality) by explicitly modeling the temporal dynamics of patients' latent states. Based on these learned patient states, we further develop a new general discrete-time formulation of the hazard rate function to estimate the survival distribution of patients with significantly improved accuracy. Extensive evaluations over real EMR data show that our proposed model compares favorably to various state-of-the-art baselines. Further our method also uncovers meaningful insights about the latent correlation among mortality and different types of organ failures.","authors":"Yuan Xue|Denny Zhou|Nan Du|Andrew M. Dai|Zhen Xu|Kun Zhang|Claire Cui","slideslive_id":"38931938","title":"Deep State-Space Generative Model For Correlated Time-to-Event Predictions"},{"UID":"20W05","abstract":"Survival function estimation is used in many disciplines, but it is most common in medical analytics in the form of the Kaplan-Meier estimator. Sensitive data (patient records) is used in the estimation without any explicit control on the information leakage, which is a significant privacy concern. We propose a first differentially private estimator of the survival function and show that it can be easily extended to provide differentially private confidence intervals and test statistics without spending any extra privacy budget. We further provide extensions for differentially private estimation of the competing risk cumulative incidence function, Nelson-Aalen's estimator for the hazard function, etc. Using eleven real-life clinical datasets, we provide empirical evidence that our proposed method provides good utility while simultaneously providing strong privacy guarantees.","authors":"Lovedeep Gondara|Ke Wang","slideslive_id":"38931939","title":"Differentially Private Survival Function Estimation"},{"UID":"20W07","abstract":"As machine learning has become increasingly applied to medical imaging data, noise in training labels has emerged as an important challenge. Variability in diagnosis of medical images is well established; in addition, variability in training and attention to task among medical labelers may exacerbate this issue. Methods for identifying and mitigating the impact of low quality labels have been studied, but are not well characterized in medical imaging tasks. For instance, Noisy Cross-Validation splits the training data into halves, and has been shown to identify low-quality labels in computer vision tasks; but it has not been applied to medical imaging tasks specifically. In addition, there may be concerns around label imbalance for medical image sets, where relevant pathology may be rare. In this work we introduce Stratified Noisy Cross-Validation (SNCV), an extension of noisy cross validation. SNCV allows us to measure confidence in model prediction and assign a quality score to each example; supports label stratification to handle class imbalance; and identifies likely low-quality labels to analyse the causes. In contrast to noisy cross-validation, sample selection for SNCV occurs after training two models, not during training, which simplifies application of the method. We assess performance of SNCV on diagnosis of glaucoma suspect risk (GSR) from retinal fundus photographs, a clinically important yet nuanced labeling task. Using training data from a previously-published deep learning model, we compute a continuous quality score (QS) for each training example. We relabel 1,277 low-QS examples using a trained glaucoma specialist; the new labels agree with the SNCV prediction over the initial label >85% of the time, indicating that low-QS examples appear mostly reflect labeler erors. We then quantify the impact of training with only high-QS labels, showing that strong model performance may be obtained with many fewer examples. By applying the method to randomly sub-sampled training dataset, we show that our method can reduce labelling burden by approximately 50% while achieving model performance non-inferior to using the full dataset on multiple held-out test sets.","authors":"Joy Hsu|Sonia Phene|Akinori Mitani|Jieying Luo|Naama Hammel|Jonathan Krause|Rory Sayres","slideslive_id":"38931941","title":"Improving medical annotation quality to decrease labeling burden using stratified noisy cross-validation"},{"UID":"20W08","abstract":"Modeling disease progression is an active area of research. Many computational methods for progression modeling have been developed but mostly at population levels. In this paper, we formulate a personalized disease progression modeling problem as a multi-task regression problem where the estimation of progression scores at different time points is defined as a learning task. We introduce a  Personalized Progression Modeling (PPM) scheme as a novel way to estimate personalized trajectories of disease by jointly discovering clusters of similar patients while estimating disease progression scores. The approach is formulated as an optimization problem that can be solved using existing optimization techniques. We present efficient algorithms for the PPM scheme, together with experimental results on both synthetic and real world healthcare data proving its analytical efficacy over other 4 baseline methods representing the current state of the art. On synthetic data, we showed that our algorithm achieves over 40% accuracy improvement over all the baselines. On the healthcare application PPM has a 4% accuracy improvement on average over the state-of-the-art baseline in predicting the viral infection progression. These results highlight significant modeling performance gains obtained with PPM.","authors":"Mohamed Ghalwash|Daby Sow","slideslive_id":"38931942","title":"A Multi-Task Learning Approach to Personalized Progression Modeling"},{"UID":"20W09","abstract":"Clinical notes in electronic health records contain highly heterogeneous writing styles, including non-standard terminology or abbreviations. Using these notes in predictive modeling has traditionally required preprocessing (e.g. taking frequent terms or topic modeling) that removes much of the richness of the source data. We propose a pretrained hierarchical recurrent neural network model that parses minimally processed clinical notes in an intuitive fashion, and show that it improves performance for discharge diagnosis classification tasks on the Medical Information Mart for Intensive Care III (MIMIC-III) dataset, compared to models that conduct no pretraining or that treat the notes as an unordered collection of terms. We also apply an attribution technique to examples to identify the words that the model uses to make its prediction, and show the importance of the words\u2019 nearby context.","authors":"Jonas Kemp|Alvin Rajkomar|Andrew M. Dai","slideslive_id":"38931943","title":"Improved Patient Classification with Hierarchical Language Model Pretraining over Clinical Notes"},{"UID":"20W10","abstract":"Industrial equipment, devices and patients typically undergo change from a healthy state to an unhealthy state. We develop a novel approach to detect unhealthy entities and also discover the time of change to enable deeper investigation into the cause for change. In the absence of an engineering or medical intervention, health degradation only happens in one direction --- healthy to unhealthy. Our transductive learning framework leverages this chronology of observations for learning a superior model with minimal supervision. Temporal Transduction is achieved by incorporating chronological constraints in the conventional max-margin classifier --- Support Vector Machines (SVM). We utilize stochastic gradient descent to solve the resulting optimization problem. Our experiments on publicly available benchmark datasets demonstrate the effectiveness of our approach in accurately detecting unhealthy entities with less supervision as compared to other strong baselines --- conventional and transductive SVM.","authors":"Abhay Harpale","slideslive_id":"38931944","title":"Health change detection using temporal transductive learning"},{"UID":"20W11","abstract":"In many Machine Learning applications, it is important to reduce the set of features used in training. This is especially important when different attributes have different acquisition costs, e.g., various blood tests. Cost-sensitive feature selection methods aim to select a subset of attributes that yields a performant Machine Learning model while keeping the total cost low. In this paper, we propose a Bayesian Optimization approach to this task. We explore the different subsets of available features by optimizing an evaluation function that weights the model's performance and total feature cost. We evaluate the proposed method on different UCI datasets, as well as a real-life one, and compare it to diverse feature selection approaches. Our results demonstrate that the Bayesian optimization cost-sensitive feature selection (BOCFS) can select a low-cost subset of informative features, therefore generating highly effective classifiers, and achieving state-of-the-art performance in some datasets.","authors":"Lucca G. Zenobio|Thiago N. C. Cardoso|Andrea Kauffmann|Augusto Antunes","slideslive_id":"38931945","title":"Cost-Sensitive Feature Selection Using Bayesian Optimization"},{"UID":"20W12","abstract":"With the increase in popularity of deep learning models for natural language processing (NLP) tasks in the field of Pharmacovigilance, more specifically for the identification of Adverse Drug Reactions (ADRs), there is an inherent need for large-scale social-media datasets aimed at such tasks. With most researchers allocating large amounts of time to crawl Twitter or buying expensive pre-curated datasets, then manually annotating by humans, these approaches do not scale well as more and more data keeps flowing in Twitter. In this work we re-purpose a publicly available archived dataset of more than 9.4 billion Tweets with the objective of creating a very large dataset of drug usage-related tweets. Using existing manually curated datasets from the literature, we then validate our filtered tweets for relevance using machine learning methods, with the end result of a publicly available dataset of 1,181,993 million tweets for public use. We provide all code and detailed procedure on how to extract this dataset and the selected tweet ids for researchers to use.","authors":"Ramya Tekumalla|Juan M Banda","slideslive_id":"38931946","title":"A large-scale Twitter dataset for drug safety applications mined from publicly existing resources"},{"UID":"20W13","abstract":"Clinical notes contain information about patients beyond structured data such as lab values or medications. However, clinical notes have been underused relative to structured data, because notes are high-dimensional and sparse. We aim to develop and evaluate a continuous representation of clinical notes. Given this representation, our goal is to predict 30-day hospital readmission at various timepoints of admission, including early stages and at discharge. We apply bidirectional encoder representations from transformers (BERT) to clinical text. Publicly-released BERT parameters are trained on standard corpora such as Wikipedia and BookCorpus, which differ from clinical text. We therefore pre-train BERT using clinical notes and fine-tune the network for the task of predicting hospital readmission. This defines ClinicalBERT. ClinicalBERT uncovers high-quality relationships between medical concepts, as judged by physicians. ClinicalBERT outperforms various baselines on 30-day hospital readmission prediction using both discharge summaries and the first few days of notes in the intensive care unit on various clinically-motivated metrics. The attention weights of ClinicalBERT can also be used to interpret predictions. To facilitate research, we open-source model parameters, and scripts for training and evaluation. ClinicalBERT is a flexible framework to represent clinical notes. It improves on previous clinical text processing methods and with little engineering can be adapted to other clinical predictive tasks.","authors":"Kexin Huang|Jaan Altosaar|Rajesh Ranganath","slideslive_id":"38931947","title":"ClinicalBERT: Modeling Clinical Notes and Predicting Hospital Readmission"},{"UID":"20W14","abstract":"Problem lists are intended to provide clinicians with a relevant summary of patient medical issues and are embedded in many electronic health record systems. Despite their importance, problem lists are often cluttered with resolved or currently irrelevant conditions. In this work, we develop a novel end-to-end framework to first extract problem lists from clinical notes and subsequently use the extracted problems to predict patient outcomes. This framework is both more performant and more interpretable than existing models used within the domain, achieving an AU-ROC of 0.710 for bounceback readmission and 0.869 for in-hospital mortality occurring after ICU discharge. We identify risk factors for both readmission and mortality outcomes and demonstrate that it can be used to develop dynamic problem lists that present clinical problems along with their quantitative importance. This allows clinicians to both easily identify the relevant problems and gain insight into the factors driving the model\u2019s prediction.","authors":"Justin Lovelace|Nathan Hurley|Adrian Haimovich|Bobak Mortazavi","slideslive_id":"38931948","title":"Mining Dynamic Problem Lists from Clinical Notes for the Interpretable Prediction of Adverse Outcomes"},{"UID":"20W15","abstract":"Deep learning is increasingly common in healthcare, yet transfer learning for physiological signals (e.g., temperature, heart rate, etc.) is under-explored. Here, we present a straightforward, yet performant framework for transferring knowledge about physiological signals. Our framework is called PHASE (\\underline{PH}ysiologic\\underline{A}l \\underline{S}ignal \\underline{E}mbeddings). It i) learns deep embeddings of physiological signals and ii) predicts adverse outcomes based on the embeddings. PHASE is the first instance of deep transfer learning in a cross-hospital, cross-department setting for physiological signals. We show that PHASE's per-signal (one for each signal) LSTM embedding functions confer a number of benefits including improved performance, successful transference between hospitals, and lower computational cost.","authors":"Hugh Chen|Scott Lundberg|Gabe Erion|Jerry H. Kim|Su-In Lee","slideslive_id":"38931949","title":"Deep Transfer Learning for Physiological Signals"},{"UID":"20W16","abstract":"Machine-learned diagnosis models have shown promise as medical aides but are trained under a closed-set assumption, i.e. that models will only encounter conditions on which they have been trained. However, it is practically infeasible to obtain sufficient training data for every human condition, and once deployed such models will invariably face previously unseen conditions. We frame machine-learned diagnosis as an open-set learning problem, and study how state-of-the-art approaches compare. Further, we extend our study to a setting where training data is distributed across several healthcare sites that do not allow data pooling, and experiment with different strategies of building open-set diagnostic ensembles. Across both settings, we observe consistent gains from explicitly modeling unseen conditions, but find the optimal training strategy to vary across settings.","authors":"Viraj Prabhu|Anitha Kannan|Geoffrey J. Tso|Namit Katariya|Manish Chablani|David Sontag|Xavier Amatriain","slideslive_id":"38931950","title":"Open Set Medical Diagnosis"},{"UID":"20W17","abstract":"This paper aims to evaluate the suitability of current deep learning methods for clinical workflow especially by focusing on dermatology. Although deep learning methods have been attempted to  get dermatologist level accuracy in several individual conditions, it has not been rigorously tested for common clinical complaints. Most projects involve data acquired in well-controlled laboratory  conditions. This may not reflect regular clinical evaluation where corresponding image quality is not always ideal. We test the robustness of deep learning methods by simulating non-ideal characteristics on user submitted images of ten classes of diseases. Assessing via imitated  conditions, we have found the overall accuracy to drop and individual predictions change significantly in many cases despite of robust training.","authors":"Sourav Mishra|Subhajit Chaudhury|Hideaki Imaizumi|Toshihiko Yamasaki","slideslive_id":"38931951","title":"Assessing Robustness of Deep Learning Methods in Dermatological Workflow"},{"UID":"20W20","abstract":"Sentiment analysis is a well-researched field of machine learning and natural language processing generally concerned with determining the degree of positive or negative polarity in free text. Traditionally, such methods have focused on analyzing user opinions directed towards external entities such as products, news, or movies. However, less attention has been paid towards understanding the sentiment of human emotion in the form of internalized thoughts and expressions of self-reflection. Given the rise of public social media platforms and private online therapy services, the opportunity for designing accurate tools to quantify emotional states in is at an all-time high. Based upon findings in psychological research, in this work we propose a new type of sentiment analysis task more appropriate for assessing the valence of human emotion. Rather than assessing text on a single polarity axis ranging from positive to negative, we analyze self-expressive thoughts using a two-dimensional assignment scheme with four sentiment categories: positive, negative, both positive and negative, and neither positive nor negative. This work details the collection of a novel annotated dataset of real-world mental health therapy logs and compares several machine learning methodologies for the accurate classification of emotional valence. We found superior performance using deep transfer learning approaches, and in particular, best results were obtained using the recent breakthrough method of BERT (Bidirectional Encoder Representations from Transformers). Based on these results, it is clear that transfer learning has the potential for greatly improving the accuracy of classifiers in the mental health domain, where labeled data is often scarce. Additionally, we argue that representing emotional sentiment on decoupled valence axes via four classification labels is an appropriate modification of traditional sentiment analysis for mental health tasks.","authors":"Benjamin Shickel|Martin Heesacker|Sherry Benton|Parisa Rashidi","slideslive_id":"38931954","title":"Automated Emotional Valence Prediction in Mental Health Text via Deep Transfer Learning"},{"UID":"20W21","abstract":"Electronic Health Records (EHRs) are commonly used by the machine learning community for research on problems specifically related to health care and medicine. EHRs have the advantages that they can be easily distributed and contain many features useful for e.g. classification problems. What makes EHR data sets different from typical machine learning data sets is that they are often very sparse, due to their high dimensionality, and often contain heterogeneous data types. Furthermore, the data sets deal with sensitive information, which limits the distribution of any models learned using them, due to privacy concerns. In this work, we explore using Generative Adversarial Networks to generate synthetic, heterogeneous EHRs with the goal of using these synthetic records in place of existing data sets. We will further explore applying differential privacy (DP) preserving optimization in order to produce differentially private synthetic EHR data sets, which provide rigorous privacy guarantees, and are therefore more easily shareable. The performance (measured by AUROC, AUPRC and accuracy) of our model's synthetic, heterogeneous data is very close to the original data set (within 6.4%) for the non-DP model when tested in a binary classification task. Although incurring a 20% performance penalty, the DP synthetic data is still useful for machine learning tasks. We additionally perform a sub-population analysis and find that our model does not introduce any bias into the synthetic EHR data compared to the baseline in either male/female populations, or the 0-18, 19-50 and 51+ age groups in terms of classification performance.","authors":"Kieran Chin-Cheong|Thomas M. Sutter|Julia E. Vogt","slideslive_id":"38931955","title":"Generation of Differentially Private Heterogeneous Synthetic Electronic Health Records using GANs"},{"UID":"20W22","abstract":"Intensive Care Unit Electronic Health Records (ICU EHRs) store multimodal data about patients including clinical notes, sparse and irregularly sampled physiological time series, lab results, and more. To date, most methods designed to learn predictive models from ICU EHR data have focused on a single modality. In this paper, we leverage the recently proposed interpolation-prediction deep learning architecture as a basis for exploring how physiological time series data and clinical notes can be integrated into a unified mortality prediction model. We study both early and late fusion approaches, and demonstrate how the relative predictive value of clinical text and physiological data change over time. Our results show that a late fusion approach can provide a statistically significant improvement in mortality prediction performance over using individual modalities in isolation.","authors":"Satya Narayan Shukla|Benjamin Marlin","slideslive_id":"38931956","title":"Integrating Physiological Time Series and Clinical Notes with Deep Learning for Improved ICU Mortality Prediction"},{"UID":"20W23","abstract":"Although there have been several recent advances in the application of deep learning algorithms to chest x-ray interpretation, we identify three major challenges for the translation of chest x-ray algorithms to the clinical setting. We examine the performance of the top 10 performing models on the CheXpert challenge leaderboard on three tasks: (1) TB detection, (2) pathology detection on photos of chest x-rays, and (3) pathology detection on data from an external institution. First, we find that the top 10 chest x-ray models on the CheXpert competition achieve an average AUC of 0.851 on the task of detecting TB on two public TB datasets without fine-tuning or including the TB labels in training data. Second, we find that the average performance of the models on photos of x-rays (AUC = 0.916) is similar to their performance on the original chest x-ray images (AUC = 0.924). Third, we find that the models tested on an external dataset either perform comparably to or exceed the average performance of radiologists. We believe that our investigation will inform rapid translation of deep learning algorithms to safe and effective clinical decision support tools that can be validated prospectively with large impact studies and clinical trials.","authors":"Pranav Rajpurkar|Anirudh Joshi|Phil Chen|Anuj Pareek|Amir Kiani|Matthew Lungren|Andrew Ng|Jeremy Irvin","slideslive_id":"38931957","title":"CheXpedition: Investigating Generalization Challenges for Translation of Chest X-Ray Algorithms to the Clinical Setting"},{"UID":"20W24","abstract":"Documenting patients' interactions with health providers and institutions requires summarizing highly complex data. Medical coding reduces the dimensionality of this problem to a set of manually assigned codes that are used to bill, track patient health, and summarize a patient encounter. Incorrect coding, however, can lead to significant financial, legal, and health costs to clinics and patients. To address this, we build several deep learning models -- including transfer learning of state-of-the-art BERT models -- to predict medical codes on a novel dataset of 39,000 patient encounters. We also show through several labeling experiments that model performance is robust to subjectivity in the labels, and find that our models outperform a clinic's coding when judged against charts corrected and relabeled by an expert.","authors":"Mehmet Seflek|Wesam Elshamy|Abboud Chaballout|Ali Madani","slideslive_id":"38931958","title":"Automated Medical Coding using BERT: Benchmarking Deep Learning in the Face of Subjective Labels"},{"UID":"20W25","abstract":"Representation learning is a commonly touted goal in machine learning for healthcare, and for good reason. If we could learn a numerical encoding of clinical data which is reflective of underlying physiological similarity, this would have significant benefits both in research and application. However, many works pursuing representation learning systems evaluate only according to traditional, single-task performance metrics, and fail to assess whether or not the representations they produce actually contain generalizable signals capturing this underlying notion of similarity. In this work, we design an evaluation procedure specifically for representation learning systems, and use it to analyze the value of large-scale multi-task representation learners. We find mixed results, with multi-task representations being commonly helpful across a battery of prediction tasks and models, even while ensemble performance is often improvement by removing tasks from the trained ensemble and learned representations demonstrate no ability to cluster.","authors":"Matthew McDermott|Bret Nestor|Wancong Zhang|Peter Szolovits|Anna Goldenberg|Marzyeh Ghassemi","slideslive_id":"38931959","title":"Distracted Multi-task Learning: Addressing Negative Transfer with Fine-tuning on EHR Time-series Data"},{"UID":"20W26","abstract":"In the last few years, the FDA has begun to recognize De Novo pathways (new approval processes) for approving AI as medical devices. A major concern with this is that the review process does not adequately test for biases in these models. There are many ways in which biases can arise in data, including during data collection, training, and model deployment. In this paper, we adopt a framework for categorizing the types of bias in datasets in a fine-grained way, which enables informed, targeted interventions for each issue appropriately. From there, we propose policy recommendations to the FDA and NIH to promote the deployment of more equitable AI diagnostic systems.","authors":"Julie R Vaughn|Avital Baral|Mayukha Vadari|William Boag","slideslive_id":"38931960","title":"Dataset Bias in Diagnostic AI systems: Guidelines for Dataset Collection and Usage"},{"UID":"20W27","abstract":"Electronic records contain sequences of events, some of which take place all at once in a single visit, and others that are dispersed over multiple visits, each with a different timestamp. We postulate that fine temporal detail, e.g., whether a series of blood tests  are completed at once or in rapid succession should not alter predictions based on this data.  Motivated by this intuition, we propose models for analyzing sequences of multivariate clinical time series data that are invariant to this temporal clustering. We propose an efficient data augmentation technique that exploits the postulated temporal-clustering invariance to regularize deep neural networks optimized for several clinical prediction tasks.  We introduce two techniques to temporally coarsen (downsample) irregular time series:  (i) grouping the data points based on regularly-spaced timestamps;  and (ii) clustering them, yielding irregularly-paced timestamps.  Moreover, we propose a MultiResolution network with Shared Weights (MRSW), improving predictive accuracy by combining predictions  based on inputs sequences transformed by different coarsening operators. Our experiments show that MRSW improves the mAP on the benchmark mortality prediction task from 51.53% to 53.92%.","authors":"Mohammad Taha Bahadori|Zachary Lipton","slideslive_id":"38931987","title":"Temporal-Clustering Invariance in Irregular Healthcare Time Series"},{"UID":"20W28","abstract":"In survival analysis, deep learning approaches have recently been proposed for estimating an individual's probability of survival over some time horizon. Such approaches can capture complex non-linear relationships, without relying on restrictive assumptions regarding the specific form of the relationship between an individual's characteristics and their underlying survival process. To date, however, these methods have focused primarily on optimizing discriminative performance, and have ignored model calibration. Well-calibrated survival curves present realistic and meaningful probabilistic estimates of the true underlying survival process for an individual. However, due to the lack of ground-truth regarding the underlying stochastic process of survival for an individual, optimizing for and measuring calibration in survival analysis is an inherently difficult task. In this work, we i) propose a new loss function, for training deep nonparametric survival analysis models, that maximizes discriminative performance, subject to good calibration, and ii) present a calibration metric for survival analysis that facilitates model comparison. Through experiments on two publicly available clinical datasets, we show that our proposed approach achieves the same discriminative performance as state-of-the-art methods, while leading to over a 60% reduction in calibration error.","authors":"Fahad Kamran|Jenna Wiens","slideslive_id":"38931988","title":"Calibrated Deep Nonparametric Survival Analysis"}]},"2021":{"highlights":"<div class=\"page-content live text-center\">\n<!-- Slides Live-->\n<div class=\"row p-3\">\n    <div class=\"col-12 bd-content\">\n    <h3>Day 1 - April 8th</h3>\n    </div>\n</div>\n<div id=\"slideslive-embed\" class=\"col-md-12 col-xs-12 my-auto p-2 hide\" data-activedate=\"2021-04-14T23:59:00.00\">\n  <div id=\"presentation-embed-38954749\" class=\"slp my-auto\"></div>\n  <script src='https://slideslive.com/embed_presentation.js'></script>\n  <script>\n    embed = new SlidesLiveEmbed(\"presentation-embed-38954749\", {\n        presentationId: \"38954749\",\n        autoPlay: false, // change to true to autoplay the embedded presentation\n        verticalEnabled: true,\n        verticalWhenWidthLte: 480,\n    });\n  </script>\n</div>\n<div class=\"row p-3\">\n    <div class=\"col-12 bd-content\">\n    <h3>Day 2 - April 9th</h3>\n    </div>\n</div>\n<div id=\"slideslive-embed2\" class=\"col-md-12 col-xs-12 my-auto p-2 hide\" data-activedate=\"2021-04-14T23:59:00.00\">\n  <div id=\"presentation-embed-38954751\" class=\"slp my-auto\"></div>\n  <script>\n    embed = new SlidesLiveEmbed(\"presentation-embed-38954751\", {\n        presentationId: \"38954751\",\n        autoPlay: false, // change to true to autoplay the embedded presentation\n        verticalEnabled: true,\n        verticalWhenWidthLte: 480,\n    });\n  </script>\n</div>\n</div>\n\n### Governing Board\n\n###### **General Chair**\n- Dr. Marzyeh Ghassemi of University of Toronto and Vector Institute\n###### **Program Chairs**\n- Dr. Tristan Naumann of Microsoft Research Seattle\n- Dr. Emma Pierson of Stanford University and Microsoft Research\n###### **Proceedings Chairs**\n- Emily Alsentzer of Harvard University and MIT\n- Matthew McDermott of MIT\n- Dr. George Chen of Carnegie Mellon University\n###### **Track Chairs**\n- ###### **Models and Methods**\n    * Dr. Mike Hughes of Tufts University\n    * Dr. Shalmali Joshi of Harvard University\n    * Dr. Rajesh Ranganath of New York University\n    * Dr. Rahul Krishnan of Microsoft Research, University of Toronto and Vector Institute\n- ###### **Applications and Practice**\n    * Dr. Andrew Beam of Harvard University\n    * Dr. Tom Pollard of MIT\n    * Dr. Bobak Mortazavi of Texas A&M University\n    * Dr. Uri Shalit of Technion - Israel Institute of Technology\n- ###### **Impact and Society**\n    * Dr. Alistair Johnson of The Hospital for Sick Children\n    * Dr. Rumi Chunara of New York University\n    * Dr. George Chen of Carnegie Mellon University\n###### **Communications Chairs**\n- Dr. Stephanie Hyland of Microsoft Research Cambridge\n- Dr. Sanja \u0160\u0107epanovi\u0107 of Bell Labs Cambridge\n- Dr. Sanmi Koyejo of University of Illinois at Urbana-Champaign and Google Research\n###### **Finance Chairs**\n- Dr. Joyce Ho of Emory University\n- Dr. Brett Beaulieu-Jones of Harvard Medical School\n###### **Tutorial Chairs**\n- Irene Chen of MIT\n- Dr. Jessica Gronsbell of University of Toronto\n###### **Virtual Chairs**\n- Dr. Stephanie Hyland of Microsoft Research Cambridge\n- Dr. Tom Pollard of MIT\n###### **Logistics Chair**\n- Tasmie Sarker of University of Toronto\n\n### Steering Committee\n\n- Dr. Yindalon Aphinyanaphongs of NYU\n- Dr. Leo Celi of MIT\n- Dr. Nigam Shah of Stanford University\n- Dr. Stephen Friend of Oxford University\n- Dr. Alan Karthikesalingam of Google Health UK\n- Dr. Ziad Obermeyer of University of California, Berkeley\n- Dr. Samantha Kleinberg of Stevens Institute of Technology\n- Dr. Anna Goldenberg of The Hospital for Sick Children Research Institute\n- Dr. Lucila Ohno-Machado of University of California, San Diego\n- Dr. Noemie Elhadad of Columbia University\n- Dr. Katherine Heller at Google Research\n- Dr. Laura Rosella of Dalla Lana School of Public Health, University of Toronto\n- Dr. Shakir Mohamed of DeepMind\n\n### Sponsors\nWe thank the Association for Computing Machinery (ACM) for sponsoring CHIL 2021, as well as the following organizations for supporting the event:\n\n- Google\n- Health[at]Scale\n- Layer6\n- Creative Destruction Lab\n- Vector Institute\n","proceedings":[{"UID":"21P01","abstract":"Electronic Health Records (EHR) are high-dimensional data with implicit connections among thousands of medical concepts. These connections, for instance, the co-occurrence of diseases and lab-disease correlations can be informative when only a subset of these variables is documented by the clinician. A feasible approach to improving the representation learning of EHR data is to associate relevant medical concepts and utilize these connections. Existing medical ontologies can be the reference for EHR structures, but they place numerous constraints on the data source. Recent progress on graph neural networks (GNN) enables end-to-end learning of topological structures for non-grid or non-sequential data. However, there are problems to be addressed on how to learn the medical graph adaptively and how to understand the effect of the medical graph on representation learning. In this paper, we propose a variationally regularized encoder-decoder graph network that achieves more robustness in graph structure learning by regularizing node representations. Our model outperforms the existing graph and non-graph based methods in various EHR predictive tasks based on both public data and real-world clinical data. Besides the improvements in empirical experiment performances, we provide an interpretation of the effect of variational regularization compared to standard graph neural network, using singular value analysis.","authors":"Weicheng Zhu (New York University) | Narges Razavian (NYU Grossman School of Medicine)","doi_link":"https://doi.org/10.1145/3450439.3451855","slideslive_active_date":"2021-04-14T23:59:00.00","slideslive_id":"38954722","title":"Variationally Regularized Graph-based Representation Learning for Electronic Health Records"},{"UID":"21P02","abstract":"Set classification is the task of predicting a single label from a set comprising multiple instances. The examples we consider are pathology slides represented by sets of patches and medical text represented by sets of word embeddings. State of the art methods, such as the transformers, typically use attention mechanisms to learn representations of set-data by modeling interactions between instances of the set. These methods, however, have complex heuristic architectures comprising multiple heads and layers. The complexity of attention architectures hampers their training when only a small number of labeled sets is available, as is often the case in medical applications. To address this problem, we present a kernel-based representation learning framework that associates between learning affinity kernels to learning representations from attention architectures. We show that learning a combination of the sum and the product of kernels is equivalent to learning representations from multi-head multi-layer attention architectures. From our framework, we devise a simplified attention architecture which we term \\emph{affinitention} (affinity-attention) nets. We demonstrate the application of affinitention nets to the classification of Set-Cifar10 dataset, thyroid malignancy prediction from pathology slides, as well as patient text message-triage. We show that affinitention nets provide competitive results compared to heuristic attention architectures and outperform other competing methods.","authors":"David Dov, Serge Assaad, Shijing Si, and Rui Wang (Duke University) | Hongteng Xu (Renmin University of China) | Shahar Ziv Kovalsky (UNC at Chapel Hill) | Jonathan Bell and Danielle Elliott Range (Duke University Hospital) | Jonathan Cohen (Kaplan Medical Center) | Ricardo Henao and Lawrence Carin (Duke University)","doi_link":"https://doi.org/10.1145/3450439.3451856","slideslive_active_date":"2021-04-14T23:59:00.00","slideslive_id":"38954723","title":"Affinitention Nets: Kernel Perspective on Attention Architectures for Set Classification with Applications to Medical Text and Images"},{"UID":"21P03","abstract":"Machine Learning, and in particular Federated Machine Learning, opens new perspectives in terms of medical research and patient care. Although Federated Machine Learning improves over centralized Machine Learning in terms of privacy, it does not provide provable privacy guarantees. Furthermore, Federated Machine Learning is quite expensive in term of bandwidth consumption as it requires participant nodes to regularly exchange large updates. This paper proposes a bandwidth-efficient privacy-preserving Federated Learning that provides theoretical privacy guarantees based on Differential Privacy. We experimentally evaluate our proposal for in-hospital mortality prediction using a real dataset, containing Electronic Health Records of about one million patients. Our results suggest that strong and provable patient-level privacy can be enforced at the expense of only a moderate loss of prediction accuracy.","authors":"Raouf Kerkouche (Privatics team, Univ. Grenoble Alpes, Inria, 38000 Grenoble, France) | Gergely \u00c1cs (Crysys Lab, BME-HIT) | Claude Castelluccia (Privatics team, Univ. Grenoble Alpes, Inria, 38000 Grenoble, France) | Pierre Genev\u00e8s (Tyrex team Univ. Grenoble Alpes, CNRS, Inria, Grenoble INP, LIG 38000 Grenoble, France)","doi_link":"https://doi.org/10.1145/3450439.3451859","slideslive_active_date":"2021-04-14T23:59:00.00","slideslive_id":"38954724","title":"Privacy-Preserving and Bandwidth-Efficient Federated Learning: An Application to In-Hospital Mortality Prediction"},{"UID":"21P04","abstract":"Recurrent Neural Networks (RNNs) are often used for sequential modeling of adverse outcomes in electronic health records (EHRs) due to their ability to encode past clinical states. These deep, recurrent architectures have displayed increased performance compared to other modeling approaches in a number of tasks, fueling the interest in deploying deep models in clinical settings. One of the key elements in ensuring safe model deployment and building user trust is model explainability. Testing with Concept Activation Vectors (TCAV) has recently been introduced as a way of providing human-understandable explanations by comparing high-level concepts to the network's gradients. While the technique has shown promising results in real-world imaging applications, it has not been applied to structured temporal inputs. To enable an application of TCAV to sequential predictions in the EHR, we propose an extension of the method to time series data. We evaluate the proposed approach on an open EHR benchmark from the intensive care unit, as well as synthetic data where we are able to better isolate individual effects.","authors":"Diana Mincu (Google Research) | Eric Loreaux (Google Health) | Shaobo Hou (DeepMind) | Sebastien Baur, Ivan Protsyuk, and Martin G Seneviratne (Google Health) | Anne Mottram and Nenad Tomasev (DeepMind) | Alan Karthikesalingam (Google Health) | Jessica Schrouff (Google Research)","doi_link":"https://doi.org/10.1145/3450439.3451858","slideslive_active_date":"2021-04-14T23:59:00.00","slideslive_id":"38954725","title":"Concept-based Model Explanations for Electronic Health Records"},{"UID":"21P05","abstract":"Sharing data is critical to generate large data sets required for the training of machine learning models. Trustworthy machine learning requires incentives, guarantees of data quality, and information privacy. Applying recent advancements in data valuation methods for machine learning can help to enable these. In this work, we analyze the suitability of three different data valuation methods for medical image classification tasks, specifically pleural effusion, on an extensive data set of chest x-ray scans. Our results reveal that a heuristic for calculating the Shapley valuation scheme based on a k-nearest neighbor classifier can successfully value large quantities of data instances. We also demonstrate possible applications for incentivizing data sharing, the efficient detection of mislabeled data, and summarizing data sets to exclude private information. Thereby, this work contributes to developing modern data infrastructures for trustworthy machine learning in health care.","authors":"Konstantin D Pandl, Fabian Feiland, Scott Thiebes, and Ali Sunyaev (Karlsruhe Institute of Technology)","doi_link":"https://doi.org/10.1145/3450439.3451861","slideslive_active_date":"2021-04-14T23:59:00.00","slideslive_id":"38954726","title":"Trustworthy Machine Learning for Health Care: Scalable Data Valuation with the Shapley Value"},{"UID":"21P06","abstract":"The pressure of ever-increasing patient demand and budget restrictions make hospital bed management a daily challenge for clinical staff. Most critical is the efficient allocation of resource-heavy Intensive Care Unit (ICU) beds to the patients who need life support. Central to solving this problem is knowing for how long the current set of ICU patients are likely to stay in the unit. In this work, we propose a new deep learning model based on the combination of temporal convolution and pointwise (1x1) convolution, to solve the length of stay prediction task on the eICU and MIMIC-IV critical care datasets. The model - which we refer to as Temporal Pointwise Convolution (TPC) - is specifically designed to mitigate common challenges with Electronic Health Records, such as skewness, irregular sampling and missing data. In doing so, we have achieved significant performance benefits of 18-68% (metric and dataset dependent) over the commonly used Long-Short Term Memory (LSTM) network, and the multi-head self-attention network known as the Transformer. By adding mortality prediction as a side-task, we can improve performance further still, resulting in a mean absolute deviation of 1.55 days (eICU) and 2.28 days (MIMIC-IV) on predicting remaining length of stay.","authors":"Emma Rocheteau and Pietro Li\u00f2 (University of Cambridge) | Stephanie Hyland (Microsoft Research)","doi_link":"https://doi.org/10.1145/3450439.3451860","slideslive_active_date":"2021-04-14T23:59:00.00","slideslive_id":"38954727","title":"Temporal Pointwise Convolutional Networks for Length of Stay Prediction in the Intensive Care Unit"},{"UID":"21P07","abstract":"Wearable devices such as smartwatches are becoming increasingly popular tools for objectively monitoring physical activity in free-living conditions. To date, research has primarily focused on the purely supervised task of human activity recognition, demonstrating limited success in inferring high-level health outcomes from low-level signals. Here, we present a novel _self-supervised_ representation learning method using activity and heart rate (HR) signals without semantic labels. With a deep neural network, we set HR responses as the _supervisory signal_ for the activity data, leveraging their underlying physiological relationship. In addition, we propose a custom quantile loss function that accounts for the long-tailed HR distribution present in the general population. We evaluate our model in the largest free-living combined-sensing dataset (comprising >280k hours of wrist accelerometer & wearable ECG data). Our contributions are two-fold: i) the pre-training task creates a model that can accurately forecast HR based only on cheap activity sensors, and ii) we leverage the information captured through this task by proposing a simple method to aggregate the learnt latent representations (embeddings) from the window-level to user-level. Notably, we show that the embeddings can generalize in various downstream tasks through transfer learning with linear classifiers, capturing physiologically meaningful, personalized information. For instance, they can be used to predict variables associated with individuals' health, fitness and demographic characteristics (AUC >70), outperforming unsupervised autoencoders and common bio-markers. Overall, we propose the first multimodal self-supervised method for behavioral and physiological data with implications for large-scale health and lifestyle monitoring. <br /><br /><strong>Code:</strong> <a href='https://github.com/sdimi/Step2heart' target='_blank' rel='noopener'>https://github.com/sdimi/Step2heart</a>","authors":"Dimitris Spathis, Ignacio Pozuelo, Soren Brage, Nicholas J. Wareham, and Cecilia Mascolo (University of Cambridge)","doi_link":"https://doi.org/10.1145/3450439.3451863","slideslive_active_date":"2021-04-14T23:59:00.00","slideslive_id":"38954728","title":"Self-supervised Transfer Learning of Physiological Representations from Free-living Wearable Data"},{"UID":"21P08","abstract":"In several crucial applications, domain knowledge is encoded by a system of ordinary differential equations (ODE), often stemming from underlying physical and biological processes. A motivating example is intensive care unit patients: the dynamics of vital physiological functions, such as the cardiovascular system with its associated variables (heart rate, cardiac contractility and output and vascular resistance) can be approximately described by a known system of ODEs. Typically, some of the ODE variables are directly observed (heart rate and blood pressure for example) while some are unobserved (cardiac contractility, output and vascular resistance), and in addition many other variables are observed but not modeled by the ODE, for example body temperature. Importantly, the unobserved ODE variables are ``known-unknowns'': We know they exist and their functional dynamics, but cannot measure them directly, nor do we know the function tying them to all observed measurements. As is often the case in medicine, and specifically the cardiovascular system, estimating these known-unknowns is highly valuable and they serve as targets for therapeutic manipulations. Under this scenario we wish to learn the parameters of the ODE generating each observed time-series, and extrapolate the future of the ODE variables and the observations. We address this task with a variational autoencoder incorporating the known ODE function, called GOKU-net for Generative ODE modeling with Known Unknowns. We first validate our method on videos of single and double pendulums with unknown length or mass; we then apply it to a model of the cardiovascular system. We show that modeling the known-unknowns allows us to successfully discover clinically meaningful unobserved system parameters, leads to much better extrapolation, and enables learning using much smaller training sets.","authors":"Ori Linial and Neta Ravid (Technion) | Danny Eytan (Technion, Rambam) | Uri Shalit (Technion)","doi_link":"https://doi.org/10.1145/3450439.3451866","slideslive_active_date":"2021-04-14T23:59:00.00","slideslive_id":"38954729","title":"Generative ODE Modeling with Known Unknowns"},{"UID":"21P09","abstract":"The impact of machine learning models on healthcare will depend on the degree of trust that healthcare professionals place in the predictions made by these models. In this paper, we present a method to provide people with clinical expertise with domain-relevant evidence about why a prediction should be trusted. We first design a probabilistic model that relates meaningful latent concepts to prediction targets and observed data. Inference of latent variables in this model corresponds to both making a prediction $\\textit{and}$ providing supporting evidence for that prediction. We present a two-step process to efficiently approximate inference: (i) estimating model parameters using variational learning, and (ii) approximating $\\textit{maximum a posteriori}$ estimation of latent variables in the model using a neural network trained with an objective derived from the probabilistic model. We demonstrate the method on the task of predicting mortality risk for cardiovascular patients. Specifically, using electrocardiogram and tabular data as input, we show that our approach provides appropriate domain-relevant supporting evidence for accurate predictions.","authors":"Aniruddh Raghu and John Guttag (Massachusetts Institute of Technology) | Katherine Young (Harvard Medical School) | Eugene Pomerantsev (Massachusetts General Hospital) | Adrian V. Dalca (Harvard Medical School & MIT) | Collin M. Stultz (Massachusetts Institute of Technology)","doi_link":"https://doi.org/10.1145/3450439.3451869","slideslive_active_date":"2021-04-14T23:59:00.00","slideslive_id":"38954730","title":"Learning to Predict with Supporting Evidence: Applications to Clinical Risk Prediction"},{"UID":"21P10","abstract":"Automatic extraction of medical conditions from free-text radiology reports is critical for supervising computer vision models to interpret medical images. In this work, we show that radiologists labeling reports significantly disagree with radiologists labeling corresponding chest X-ray images, which reduces the quality of report labels as proxies for image labels. We develop and evaluate methods to produce labels from radiology reports that have better agreement with radiologists labeling images. Our best performing method, called VisualCheXbert, uses a biomedically-pretrained BERT model to directly map from a radiology report to the image labels, with a supervisory signal determined by a computer vision model trained to detect medical conditions from chest X-ray images. We find that VisualCheXbert outperforms an approach using an existing radiology report labeler by an average F1 score of 0.14 (95% CI 0.12, 0.17). We also find that VisualCheXbert better agrees with radiologists labeling chest X-ray images than do radiologists labeling the corresponding radiology reports by an average F1 score across several medical conditions of between 0.12 (95% CI 0.09, 0.15) and 0.21 (95% CI 0.18, 0.24).","authors":"Saahil Jain and Akshay Smit (Stanford University) | Steven QH Truong, Chanh DT Nguyen, and Minh-Thanh Huynh (VinBrain) | Mudit Jain (unaffiliated) | Victoria A. Young, Andrew Y. Ng, Matthew P. Lungren, and Pranav Rajpurkar (Stanford University)","doi_link":"https://doi.org/10.1145/3450439.3451862","slideslive_active_date":"2021-04-14T23:59:00.00","slideslive_id":"38954731","title":"VisualCheXbert: Addressing the Discrepancy Between Radiology Report Labels and Image Labels"},{"UID":"21P11","abstract":"Deep learning methods for chest X-ray interpretation typically rely on pretrained models developed for ImageNet. This paradigm assumes that better ImageNet architectures perform better on chest X-ray tasks and that ImageNet-pretrained weights provide a performance boost over random initialization. In this work, we compare the transfer performance and parameter efficiency of 16 popular convolutional architectures on a large chest X-ray dataset (CheXpert) to investigate these assumptions. First, we find no relationship between ImageNet performance and CheXpert performance for both models without pretraining and models with pretraining. Second, we find that, for models without pretraining, the choice of model family influences performance more than size within a family for medical imaging tasks. Third, we observe that ImageNet pretraining yields a statistically significant boost in performance across architectures, with a higher boost for smaller architectures. Fourth, we examine whether ImageNet architectures are unnecessarily large for CheXpert by truncating final blocks from pretrained models, and find that we can make models 3.25x more parameter-efficient on average without a statistically significant drop in performance. Our work contributes new experimental evidence about the relation of ImageNet to chest x-ray interpretation performance.","authors":"Alexander Ke, William Ellsworth, Oishi Banerjee, Andrew Y. Ng, and Pranav Rajpurkar (Stanford University)","doi_link":"https://doi.org/10.1145/3450439.3451867","slideslive_active_date":"2021-04-14T23:59:00.00","slideslive_id":"38954732","title":"CheXtransfer: Performance and Parameter Efficiency of ImageNet Models for Chest X-Ray Interpretation"},{"UID":"21P12","abstract":"Recent advances in training deep learning models have demonstrated the potential to provide accurate chest X-ray interpretation and increase access to radiology expertise. However, poor generalization due to data distribution shifts in clinical settings is a key barrier to implementation. In this study, we measured the diagnostic performance for 8 different chest X-ray models when applied to (1) smartphone photos of chest X-rays and (2) external datasets without any finetuning. All models were developed by different groups and submitted to the CheXpert challenge, and re-applied to test datasets without further tuning. We found that (1) on photos of chest X-rays, all 8 models experienced a statistically significant drop in task performance, but only 3 performed significantly worse than radiologists on average, and (2) on the external set, none of the models performed statistically significantly worse than radiologists, and five models performed statistically significantly better than radiologists. Our results demonstrate that some chest X-ray models, under clinically relevant distribution shifts, were comparable to radiologists while other models were not. Future work should investigate aspects of model training procedures and dataset collection that influence generalization in the presence of data distribution shifts.","authors":"Pranav Rajpurkar, Anirudh Joshi, Anuj Pareek, Andrew Y. Ng, and Matthew P. Lungren (Stanford University)","doi_link":"https://doi.org/10.1145/3450439.3451876","slideslive_active_date":"2021-04-14T23:59:00.00","slideslive_id":"38954733","title":"CheXternal: Generalization of Deep Learning Models for Chest X-ray Interpretation to Photos of Chest X-rays and External Clinical Settings"},{"UID":"21P13","abstract":"Balanced representation learning methods have been applied successfully to counterfactual inference from observational data. However, approaches that account for survival outcomes are relatively limited. Survival data are frequently encountered across diverse medical applications, \\textit{i.e.}, drug development, risk profiling, and clinical trials, and such data are also relevant in fields like manufacturing (\\textit{e.g.}, for equipment monitoring). When the outcome of interest is a time-to-event, special precautions for handling censored events need to be taken, as ignoring censored outcomes may lead to biased estimates. We propose a theoretically grounded unified framework for counterfactual inference applicable to survival outcomes. Further, we formulate a nonparametric hazard ratio metric for evaluating average and individualized treatment effects. Experimental results on real-world and semi-synthetic datasets, the latter of which we introduce, demonstrate that the proposed approach significantly outperforms competitive alternatives in both survival-outcome prediction and treatment-effect estimation.","authors":"Paidamoyo Chapfuwa, Serge Assaad, Shuxi Zeng, Michael Pencina, Lawrence Carin, and Ricardo Henao (Duke University)","doi_link":"https://doi.org/10.1145/3450439.3451875","slideslive_active_date":"2021-04-14T23:59:00.00","slideslive_id":"38954734","title":"Enabling Counterfactual Survival Analysis with Balanced Representations"},{"UID":"21P14","abstract":"Generating a novel and optimized molecule with desired chemical properties is an essential part of the drug discovery process. Failure to meet one of the required properties can frequently lead to failure in a clinical test which is costly. In addition, optimizing these multiple properties is a challenging task because the optimization of one property is prone to changing other properties. In this paper, we pose this multi-property optimization problem as a sequence translation process and propose a new optimized molecule generator model based on the Transformer with two constraint networks: property prediction and similarity prediction. We further improve the model by incorporating score predictions from these constraint networks in a modified beam search algorithm. The experiments demonstrate that our proposed model outperforms state-of-the-art models by a significant margin for optimizing multiple properties simultaneously.","authors":"Bonggun Shin and Sungsoo Park (Deargen Inc.) | JinYeong Bak (SungKyunKwan University) | Joyce C. Ho (Emory University)","doi_link":"https://doi.org/10.1145/3450439.3451879","slideslive_active_date":"2021-04-14T23:59:00.00","slideslive_id":"38954735","title":"Controlled Molecule Generator for Optimizing Multiple Chemical Properties"},{"UID":"21P15","abstract":"There are large individual differences in physiological processes, making designing personalized health sensing algorithms challenging. Existing machine learning systems struggle to generalize well to unseen subjects or contexts and can often contain problematic biases. Video-based physiological measurement is not an exception. Therefore, learning personalized or customized models from a small number of unlabeled samples is very attractive as it would allow fast calibrations to improve generalization and help correct biases. In this paper, we present a novel meta-learning approach called MetaPhys for personalized video-based cardiac measurement. Our method uses only 18-seconds of video for customization and works effectively in both supervised and unsupervised manners. We evaluate our proposed approach on two benchmark datasets and demonstrate superior performance in cross-dataset evaluation with substantial reductions (42% to 44%) in errors compared with state-of-the-art approaches. We have also demonstrated our proposed method significantly helps reduce the bias in skin type.","authors":"Xin Liu and Ziheng Jiang (University of Washington) | Josh Fromm (OctoML) | Xuhai Xu and Shwetak Patel (University of Washington) | Daniel McDuff (Microsoft Research)","doi_link":"https://doi.org/10.1145/3450439.3451870","slideslive_active_date":"2021-04-14T23:59:00.00","slideslive_id":"38954736","title":"MetaPhys: Few-Shot Adaptation for Non-Contact Physiological Measurement"},{"UID":"21P16","abstract":"Machine learning algorithms in healthcare have the potential to continually learn from real-world data generated during healthcare delivery and adapt to dataset shifts. As such, regulatory bodies like the US FDA have begun discussions on how to autonomously approve modifications to algorithms. Current proposals evaluate algorithmic modifications via hypothesis testing. However, these methods are only able to define and control the online error rate if the data is stationary over time, which is unlikely to hold in practice. In this manuscript, we investigate designing approval policies for modifications to ML algorithms in the presence of distributional shifts. Our key observation is that the approval policy that is most efficient at identifying and approving beneficial modifications varies across different problem settings. So rather than selecting fixed approval policy a priori, we propose learning the best approval policy by searching over a family of approval strategies. We define a family of strategies that range in their level of optimism when approving modifications. This family includes the pessimistic strategy that, in fact, rescinds approval, which is necessary when no version of the ML algorithm performs well. We use the exponentially weighted averaging forecaster (EWAF) to learn the most appropriate strategy and derive tighter regret bounds assuming the distributional shifts are bounded. In simulation studies and empirical analyses, we find that wrapping approval strategies within EWAF algorithm is a simple yet effective strategy that can help protect against distributional shifts without significantly slowing down approval of beneficial modifications.","authors":"Jean Feng (University of California, San Francisco)","doi_link":"https://doi.org/10.1145/3450439.3451864","slideslive_active_date":"2021-04-14T23:59:00.00","slideslive_id":"38954737","title":"Learning to Safely Approve Updates to Machine Learning Algorithms"},{"UID":"21P17","abstract":"The black-box nature of the deep networks makes the explanation for \"why\" they make certain predictions extremely challenging. Saliency maps are one of the most widely-used local explanation tools to alleviate this problem. One of the primary approaches for generating saliency maps is by optimizing a mask over the input dimensions so that the output of the network is influenced the most by the masking. However, prior work only studies such influence by removing evidence from the input. In this paper, we present iGOS++, a framework to generate saliency maps that are optimized for altering the output of the black-box system by either removing or preserving only a small fraction of the input. Additionally, we propose to add a bilateral total variation term to the optimization that improves the continuity of the saliency map especially under high resolution and with thin object parts. The evaluation results from comparing iGOS++ against state-of-the-art saliency map methods show significant improvement in locating salient regions that are directly interpretable by humans. We utilized iGOS++ in the task of classifying COVID-19 cases from x-ray images and discovered that sometimes the CNN network is overfitted to the characters printed on the x-ray images when performing classification. Fixing this issue by data cleansing significantly improved the precision and recall of the classifier.","authors":"Saeed Khorram, Tyler Lawson, and Fuxin Li (Oregon State University)","doi_link":"https://doi.org/10.1145/3450439.3451865","slideslive_active_date":"2021-04-14T23:59:00.00","slideslive_id":"38954738","title":"iGOS++: Integrated Gradient Optimized Saliency by Bilateral Perturbations"},{"UID":"21P18","abstract":"Despite the large number of patients in Electronic Health Records (EHRs), the subset of usable data for modeling outcomes of specific phenotypes are often imbalanced and of modest size. This can be attributed to the uneven coverage of medical concepts in EHRs. We propose OMTL, an Ontology-driven Multi-Task Learning framework, that is designed to overcome such data limitations.The key contribution of our work is the effective use of knowledge from a predefined well-established medical relationship graph (ontology) to construct a novel deep learning network architecture that mirrors this ontology. This enables common representations to be shared across related phenotypes, and was found to improve the learning performance. The proposed OMTL naturally allows for multi-task learning of different phenotypes on distinct predictive tasks. These phenotypes are tied together by their semantic relationship according to the external medical ontology. Using the publicly available MIMIC-III database, we evaluate OMTL and demonstrate its efficacy on several real patient outcome predictions over state-of-the-art multi-task learning schemes. The results of evaluating the proposed approach on six experiments show improvement in the area under ROC curve by 9\\% and by 8\\% in the area under precision-recall curve.","authors":"Mohamed Ghalwash, Zijun Yao, Prithwish Chakraborty, james Codella, and Daby Sow (IBM Research)","doi_link":"https://doi.org/10.1145/3450439.3451881","slideslive_active_date":"2021-04-14T23:59:00.00","slideslive_id":"38954748","title":"Phenotypical Ontology Driven Framework for Multi-Task Learning"},{"UID":"21P19","abstract":"A single gene can encode for different protein versions through a process called alternative splicing. Since proteins play major roles in cellular functions, aberrant splicing profiles can result in a variety of diseases, including cancers. Alternative splicing is determined by the gene's primary sequence and other regulatory factors such as RNA-binding protein levels. With these as input, we formulate the prediction of RNA splicing as a regression task and build a new training dataset (CAPD) to benchmark learned models. We propose discrete compositional energy network (DCEN) which leverages the hierarchical relationships between splice sites, junctions and transcripts to approach this task. In the case of alternative splicing prediction, DCEN models mRNA transcript probabilities through its constituent splice junctions' energy values. These transcript probabilities are subsequently mapped to relative abundance values of key nucleotides and trained with ground-truth experimental measurements. Through our experiments on CAPD, we show that DCEN outperforms baselines and ablation variants.","authors":"Alvin Chan, Anna Korsakova, Yew-Soon Ong, Fernaldo Richtia Winnerdy, Kah Wai Lim, and Anh Tuan Phan (Nanyang Technological University)","doi_link":"https://doi.org/10.1145/3450439.3451857","slideslive_active_date":"2021-04-14T23:59:00.00","slideslive_id":"38954739","title":"RNA Alternative Splicing Prediction with Discrete Compositional Energy Network"},{"UID":"21P20","abstract":"Colorectal cancer recurrence is a major clinical problem - around 30-40% of patients who are treated with curative intent surgery will experience cancer relapse. Proactive prognostication is critical for early detection and treatment of recurrence. However, the common clinical approach to monitoring recurrence through testing for carcinoembryonic antigen (CEA) does not possess a strong prognostic performance. In our paper, we study a series of machine and deep learning architectures that exploit heterogeneous healthcare data to predict colorectal cancer recurrence. In particular, we demonstrate three different approaches to extract and integrate features from multiple modalities including longitudinal as well as tabular clinical data. Our best model employs a hybrid architecture that takes in multi-modal inputs and comprises: 1) a Transformer model carefully modified to extract high-quality features from time-series data, and 2) a Multi-Layered Perceptron (MLP) that learns tabular data features, followed by feature integration and classification for prediction of recurrence. It achieves an AUROC score of 0.95, as well as precision, sensitivity and specificity scores of 0.83, 0.80 and 0.96 respectively, surpassing the performance of all-known published results based on CEA, as well as most commercially available diagnostic assays. Our results could lead to better post-operative management and follow-up of colorectal cancer patients.","authors":"Danliang Ho (National University of Singapore) | Iain Bee Huat Tan (National Cancer Center Singapore) | Mehul Motani (National University of Singapore)","doi_link":"https://doi.org/10.1145/3450439.3451868","slideslive_active_date":"2021-04-14T23:59:00.00","slideslive_id":"38954740","title":"Predictive Models for Colorectal Cancer Recurrence Using Multi-modal Healthcare Data"},{"UID":"21P21","abstract":"Melanoma is the most common form of cancer in the world. Early diagnosis of the disease and an accurate estimation of its size and shape are crucial in preventing its spread to other body parts. Manual segmentation of these lesions by a radiologist however is time consuming and error-prone. It is clinically desirable to have an automatic tool to detect malignant skin lesions from dermoscopic skin images. We propose a novel end-to-end convolution neural network(CNN) for a precise and robust skin lesion localization and segmentation. The proposed network has 3 sub-encoders branching out from the main encoder. The 3 sub-encoders are inspired from Coordinate Convolution, Hourglass, and Octave Convolutional blocks: each sub-encoder summarizes different patterns and yet collectively aims to achieve a precise segmentation. We trained our segmentation model just on the ISIC 2018 dataset. To demonstrate the generalizability of our model, we evaluated our model on the ISIC 2018 and unseen datasets including ISIC 2017 and PH$^2$. Our approach showed an average 5\\% improvement in performance over different datasets while having less than half of the number of parameters when compared to other state-of-the-art segmentation models.","authors":"shreshth saini (indian institute of technology jodhpur) | Jeon Young Seok and Mengling Feng (Saw Swee Hock School of PublicHealth, National University HealthSystem, National University ofSingapore)","doi_link":"https://doi.org/10.1145/3450439.3451873","slideslive_active_date":"2021-04-14T23:59:00.00","slideslive_id":"38954741","title":"B-SegNet : Branched-SegMentor Network For Skin Lesion Segmentation"},{"UID":"21P22","abstract":"In medicine, comorbidities refer to the presence of multiple, co-occurring diseases. Due to their co-occurring nature, the course of one comorbidity is often highly dependent on the course of the other disease and, hence, treatments can have significant spill-over effects. Despite the prevalence of comorbidities among patients, a comprehensive statistical framework for modeling the longitudinal dynamics of comorbidities is missing. In this paper, we propose a probabilistic model for analyzing comorbidity dynamics over time in patients. Specifically, we develop a coupled hidden Markov model with a personalized, non-homogeneous transition mechanism, named Comorbidity-HMM. The specification of our Comorbidity-HMM is informed by clinical research: (1) It accounts for different disease states (i. e., acute, stable) in the disease progression by introducing latent states that are of clinical meaning. (2) It models a coupling among the trajectories from comorbidities to capture co-evolution dynamics. (3) It considers between-patient heterogeneity (e. g., risk factors, treatments) in the transition mechanism. Based on our model, we define a spill-over effect that measures the indirect effect of treatments on patient trajectories through coupling (i. e., through comorbidity co-evolution). We evaluated our proposed Comorbidity-HMM based on 675 health trajectories where we investigate the joint progression of diabetes mellitus and chronic liver disease. Compared to alternative models without coupling, we find that our Comorbidity-HMM achieves a superior fit. Further, we quantify the spill-over effect, that is, to what extent diabetes treatments are associated with a change in the chronic liver disease from an acute to a stable disease state. To this end, our model is of direct relevance for both treatment planning and clinical research in the context of comorbidities.","authors":"Basil Maag, Stefan Feuerriegel, and Mathias Kraus (ETH Zurich) | Maytal Saar-Tsechansky (University of Texas at Austin) | Thomas Zueger (1) Inselspital, Bern, University Hospital, University of Bern 2) ETH Zurich)","doi_link":"https://doi.org/10.1145/3450439.3451871","slideslive_active_date":"2021-04-14T23:59:00.00","slideslive_id":"38954742","title":"Modeling Longitudinal Dynamics of Comorbidities"},{"UID":"21P23","abstract":"Generating interpretable visualizations of multivariate time series in the intensive care unit is of great practical importance. Clinicians seek to condense complex clinical observations into intuitively understandable critical illness patterns, like failures of different organ systems. They would greatly benefit from a low-dimensional representation in which the trajectories of the patients' pathology become apparent and relevant health features are highlighted. To this end, we propose to use the latent topological structure of Self-Organizing Maps (SOMs) to achieve an interpretable latent representation of ICU time series and combine it with recent advances in deep clustering. Specifically, we (a) present a novel way to fit SOMs with probabilistic cluster assignments (PSOM), (b) propose a new deep architecture for probabilistic clustering (DPSOM) using a VAE, and (c) extend our architecture to cluster and forecast clinical states in time series (T-DPSOM). We show that our model achieves superior clustering performance compared to state-of-the-art SOM-based clustering methods while maintaining the favorable visualization properties of SOMs. On the eICU data-set, we demonstrate that T-DPSOM provides interpretable visualizations of patient state trajectories and uncertainty estimation. We show that our method rediscovers well-known clinical patient characteristics, such as a dynamic variant of the Acute Physiology And Chronic Health Evaluation (APACHE) score. Moreover, we illustrate how it can disentangle individual organ dysfunctions on disjoint regions of the two-dimensional SOM map.","authors":"Laura Manduchi, Matthias H\u00fcser, Martin Faltys, Julia Vogt, Gunnar R\u00e4tsch, and Vincent Fortuin (ETH Z\u00fcrich)","doi_link":"https://doi.org/10.1145/3450439.3451872","slideslive_active_date":"2021-04-14T23:59:00.00","slideslive_id":"38954743","title":"T-DPSOM - An Interpretable Clustering Method for Unsupervised Learning of Patient Health States"},{"UID":"21P24","abstract":"Wearable technology opens opportunities to reduce sedentary behavior; however, commercially available devices do not provide tailored coaching strategies. Just-In-Time Adaptive Interventions (JITAI) provide such a framework; however most JITAI are conceptual to date. We conduct a study to evaluate just-in-time nudges in free-living conditions in terms of receptiveness and nudge impact. We first quantify baseline behavioral patterns in context using features such as location and step count, and assess differences in individual responses. We show there is a strong inverse relationship between average daily step counts and time spent being sedentary indicating that steps are steadily taken throughout the day, rather than in large bursts. Interestingly, the effect of nudges delivered at the workplace is larger in terms of step count than those delivered at home. We develop Random Forest models to learn nudge receptiveness using both individualized and contextualized data. We show that step count is the least important identifier in nudge receptiveness, while location is the most important. Furthermore, we compare the developed models with a commercially available smart coach using post-hoc analysis. The results show that using the contextualized and individualized information significantly outperforms non-JITAI approaches to determine nudge receptiveness.","authors":"Matthew Saponaro, Ajith Vemuri, Greg Dominick, and Keith Decker (University of Delaware)","doi_link":"https://doi.org/10.1145/3450439.3451874","slideslive_active_date":"2021-04-14T23:59:00.00","slideslive_id":"38954744","title":"Contextualization and Individualization for Just-in-Time Adaptive Interventions to Reduce Sedentary Behavior"},{"UID":"21P25","abstract":"Pre-training (PT) has been used successfully in many areas of machine learning. One area where PT would be extremely impactful is over electronic health record (EHR) data. Successful PT strategies on this modality could improve model performance in data-scarce contexts such as modeling for rare diseases or allowing smaller hospitals to benefit from data from larger health systems. While many PT strategies have been explored in other domains, much less exploration has occurred for EHR data. One reason this may be is the lack of standardized benchmarks suitable for developing and testing PT algorithms. In this work, we establish a PT benchmark dataset for EHR timeseries data, establishing cohorts, a diverse set of fine-tuning tasks, and PT-focused evaluation regimes across two public EHR datasets: MIMIC-III and eICU. This benchmark fills an essential hole in the field by enabling a robust manner of iterating on PT strategies for this modality. To show the value of this benchmark and provide baselines for further research, we also profile two simple PT algorithms: a self-supervised, masked imputation system and a weakly-supervised, multi-task system. We find that PT strategies (in particular weakly-supervised PT methods) can offer significant gains over traditional learning in few-shot settings, especially on tasks with strong class imbalance. Our full benchmark and code are publicly available at <a href='https://github.com/mmcdermott/comprehensive_MTL_EHR' target='_blank' rel='noopener'>https://github.com/mmcdermott/comprehensive_MTL_EHR</a>.","authors":"Matthew McDermott (Massachusetts Institute of Technology) | Bret Nestor (University of Toronto) | Evan Kim (Massachusetts Institute of Technology) | Wancong Zhang (New York University) | Anna Goldenberg (Hospital for Sick Children, University of Toronto, Vector Institute) | Peter Szolovits (MIT) | Marzyeh Ghassemi (University of Toronto | Vector Institute for Artificial Intelligence)","doi_link":"https://doi.org/10.1145/3450439.3451877","slideslive_active_date":"2021-04-14T23:59:00.00","slideslive_id":"38954745","title":"A Comprehensive EHR Timeseries Pre-training Benchmark"},{"UID":"21P26","abstract":"Clinical machine learning models have been found to significantly degrade in performance on hospitals or regions not seen during training. Recent developments in domain generalization offer a promising solution to this problem, by creating models that learn invariances which hold across environments. In this work, we benchmark the performance of eight domain generalization methods on clinical time series and medical imaging data. We introduce a framework to induce practical confounding and sampling bias to stress-test these methods over existing non-healthcare benchmarks. We find, consistent with prior work, that current domain generalization methods do not achieve significant gains in out-of-distribution performance over empirical risk minimization on real-world medical imaging data. However, we do find a subset of realistic confounding scenarios where significant performance gains are observed. We characterize these scenarios in detail, and recommend best practices for domain generalization in the clinical setting.","authors":"Haoran Zhang (University of Toronto | Vector Institute) | Natalie Dullerud (University of Toronto, Vector Institute) | Laleh Seyyed-Kalantari (University of Toronto) | Quaid Morris (Memorial Sloan Kettering Cancer Center) | Shalmali Joshi (Harvard University) | Marzyeh Ghassemi (University of Toronto | Vector Institute for Artificial Intelligence)","doi_link":"https://doi.org/10.1145/3450439.3451878","slideslive_active_date":"2021-04-14T23:59:00.00","slideslive_id":"38954746","title":"An Empirical Framework for Domain Generalization In Clinical Settings"},{"UID":"21P27","abstract":"Early detection of influenza-like symptoms can prevent widespread flu viruses and enable timely treatments, particularly in the post-pandemic era. Mobile sensing leverages an increasingly diverse set of embedded sensors to capture fine-grained information of human behaviors and ambient contexts and can serve as a promising solution for influenza-like symptom recognition. Traditionally, handcrafted and high level features of mobile sensing data are extracted by using handcrafted feature engineering and Convolutional/Recurrent Neural Network respectively. However, in this work, we use graph representation to encode the dynamics of state transitions and internal dependencies in human behaviors, apply graph embeddings to automatically extract the topological and spatial features from graph input and propose an end-to-end Graph Neural Network model with multi-channel mobile sensing input for influenza-like symptom recognition based on people's daily mobility, social interactions, and physical activities. Using data generated from 448 participants, We show that Graph Neural Networks (GNN) with GraphSAGE convolutional layers significantly outperform baseline models with handcrafted features. Furthermore, we use GNN interpretability method to generate insight (important node, graph structure) for the symptom recognition. To the best of our knowledge, this is the first work that applies graph representation and graph neural network on mobile sensing data for graph-based human behaviors modeling.","authors":"Guimin Dong, Lihua Cai, Debajyoti Datta, Shashwat Kumar, Laura E. Barnes, and Mehdi Boukhechba (University of Virginia)","doi_link":"https://doi.org/10.1145/3450439.3451880","slideslive_active_date":"2021-04-14T23:59:00.00","slideslive_id":"38954747","title":"Influenza-like Symptom Recognition using Mobile Sensing and Graph Neural Networks"}],"speakers":[{"UID":"21K01","abstract":"Until today, all the available therapeutics are designed by human experts, with no help from AI tools. This reliance on human knowledge and dependence on large-scale experimentations result in prohibitive development cost and high failure rate. Recent developments in machine learning algorithms for molecular modeling aim to transform this field. In my talk, I will present state-of-the-art approaches for property prediction and de-novo molecular generation, describing their use in drug design. In addition, I will highlight unsolved algorithmic questions in this field, including confidence estimation, pretraining, and deficiencies in learned molecular representations.","bio":"Regina Barzilay is a professor in the Department of Electrical Engineering and Computer Science and a member of the Computer Science and Artificial Intelligence Laboratory at the Massachusetts Institute of Technology. She is an AI faculty lead for Jameel Clinic, an MIT center for Machine Learning in Health at MIT. Her research interests are in natural language processing, applications of deep learning to chemistry and oncology. She is a recipient of various awards including the NSF Career Award, the MIT Technology Review TR-35 Award, Microsoft Faculty Fellowship and several Best Paper Awards at NAACL and ACL. In 2017, she received a MacArthur fellowship, an ACL fellowship and an AAAI fellowship. In 2020, she was awarded AAAI Squirrel Award for Artificial Intelligence for the Benefit of Humanity. She received her Ph.D. in Computer Science from Columbia University, and spent a year as a postdoc at Cornell University. Regina received her undergraduate from Ben Gurion University of the Negev, Israel.","image":"static/images/speakers/r-barzilay.jpg","institution":"MIT Computer Science & Artificial Intelligence Lab","slideslive_active_date":"2021-04-14T23:59:00.00","slideslive_id":"38954711","speaker":"Regina Barzilay","title":"AI for Drug Discovery: Challenges and Opportunities","website":"https://www.regina.csail.mit.edu"},{"UID":"21K02","abstract":"Improved healthcare delivery and patient outcomes are the ultimate goals of many AI applications in healthcare. However, relatively few machine learning models have been translated to clinical practice so far and among those even fewer have undergone a randomized control trial (RCT) to assess their impact. This talk will highlight aspects of the clinical translational process, beyond retrospective modeling, that impact design, development, validation, and regulation of machine learning models in healthcare. In particular, this talk focuses on our recent study of predicting favorable outcomes in hospitalized COVID-19 patients. The resulting model, which was deployed and prospectively validated at NYU Langone, underwent an RCT, and was eventually shared with other institutions. I will discuss challenges around integrating our model in the EHR system and their implications, the efficacy and safety results of our RCT, and practical insights about sharing models across clinics. We will end the talk by reviewing results of a survey of over 195 clinical users who interacted with this model, summarizing when and how the model was most helpful.","bio":"Narges Razavian is an assistant professor at NYU Langone Health, Center for Healthcare Innovation and Delivery Sciences, and Predictive Analytics Unit. Her lab focuses on various applications of Machine Learning and AI for medicine with a clinical translation outlook, and they work with Medical Images, Clinical Notes, and Electronic Health Records. Before NYU Langone, she was a postdoc at CILVR lab at NYU Courant CS department. She received her PhD at CMU Computational Biology group.","image":"static/images/speakers/n-razavian.jpg","institution":"New York University Langone Medical Center","slideslive_active_date":"2021-04-14T23:59:00.00","slideslive_id":"38954712","speaker":"Narges Razavian","title":"Machine Learning in Healthcare: From Modeling to Clinical Impact","website":"http://razavian.net/"},{"UID":"21K03","abstract":"In early March 2020, Mark joined an interdisciplinary team to launch the Pandemic Response Network. Over the subsequent months, he helped build and launch programs to support health workers, university students and staff, small businesses, K-12 public schools, and historically marginalized communities through the COVID-19 pandemic. With a strong background in design and implementation of high-tech health innovations, Mark worked alongside public health practitioners and community leaders to repeatedly execute the last mile implementation of critical COVID-19 programs, including symptom monitoring in the workplace, rapid antigen testing in schools, and pop-up vaccination events in churches. The portfolio of programs rapidly shifted health care capabilities and expertise out of hospitals and clinics into community settings that were poorly supported by existing public health infrastructure. The experience forced Mark and his team to approach technology design with a new set of assumptions and led to the development of completely novel data streams and technology systems. In his talk, Mark distills insights and learnings from the front lines of the COVID-19 response and highlights important implications and opportunities for the field of machine learning and artificial intelligence in health care.","bio":"Mark Sendak, MD, MPP is the Population Health & Data Science Lead at the Duke Institute for Health Innovation (DIHI), where he leads interdisciplinary teams of data scientists, clinicians, and machine learning experts to build technologies that solve real clinical problems. He has built tools to support Duke Health's Accountable Care Organization, COVID-19 Pandemic Response Network, and hospital network. Together with his team, he has integrated dozens of data-driven technologies into clinical operations and is a co-inventor of software to scale machine learning applications. He leads the DIHI Clinical Research & Innovation scholarship, which equips medical students with the business and data science skills required to lead health care innovation efforts. His work has been published in technical venues such as the Machine Learning for Healthcare Proceedings and Fairness, Accountability, and Transparency in Machine Learning Proceedings and clinical journals such as Plos Medicine, Nature Medicine and JAMA Open. He has served as an expert advisor to the American Medical Association, AARP, and National Academies of Medicine on matters related to machine learning, innovation, and policy. He obtained his MD and Masters of Public Policy at Duke University as a Dean's Tuition Scholar and his Bachelor's of Science in Mathematics from UCLA.","image":"static/images/speakers/m-sendak.jpg","institution":"Duke Institute for Health Innovation","slideslive_active_date":"2021-04-14T23:59:00.00","slideslive_id":"38954713","speaker":"Mark Sendak","title":"Holding a Hammer When There are no Nails - Rapid Iteration to Build COVID-19 Support Programs for Historically Marginalized Communities","website":"https://dihi.org/team-member/mark-sendak-md/"},{"UID":"21K04","abstract":"Machine learning in healthcare could have transformative impact for patients, caregivers and health systems but the potential benefits remain challenging to realise at scale. Along the path from the development of a model to the realisation of clinical and health-economic impact are a number of challenges and learnings that might be transferable across a range of applications. This talk surveys some recent progress at Google Health and shares learnings from their team in moving from early research to product development; from product development to deployment; and from deployment to early measures of clinical impact.","bio":"Dr. Alan Karthikesalingam is a surgeon-scientist who leads the healthcare machine learning research group at Google Health in London (and formerly for healthcare at DeepMind).<br /><br />He led DeepMind and Google\u2019s teams in four landmark studies in Nature and Nature Medicine focusing on AI for breast cancer screening with Cancer Research UK, AI for the recognition and prediction of blinding eye diseases with the world\u2019s largest eye hospital (Moorfields) and medical records research with the Veterans Affairs developing AI early warning systems for common causes of patient deterioration, like acute kidney injury.<br /><br />He is leading work on how machine learning approaches can best promote AI safety as the team takes forward its early research into products for clinical care. Alan continues to practice clinically and supervise PhD students as a lecturer in the vascular surgery department of Imperial College, London.","image":"static/images/speakers/a-karthikesalingam.jpg","institution":"Google Health - London","slideslive_active_date":"2021-04-14T23:59:00.00","slideslive_id":"38954714","speaker":" Alan Karthikesalingam","title":"Lessons on the Path from Code to Clinic  - Some Common Myths in Machine Learning for Healthcare","website":""},{"UID":"21K05","abstract":"In medicine, the integration of artificial intelligence (AI) and machine learning (ML) tools could lead to a paradigm shift in which human-AI collaboration becomes integrated in medical decision-making. Despite many years of enthusiasm towards these technologies, the majority of tools fail once they are deployed in the real-world, often due to failures in workflow integration and interface design. In this talk, I will share research using methods in human-computer interaction (HCI) to design and evaluate machine learning tools for real-world clinical use. Results from this work suggest that trends in explainable AI may be inappropriate for clinical environments. I will discuss paths towards designing these tools for real-world medical systems, and describe how we are using collaborations across medicine, data science, and HCI to create machine learning tools for complex medical decisions.","bio":"Dr. Maia Jacobs is an assistant professor at Northwestern University in Computer Science and Preventive Medicine. Her research contributes to the fields of Computer Science, Human-Computer Interaction (HCI), and Health Informatics through the design and evaluation of novel computing approaches that provide individuals with timely, relevant, and actionable health information. Recent projects include the design and deployment of mobile tools to increase health information access in rural communities, evaluating the influence of AI interface design on expert decision making, and co-designing intelligent decision support tools with clinicians. Her research has been funded by the National Science Foundation, the National Cancer Institute, and the Harvard Data Science Institute and has resulted in the deployment of tools currently being used by healthcare systems and patients around the country. She completed her PhD in Human Centered Computing at Georgia Institute of Technology and was a postdoctoral fellow in the Center for Research on Computation and Society at Harvard University. Jacobs\u2019 work was awarded the iSchools Doctoral Dissertation Award, the Georgia Institute of Technology College of Computing Dissertation Award, and was recognized in the 2016 report to the President of the United States from the President's Cancer Panel, which focused on improving cancer-related outcomes.","image":"static/images/speakers/m-jacobs.png","institution":"Northwestern University","slideslive_active_date":"2021-04-14T23:59:00.00","slideslive_id":"38954715","speaker":"Maia Jacobs","title":"Bringing AI to the Bedside with User Centered Design","website":"http://maiajacobs.com/"},{"UID":"21K06","abstract":"The wide adoption of electronic health records (EHR) systems has led to the availability of large clinical datasets available for precision medicine research. EHR data, linked with bio-repository, is a valuable new source for deriving real-word, data-driven prediction models of disease risk and treatment response. Yet, they also bring analytical difficulties. Precise information on clinical outcomes is not readily available and requires labor intensive manual chart review. Synthesizing information across healthcare systems is also challenging due to heterogeneity and privacy. In this talk, I\u2019ll discuss analytical approaches for mining EHR data with a focus on denoising, scalability and transportability . These methods will be illustrated using EHR data from multiple healthcare centers.","bio":"Dr. Tianxi Cai is the John Rock Professor of Population and Translational Data Science jointly appointed in the Department of Biostatistics at the Harvard T.H. Chan School of Public Health (HSPH) and the Department of Biomedical Informatics (DBMI), Harvard Medical School, where she directs the Translational Data Science Center for a learning healthcare system. Her recent research has been focusing on developing interpretable and robust statistical and machine learning methods for deriving precision medicine strategies and more broadly for mining large-scale biomedical data including electronic health records data.","image":"static/images/speakers/t-cai.jpg","institution":"Harvard Medical School","slideslive_active_date":"2021-04-14T23:59:00.00","slideslive_id":"38954716","speaker":"Tianxi Cai","title":"Precision Medicine with Imprecise EHR Data","website":"https://celehs.hms.harvard.edu/tcai/"}],"tutorials":[{"UID":"21T01","abstract":"Causal inference is an important topic in healthcare because a causal relationship between an exposure and a health outcome may suggest an intervention to improve the health outcome. In this tutorial, we provide an introduction to the field of causal inference. We will cover several fundamental topics in causal inference, including the potential outcome framework, structural equation modeling,  propensity score modeling, and instrumental variable analysis. Methods will be illustrated using real clinical examples.","authors":"Linbo Wang","bio":"\n    Linbo Wang is an assistant professor in the Department of Statistical Sciences, University of Toronto. He is also an Affiliate Assistant Professor in the Department of Statistics, University of Washington, and a faculty affiliate at Vector Institute. His research interest is centered around causality and its interaction with statistics and machine learning. Prior to these roles, he was a postdoc at Harvard T.H. Chan School of Public Health. He obtained his Ph.D. from the University of Washington.","rocketchat_id":"","slideslive_active_date":"2021-03-28T23:59:00.00","slideslive_id":"38954717","title":"Causal Inference in Clinical Research: From Theory to Practice"},{"UID":"21T02","abstract":"Mobile health (mHealth) technologies are providing new promising ways to deliver interventions in both clinical and non-clinical settings. Wearable sensors and smartphones collect real-time data streams that provide information about an individual\u2019s current health including both internal (e.g., mood, blood sugar level) and external (e.g., social, location) contexts. Both wearables and smartphones can be used to deliver interventions. mHealth interventions are in current use across a vast number of health-related fields including medication adherence, physical activity, weight loss, mental illness and addictions. This tutorial discusses the micro-randomized trial (MRT), an experimental trial design for use in optimizing real time delivery of sequences of treatment, with an emphasis on mHealth. We introduce the MRT design using HeartSteps, a physical activity study, as an example. We define the causal excursion effect and discuss reasons why this effect is often considered the primary causal effect of interest in MRT analysis. We introduce statistical methods for primary and secondary analyses for MRT with continuous binary outcomes. We discuss the sample size considerations for designing MRTs.","authors":"Tianchen Qian","bio":"\n    Tianchen Qian is an Assistant Professor in the Department of Statistics at University of California, Irvine. He completed his PhD at the Johns Hopkins University and was a postdoctoral fellow at Harvard University. His research is focused on the experimental design and statistical analysis methods for developing mobile health interventions. In particular, he has developed causal inference methods for analyzing micro-randomized trial data and sample size calculation approaches for designing micro-randomized trials.\n    <br /><br />Tianchen Qian, Ph.D., Assistant Professor, Department of Statistics, Donald Bren School of Information and Computer Sciences, UC Irvine | Email: <a href='mailto:t.qian@uci.edu'>t.qian@uci.edu</a> | Website: <a href='https://sites.google.com/view/tianchen-qian' target='_blank' rel='noopener'>https://sites.google.com/view/tianchen-qian</a>","rocketchat_id":"","slideslive_active_date":"2021-03-28T23:59:00.00","slideslive_id":"38954718","title":"Experimental Design and Causal Inference Methods For Micro-Randomized Trials: A Framework for Developing Mobile Health Interventions"},{"UID":"21T03","abstract":"Offline reinforcement learning (offline RL), a.k.a. batch-mode reinforcement learning, involves learning a policy from potentially suboptimal data. In contrast to imitation learning, offline RL does not rely on expert demonstrations, but rather seeks to surpass the average performance of the agents that generated the data. Methodologies such as the gathering of new experience fall short in offline settings, requiring reassessment of fundamental learning paradigms. In this tutorial I aim to provide the necessary background and challenges of this exciting area of research, from off policy evaluation through bandits to deep reinforcement learning.","authors":"Guy Tennenholtz","bio":"\n    Guy Tennenholtz is a fourth-year Ph.D. student at the Technion University, advised by Prof. Shie Mannor. His research interests lie in the field of reinforcement learning, and specifically, how offline data can be leveraged to build better agents. Problems of large action spaces, partial observability, confounding bias, and uncertainty are only some of the problems he is actively researching. In his spare time Guy also enjoys creating mobile games, with the vision of incorporating AI into both the game development process and gameplay.","rocketchat_id":"","slideslive_active_date":"2021-03-28T23:59:00.00","slideslive_id":"38954719","title":"Offline Reinforcement Learning"},{"UID":"21T04","abstract":"As machine learning black boxes are increasingly being deployed in domains such as healthcare and criminal justice, there is growing emphasis on building tools and techniques for explaining these black boxes in a post hoc manner. Such explanations are being leveraged by domain experts to diagnose systematic errors and underlying biases of black boxes. However, recent research has shed light on the vulnerabilities of popular post hoc explanation techniques. In this tutorial, I will provide a brief overview of post hoc explanation methods with special emphasis on feature attribution methods such as LIME and SHAP. I will then discuss recent research which demonstrates that these methods are brittle, unstable, and are vulnerable to a variety of adversarial attacks. Lastly, I will present two solutions to address some of the vulnerabilities of these methods \u2013 (i)  a generic framework based on adversarial training that is designed to make post hoc explanations more stable and robust to shifts in the underlying data, and (ii) a Bayesian framework that captures the uncertainty associated with post hoc explanations and in turn allows us to generate reliable explanations which satisfy user specified levels of confidence. Overall, this tutorial will provide a bird\u2019s eye view of the state-of-the-art in the burgeoning field of explainable machine learning.","authors":"Hima Lakkaraju","bio":"\n    Hima Lakkaraju is an Assistant Professor at Harvard University focusing on explainability, fairness, and robustness of machine learning models. She has also been working with various domain experts in criminal justice and healthcare to understand the real world implications of explainable and fair ML. Hima has recently been named one of the 35 innovators under 35 by MIT Tech Review, and has received best paper awards at SIAM International Conference on Data Mining (SDM) and INFORMS. She has given invited workshop talks at ICML, NeurIPS, AAAI, and CVPR, and her research has also been covered by various popular media outlets including the New York Times, MIT Tech Review, TIME, and Forbes. For more information, please visit: <a href='https://himalakkaraju.github.io' target='_blank' rel='noopener'>https://himalakkaraju.github.io</a>","rocketchat_id":"","slideslive_active_date":"2021-03-28T23:59:00.00","slideslive_id":"38954720","title":"Explainable ML: Understanding the Limits and Pushing the Boundaries"},{"UID":"21T05","abstract":"Phenotyping is the process of identifying a patient\u2019s health state based on the information in their electronic health records. In this tutorial, we will discuss why phenotyping is a challenging problem from both a practical and methodological perspective. We will focus primarily on the the challenges in obtaining annotated phenotype information from patient records and present statistical learning methods that leverage unlabeled examples to improve model estimation and evaluation to reduce the annotation burden.","authors":"Jesse Gronsbell | Chuan Hong | Molei Liu | Clara-Lea Bonzel | Aaron Sonabend","bio":"\n    Jesse Gronsbell is an Assistant Professor in the Department of Statistical Sciences at the University of Toronto.  Prior to joining U of T,  Jesse spent a couple of years as a data scientist in the Mental Health Research and Development Group at Alphabet's Verily Life Sciences.  Her primary interest is in the development of statistical methods for modern digital data sources such as electronic health records and mobile health data.\n    <br /><br />Chuan Hong is an instructor in biomedical informatics from the Department of Biomedical Informatics (DBMI) at Harvard Medical School. She received her PhD in Biostatistics from the University of Texas Health Science Center at Houston. Her doctoral research focused on meta-analysis and DNA methylation detection. At DBMI, Chuan's research interests lie in developing statistical and computational methods for biomarker evaluation, predictive modeling, and precision medicine with biomedical data. In particular, she is interested in combining electronic medical records with biorepositories and relevant resources to improve phenotyping accuracy, detect novel biomarkers, and monitor disease progression in clinical research.\n    <br /><br />Molei Liu is a 4th year PhD candidate in the Biostatistics department at Harvard T.H. Chan School of Public Health. He received a Bachelor's degree in Statistics from Peking University. Molei has been working in areas including high dimensional statistics, distributed learning, semi-supervised learning, semi-parametric inference, and model-X inference. He has also been working on methods for phenome-wide association studies (PheWAS) using electronic health records data.\n    <br /><br />Clara-Lea Bonzel is a research assistant at the Department of Biomedical Informatics at Harvard Medical School. She is mainly interested in personalized medicine using phenomic and genomic data, and model selection and evaluation.   Clara-Lea received her master's degree in Applied Mathematics and Financial Engineering from the Swiss Federal Institute of Technology (EPFL).\n    <br /><br />Aaron Sonabend is a PhD candidate in the Biostatistics department at Harvard T.H. Chan School of Public Health. He is primarily focused on developing robust reinforcement learning and natural language processing methods for contexts with sampling bias, partially observed rewards, or strong distribution shifts. He is interested in healthcare and biomedical applications, such as finding optimal sequential treatment regimes for complex diseases, and phenotyping using electronic health records. Aaron holds a Bachelor's degree in Applied Mathematics, and in Economics from the National Autonomous Technological Institute of Mexico (ITAM).","rocketchat_id":"","slideslive_active_date":"2021-03-28T23:59:00.00","slideslive_id":"38954721","title":"Semi-supervised Phenotyping with Electronic Health Records"}],"workshops":[{"UID":"21WS01","abstract":"In many real-world environments, the details of decision-making processes are not fully known, e.g., how oncologists decide on specific radiation therapy treatment plans for cancer patients, how clinicians decide on medication dosages for different patients, or how hypertension patients choose their diet to control their illness. While conventional machine learning and statistical methods can be used to better understand such processes, they often fail to provide meaningful insights into the unknown parameters when the problem's setting is heavily constrained. Similarly, conventional constrained inference models, such as inverse optimization, are not well equipped for data-driven problems. In this study, we develop a novel methodology (called MLIO) that combines machine learning and inverse optimization techniques to recover the utility functions of a black-box decision-making process. Our method can be applied to settings where different types of data are required to capture the problem. MLIO is specifically developed with data-intensive medical decision-making environments in mind. We evaluate our approach in the context of personalized diet recommendations for patients, building on a large dataset of historical daily food intakes of patients from NHANES. MLIO considers these prior dietary behaviors in addition to complementary data (e.g., demographics and preexisting conditions) to recover the underlying criteria that the patients had in mind when deciding on their food choices. Once the underlying criteria are known, an optimization model can be used to find personalized diet recommendations that adhere to patients' behavior while meeting all required dietary constraints.","authors":"Farzin Ahmadi, Tinglong Dai, and Kimia Ghobadi (Johns Hopkins University)","title":"Emulating Human Decision-Making Under Multiple Constraints"},{"UID":"21WS02","abstract":"Deep neural networks have increasingly been used as an auxiliary tool in healthcare applications, due to their ability to improve performance of several diagnosis tasks. However, these methods are not widely adopted in clinical settings due to the practical limitations in the reliability, generalizability, and interpretability of deep learning based systems. As a result, methods have been developed that impose additional constraints during network training to gain more control as well as improve interpretabilty, facilitating their acceptance in healthcare community. In this work, we investigate the benefit of using Orthogonal Spheres (OS) constraint for classification of COVID-19 cases from chest X-ray images. The OS constraint can be written as a simple orthonormality term which is used in conjunction with the standard cross-entropy loss during classification network training. Previous studies have demonstrated significant benefits in applying such constraints to deep learning models. Our findings corroborate these observations, indicating that the orthonormality loss function effectively produces improved semantic localization via GradCAM visualizations, enhanced classification performance, and reduced model calibration error. Our approach achieves an improvement in accuracy of 1.6% and 4.8% for two- and three-class classification, respectively; similar results are found for models with data augmentation applied. In addition to these findings, our work also presents a new application of the OS regularizer in healthcare, increasing the post-hoc interpretability and performance of deep learning models for COVID-19 classification to facilitate adoption of these methods in clinical settings. We also identify the limitations of our strategy that can be explored for further research in future.","authors":"Ella Y. Wang (BASIS Chandler); Anirudh Som (SRI International); Ankita Shukla, Hongjun Choi, and Pavan Turaga (ASU)","title":"Interpretable COVID-19 Chest X-Ray Classification via Orthogonality Constraint"},{"UID":"21WS03","abstract":"Meta-analysis is a systematic approach for understanding a phenomenon by analyzing the results of many previously published experimental studies related to the same treatment and outcome measurement. It is an important tool for medical researchers and clinicians to derive reliable conclusions regarding the overall effect of treatments and interventions (e.g., drugs) on a certain outcome (e.g., the severity of a disease). Unfortunately, conventional meta-analysis involves great human effort, i.e., it is constructed by hand and is extremely time-consuming and labor-intensive, rendering a process that is inefficient in practice and vulnerable to human bias. To overcome these challenges, we work toward automating meta-analysis with a focus on controlling for the potential biases. Automating meta-analysis consists of two major steps: (1) extracting information from scientific publications written in natural language, which is different and noisier than what humans typically extract when conducting a meta-analysis; and (2) modeling meta-analysis, from a novel \\textit{causal-inference} perspective, to control for the potential biases and summarize the treatment effect from the outputs of the first step. Since sufficient prior work exists for the first step, this study focuses on the second step. The core contribution of this work is a multiple causal inference algorithm tailored to the potentially noisy and biased information automatically extracted by current natural language processing systems. Empirical evaluations on both synthetic and semi-synthetic data show that the proposed approach for automated meta-analysis yields high-quality performance.","authors":"Lu Cheng (Arizona State University); Dmitriy Katz-Rogozhnikov, Kush R. Varshney, and Ioana Baldini (IBM Research)","title":"Automated Meta-Analysis in Medical Research: A Causal Learning Perspective"},{"UID":"21WS04","abstract":"Attention is a powerful concept in computer vision. End-to-end networks that learn to focus selectively on regions of an image or video often perform strongly. However, other image regions, while not necessarily containing the signal of interest, may contain useful context. We present an approach that exploits the idea that statistics of noise may be shared between the regions that contain the signal of interest and those that do not. Our technique uses the inverse of an attention mask to generate a noise estimate that is then used to denoise temporal observations. We apply this to the task of camera-based physiological measurement. A convolutional attention network is used to learn which regions of a video contain the physiological signal and generate a preliminary estimate. A noise estimate is obtained by using the pixel intensities in the inverse regions of the learned attention mask, this in turn is used to refine the estimate of the physiological signal. We perform experiments on two large benchmark datasets and show that this approach produces state-of-the-art results, increasing the signal-to-noise ratio by up to 5.8 dB, reducing heart rate and breathing rate estimation error by as much as 30%, recovering subtle waveform dynamics, and generalizing from RGB to NIR videos without retraining.","authors":"Ewa Nowara (RICE UNIVERSITY); Daniel McDuff (Microsoft Research); Ashok Veeraraghavan (RICE UNIVERSITY)","title":"The Benefit of Distraction: Denoising Remote Vitals Measurements using Inverse Attention"},{"UID":"21WS05","abstract":"Electronic health records (EHRs) provide an abundance of data for clinical outcomes modeling. The prevalence of EHR data has enabled a number of studies using a variety of machine learning algorithms to predict potential adverse events. However, these studies do not account for the heterogeneity present in EHR data, including various lengths of stay, various frequencies of vitals captured in invasive versus non-invasive fashion, and various repetitions (or lack of thereof) of laboratory examinations. Therefore, studies limit the types of features extracted or the domain considered to provide a more homogeneous training set to machine learning models. The heterogeneity in this data represents important risk differences in each patient. In this work, we examine such data in an intensive care unit (ICU) setting, where the length of stay and the frequency of data gathered may vary significantly based upon the severity of patient condition. Therefore, it is unreasonable to use the same model for patients first entering the ICU versus those that have been there for above average lengths of stay. Developing multiple individual models to account for different patient cohorts, different lengths of stay, and different sources for key vital sign data may be tedious and not account for rare cases well. We address this challenge by developing a dynamic model, based upon meta-learning, to adapt to data heterogeneity and generate predictions of various outcomes across the different lengths of data. We compare this technique against a set of benchmarks on a publicly-available ICU dataset (MIMIC-III) and demonstrate improved model performance by accounting for data heterogeneity.","authors":"Lida Zhang (Texas A&M University); Xiaohan Chen, Tianlong Chen, and Zhangyang Wang (University of Texas at Austin); Bobak J. Mortazavi (Texas A&M University)","title":"DynEHR: Dynamic Adaptation of Models with Data Heterogeneity in Electronic Health Records"},{"UID":"21WS06","abstract":"Machine Learning (ML) is widely used to automatically extract meaningful information from Electronic Health Records (EHR) to support operational, clinical, and financial decision making. However, ML models require a large number of annotated examples to provide satisfactory results, which is not possible in most healthcare scenarios due to the high cost of clinician labeled data. Active Learning (AL) is a process of selecting the most informative instances to be labeled by an expert to further train a supervised algorithm. We demonstrate the effectiveness of AL in multi-label text classification in the clinical domain. In this context, we apply a set of well-known AL methods to help automatically assign ICD-9 codes on the MIMIC-III dataset. Our results show that the selection of informative instances provides satisfactory classification with a significantly reduced training set (8.3\\% of the total instances). We conclude that AL methods can significantly reduce the manual annotation cost while preserving model performance.","authors":"Martha Ferreira (Dalhousie University); Michal Malyska and Nicola Sahar (Semantic Health); Riccardo Miotto (Icahn School of Medicine at Mount Sinai); Fernando Paulovich (Dalhousie University); Evangelos Milios (Dalhousie University, Faculty of Computer Scienc)","title":"Active Learning for Medical Code Assignment"},{"UID":"21WS07","abstract":"Assessment of COVID-19 pandemic predictions indicates that differential equation-based epidemic spreading models are less than satisfactory in the contemporary world of intense human connectivity. Network-based simulations are more apt for studying the contagion dynamics due to their ability to model heterogeneity of human interactions. However, the quality of predictions in network-based models depends on how well the underlying wire-frame approximates the real social contact network of the population. In this paper, we propose a framework to create a modular wire-frame to mimic the social contact network of geography by lacing it with demographic information. The proposed inter-connected network sports small-world topology, accommodates density variations in the geography, and emulates human interactions in family, social, and work spaces. The resulting wire-frame is a generic and potent instrument for urban planners, demographers, economists, and social scientists to simulate different \"what-if\" scenarios and predict epidemic variables. The basic frame can be laden with any economic, social, urban data that can potentially shape human connectance. We present a preliminary study of the impact of variations in contact patterns due to density and demography on the epidemic variables.","authors":"Kirti Jain (Department of Computer Science, University of Delhi, Delhi, India); Sharanjit Kaur (Acharya Narendra Dev College, University of Delhi, Delhi, India); Vasudha Bhatnagar (Department of Computer Science, University of Delhi, Delhi, India)","title":"Framing Social Contact Networks for Contagion Dynamics"},{"UID":"21WS08","abstract":"Shaping an epidemic with an adaptive contact restriction policy that balances the disease and socioeconomic impact has been the holy grail during the COVID-19 pandemic. Most of the existing work on epidemiological models focuses on scenario-based forecasting via simulation but techniques for explicit control of epidemics via an analytical framework are largely missing. In this paper, we consider the problem of determining the optimal control policy for transmission rate assuming SIR dynamics, which is the most widely used epidemiological paradigm. We first demonstrate that the SIR model with infectious patients and susceptible contacts (i.e., product of transmission rate and susceptible population) interpreted as predators and prey respectively reduces to a Lotka-Volterra (LV) predator-prey model. The modified SIR system (LVSIR) has a stable equilibrium point, an 'energy' conservation property, and exhibits bounded cyclic behaviour similar to an LV system. This mapping permits a theoretical analysis of the control problem supporting some of the recent simulation-based studies that point to the benefits of periodic interventions. We use a control-Lyapunov approach to design adaptive control policies (CoSIR) to nudge the SIR model to the desired equilibrium that permits ready extensions to richer compartmental models. We also describe a practical implementation of this transmission control method by approximating the ideal control with a finite, but a time-varying set of restriction levels. We provide experimental results comparing with periodic lockdowns on few different geographical regions (India, Mexico, Netherlands) to demonstrate the efficacy of this approach.","authors":"Harsh Maheshwari and Shreyas Shetty (Flipkart Internet Private Ltd.); Nayana Bannur (Wadhwani AI); Srujana Merugu (Independent)","title":"CoSIR: Managing an Epidemic via Optimal Adaptive Control of Transmission Rate Policy"},{"UID":"21WS09","abstract":"A major obstacle to the integration of deep learning models for chest x-ray interpretation into clinical settings is the lack of understanding of their failure modes. In this work, we first investigate whether there are clinical subgroups that chest x-ray models are likely to misclassify. We find that older patients and patients with a lung lesion or pneumothorax finding have a higher probability of being misclassified on some diseases. Second, we develop misclassification predictors on chest x-ray models using their outputs and clinical features. We find that our best performing misclassification identifier achieves an AUROC close to 0.9 for most diseases. Third, employing our misclassification identifiers, we develop a corrective algorithm to selectively flip model predictions that have high likelihood of misclassification at inference time. We observe F1 improvement on the prediction of Consolidation (0.008, 95%CI[0.005, 0.010]) and Edema (0.003, 95%CI[0.001, 0.006]). By carrying out our investigation on ten distinct and high-performing chest x-ray models, we are able to derive insights across model architectures and offer a generalizable framework applicable to other medical imaging tasks.","authors":"Emma Chen, Andy Kim, Rayan Krishnan, Andrew Y. Ng, and Pranav Rajpurkar (Stanford University)","title":"CheXbreak: Misclassification Identification for Deep Learning Models Interpreting Chest X-rays"},{"UID":"21WS10","abstract":"Contrastive learning is a form of self-supervision that can leverage unlabeled data to produce pretrained models. While contrastive learning has demonstrated promising results on natural image classification tasks, its application to medical imaging tasks like chest X-ray interpretation has been limited. In this work, we propose MoCo-CXR, which is an adaptation of the contrastive learning method Momentum Contrast (MoCo), to produce models with better representations and initializations for the detection of pathologies in chest X-rays. In detecting pleural effusion, we find that linear models trained on MoCo-CXR-pretrained representations outperform those without MoCo-CXR-pretrained representations, indicating that MoCo-CXR-pretrained representations are of higher-quality. End-to-end fine-tuning experiments reveal that a model initialized via MoCo-CXR-pretraining outperforms its non-MoCo-CXR-pretrained counterpart. We find that MoCo-CXR-pretraining provides the most benefit with limited labeled training data. Finally, we demonstrate similar results on a target Tuberculosis dataset unseen during pretraining, indicating that MoCo-CXR-pretraining endows models with representations and transferability that can be applied across chest X-ray datasets and tasks.","authors":"Hari Sowrirajan, Jingbo Yang, Andrew Ng, and Pranav Rajpurkar (Stanford University)","title":"MoCo-CXR: MoCo Pretraining Improves Representation and Transferability of Chest X-ray Models"},{"UID":"21WS11","abstract":"Inertial Measurement Unit (IMU) sensors are becoming increasingly ubiquitous in everyday devices such as smartphones, fitness watches, etc. As a result, the array of health-related applications that tap onto this data has been growing, as well as the importance of designing accurate prediction models for tasks such as human activity recognition (HAR). However, one important task that has received little attention is the prediction of an individual's heart rate when undergoing a physical activity using IMU data. This could be used, for example, to determine which activities are safe for a person without having him/her actually perform them. We propose a neural architecture for this task composed of convolutional and LSTM layers, similarly to the state-of-the-art techniques for the closely related task of HAR. However, our model includes a convolutional network that extracts, based on sensor data from a previously executed activity, a physical conditioning embedding (PCE) of the individual to be used as the LSTM's initial hidden state. We evaluate the proposed model, dubbed PCE-LSTM, when predicting the heart rate of 23 subjects performing a variety of physical activities from IMU-sensor data available in public datasets (PAMAP2, PPG-DaLiA). For comparison, we use as baselines the only model specifically proposed for this task, and an adapted state-of-the-art model for HAR. PCE-LSTM yields over 10% lower mean absolute error. We demonstrate empirically that this error reduction is in part due to the use of the PCE. Last, we use the two datasets (PPG-DaLiA, WESAD) to show that PCE-LSTM can also be successfully applied when photoplethysmography (PPG) sensors are available to rectify heart rate measurement errors caused by movement, outperforming the state-of-the-art deep learning baselines by more than 30%.","authors":"Davi Pedrosa de Aguiar, Ot\u00e1vio Augusto Silva, and Fabricio Murai (Universidade Federal de Minas Gerais)","title":"Encoding physical conditioning from inertial sensors for multi-step heart rate estimation"},{"UID":"21WS12","abstract":"COVID-19 pandemic has been ravaging the world we know since it's insurgence. Computer-Aided Diagnosis (CAD) systems with high precision and reliability can play a vital role in the battle against COVID-19. Most of the existing works in the literature focus on developing sophisticated methods yielding high detection performance yet not addressing the issue of predictive uncertainty. Uncertainty estimation has been explored heavily in the literature for Deep Neural Networks; however, not much work focused on this issue on COVID-19 detection. In this work, we explore the efficacy of state-of-the-art (SOTA) uncertainty estimation methods on COVID-19 detection. We propose to augment the best performing method by using feature denoising algorithm to gain higher Positive Predictive Value (PPV) on COVID positive cases. Through extensive experimentation, we identify the most lightweight and easy-to-deploy uncertainty estimation framework that can effectively identify the confusing COVID-19 cases for expert analysis while performing comparatively with the existing resource heavy uncertainty estimation methods. In collaboration with medical professionals, we further validate the results to ensure the viability of the framework in clinical practice.","authors":"Krishanu Sarker (Georgia State University); Sharbani Pandit (Georgia Institute of Technology); Anupam Sarker (Institute of Epidemiology, Disease Control and Research); Saeid Belkasim and Shihao Ji (Georgia State University)","title":"Towards Reliable and Trustworthy Computer-Aided Diagnosis Predictions: Diagnosing COVID-19 from X-Ray Images"},{"UID":"21WS13","abstract":"We systematically evaluate the performance of deep learning models in the presence of diseases not labeled for or present during training. First, we evaluate whether deep learning models trained on a subset of diseases (seen diseases) can detect the presence of any one of a larger set of diseases. We find that models tend to falsely classify diseases outside of the subset (unseen diseases) as \"no disease\". Second, we evaluate whether models trained on seen diseases can detect seen diseases when co-occurring with diseases outside the subset (unseen diseases). We find that models are still able to detect seen diseases even when co-occurring with unseen diseases. Third, we evaluate whether feature representations learned by models may be used to detect the presence of unseen diseases given a small labeled set of unseen diseases. We find that the penultimate layer provides useful features for unseen disease detection. Our results can inform the safe clinical deployment of deep learning models trained on a non-exhaustive set of disease classes.","authors":"Siyu Shi (Department of Medicine, School of Medicine, Stanford University); Ishaan Malhi, Kevin Tran, Andrew Y. Ng, and Pranav Rajpurkar (Department of Computer Science, Stanford University)","title":"CheXseen: Unseen Disease Detection for Deep Learning Interpretation of Chest X-rays"},{"UID":"21WS14","abstract":"We explore the application of graph neural networks (GNNs) to the problem of estimating exposure to an infectious pathogen and probability of transmission. Specifically, given a datatset in which a subset of patients are known to be infected and information in the form of a graph about who has interacted with whom, we aim to directly estimate transmission dynamics, i.e., what types of interactions (e.g., length and number) lead to transmission events. While, graph neural networks (GNNs) have proven capable of learning meaningful representations from graph data, they commonly assume tasks with high homophily (i.e., nodes that share an edge look similar). Recently researchers have proposed techniques for addressing problems with low homophily (e.g., adding residual connections to GNNs). In our problem setting, homophily is high on average, the majority of patients do not become infected. But, homophily remains low with respect to the minority class. In this paper, we characterize this setting as particularly challenging for GNNs. Given the asymmetry in homophily between classes, we hypothesize that solutions designed to address low homophily on average will not suffice and instead propose a solution based on attention. Applied to both real-world and synthetic network data, we test this hypothesis and explore the ability of GNNs to learn complex transmission dynamics directly from network data. Overall, attention proves to be an effective mechanism for addressing low homophily in the minority class (AUROC with 95\\% CI: GCN 0.684 (0.659,0.710) vs. GAT 0.715 (0.688,0.742)) and such a data-driven approach can outperform approaches based on potentially flawed expert knowledge.","authors":"Jeeheh Oh (University of Michigan, Ann Arbor); Jenna Wiens (University of Michigan)","title":"A Data-Driven Approach to Estimating Infectious Disease Transmission from Graphs: A Case of Class Imbalance Driven Low Homophily"},{"UID":"21WS15","abstract":"Explainable artificial intelligence provides an opportunity to improve prediction accuracy over standard linear models using 'black box' machine learning (ML) models while still revealing insights into a complex outcome such as all-cause mortality. We propose the IMPACT (Interpretable Machine learning Prediction of All-Cause morTality) framework that implements and explains complex, non-linear ML models in epidemiological research, by combining a tree ensemble mortality prediction model and an explainability method. We use 133 variables from NHANES 1999-2014 datasets (number of samples: ?? = 47, 261) to predict all-cause mortality. To explain our model, we extract local (i.e., per-sample) explanations to verify well-studied mortality risk factors, and make new dis- coveries. We present major factors for predicting ??-year mortality (?? = 1, 3, 5) across different age groups and their individualized im- pact on mortality prediction. Moreover, we highlight interactions between risk factors associated with mortality prediction, which leads to findings that linear models do not reveal. We demonstrate that compared with traditional linear models, tree-based models have unique strengths such as: (1) improving prediction power, (2) making no distribution assumptions, (3) capturing non-linear relationships and important thresholds, (4) identifying feature interactions, and (5) detecting different non-linear relationships between models. Given the popularity of complex ML models in prognostic research, combining these models with explainability methods has implications for further applications of ML in medical fields. To our knowledge, this is the first study that combines complex ML models and state-of-the-art feature attributions to explain mortality prediction, which enables us to achieve higher prediction accuracy and gain new insights into the effect of risk factors on mortality.","authors":"Wei Qiu, Hugh Chen, Ayse Berceste Dincer, and Su-In Lee (Paul G. Allen School of Computer Science and Engineering, University of Washington)","title":"Interpretable Machine Learning Prediction of All-cause Mortality"},{"UID":"21WS16","abstract":"Cardiogenic shock is a deadly and complicated illness. Despite extensive research into treating cardiogenic shock, mortality remains high and has not decreased over time. Patients suffering from cardiogenic shock are highly heterogeneous, and developing an understanding of phenotypes among these patients is crucial for understanding this disease and the appropriate treatments for individual patients. In this work, we develop a deep mixture of experts approach to jointly find phenotypes among patients with cardiogenic shock while simultaneously estimating their risk of in-hospital mortality. Although trained with information regarding treatment and outcomes, after training, the proposed model is decomposable into a network that clusters patients into phenotypes from information available prior to treatment. This model is validated on a synthetic dataset and then applied to a cohort of 28,304 patients with cardiogenic shock. The full model predicts in-hospital mortality on this cohort with an AUROC of 0.85 \u00b1 0.01. The model discovers five phenotypes among the population, finding statistically different mortality rates among them and among treatment choices within those groups. This approach allows for grouping patients in clinical clusters with different rates of device utilization and different risk of mortality. This approach is suitable for jointly finding phenotypes within a clinical population and in modeling risk among that population.","authors":"Nathan C. Hurley (Texas A&M University); Alyssa Berkowitz (Yale University); Frederick Masoudi (University of Colorado School of Medicine); Joseph Ross and Nihar Desai (Yale University); Nilay Shah (Mayo Clinic); Sanket Dhruva (UCSF School of Medicine); Bobak J. Mortazavi (Texas A&M University)","title":"Outcomes-Driven Clinical Phenotyping in Patients with Cardiogenic Shock for Risk Modeling and Comparative Treatment Effectiveness"},{"UID":"21WS17","abstract":"Severe infectious diseases such as the novel coronavirus (COVID-19) pose a huge threat to public health. Stringent control measures, such as school closures and stay-at-home orders, while having significant effects, also bring huge economic losses. In the face of an emerging infectious disease, a crucial question for policymakers is how to make the trade-off and implement the appropriate interventions timely, with the existence of huge uncertainty. In this work, we propose a Multi-Objective Model-based Reinforcement Learning framework to facilitate data-driven decision making and minimize the long-term overall cost. Specifically, at each decision point, a Bayesian epidemiological model is first learned as the environment model, and then the proposed model-based multi-objective planning algorithm is applied to find a set of Pareto-optimal policies. This framework, combined with the prediction bands for each policy, provides a real-time decision support tool for policymakers. The application is demonstrated with the spread of COVID-19 in China.","authors":"Runzhe Wan, Xinyu Zhang, and Rui Song (North Carolina State University)","title":"Multi-Objective Model-based Reinforcement Learning for Infectious Disease Control"},{"UID":"21WS18","abstract":"With the growing amount of text in health data, there have beenrapid advances in large pre-trained models that can be applied to awide variety of biomedical tasks with minimal task-specific mod-ifications. Emphasizing the cost of these models, which renderstechnical replication challenging, this paper summarizes experi-ments conducted in replicating BioBERT and further pre-trainingand careful fine-tuning in the biomedical domain. We also inves-tigate the effectiveness of domain-specific and domain-agnosticpre-trained models across downstream biomedical NLP tasks. Ourfinding confirms that pre-trained models can be impactful in somedownstream NLP tasks (QA and NER) in the biomedical domain;however, this improvement may not justify the high cost of domain-specific pre-training.","authors":"Paul Grouchi (Untether AI); Shobhit Jain (Manulife); Michael Liu (Tealbook); Kuhan Wang (CIBC); Max Tian (Adeptmind); Nidhi Arora (Intact); Hillary Ngai (University of Toronto); Faiza Khan Khattak (Manulife); Elham Dolatabadi and Sedef Akinli Kocak (Vector Institute)","title":"An Experimental Evaluation of Transformer-based LanguageModels in the Biomedical Domain"},{"UID":"21WS19","abstract":"Question Answering (QA) is a widely-used framework for developing and evaluating an intelligent machine. In this light, QA on Electronic Health Records (EHR), namely EHR QA, can work as a crucial milestone towards developing an intelligent agent in healthcare. EHR data are typically stored in a  relational database, which can also be converted to a directed acyclic graph, allowing two approaches for EHR QA: Table-based QA and Knowledge Graph-based QA. We hypothesize that the graph-based approach is more suitable for EHR QA as graphs can represent relations between entities and values more naturally compared to tables, which essentially require JOIN operations. In this paper, we propose a graph-based EHR QA where natural language queries are converted to SPARQL instead of SQL. To validate our hypothesis, we create four EHR QA datasets (graph-based VS table-based, and simplified database schema VS original database schema), based on a table-based dataset MIMICSQL. We test both a simple Seq2Seq model and a state-of-the-art EHR QA model on all datasets where the graph-based datasets facilitated up to 34% higher accuracy than the table-based dataset without any modification to the model architectures. Finally, all datasets will be open-sourced to encourage further EHR QA research in both directions.","authors":"Junwoo Park and Youngwoo Cho (Korea Advanced Institute of Science and Technology (KAIST)); Haneol Lee (Yonsei University); Jaegul Choo and Edward Choi (Korea Advanced Institute of Science and Technology (KAIST))","title":"Knowledge Graph-based Question Answering with Electronic Health Records"},{"UID":"21WS20","abstract":"There is an increased adoption of electronic health record (EHR) systems by variety of hospitals and medical centers. This provides an opportunity to leverage automated computer systems in assisting healthcare workers. One of the least utilized but rich source of patient information is the unstructured clinical text. In this work, we develop \\model, a chart-aware temporal attention network for learning patient representations from clinical notes. We introduce a novel representation where each note is considered a single unit, like a sentence, and composed of attention-weighted words. The notes in turn are aggregated into a patient representation using a second weighting unit, note attention. Unlike standard attention computations which focus only on the content of the note, we incorporate the chart-time for each note as a constraint for attention calculation. This allows our model to focus on notes closer to the prediction time. Using the MIMIC-III dataset, we empirically show that our patient representation and attention calculation achieves the best performance in comparison with various state-of-the-art baselines for one-year mortality prediction and 30-day hospital readmission. Moreover, the attention weights can be used to offer transparency into our model's predictions.","authors":" Zelalem Gero and Joyce Ho (Emory University)","title":"CATAN: Chart-aware temporal attention network for clinical text classification"},{"UID":"21WS21","abstract":"Survival analysis is a challenging variation of regression modeling because of the presence of censoring, where the outcome measurement is only partially known, due to, for example, loss to follow up. Such problems come up frequently in medical applications, making survival analysis a key endeavor in biostatistics and machine learning for healthcare, with Cox regression models being amongst the most commonly employed models. We describe a new approach for survival analysis regression models, based on learning mixtures of Cox regressions to model individual survival distributions. We propose an approximation to the Expectation Maximization algorithm for this model that does hard assignments to mixture groups to make optimization efficient. In each group assignment, we fit the hazard ratios within each group using deep neural networks, and the baseline hazard for each mixture component non-parametrically. We perform experiments on multiple real world datasets, and look at the mortality rates of patients across ethnicity and gender. We emphasize the importance of calibration in healthcare settings and demonstrate that our approach outperforms classical and modern survival analysis baselines, both in terms of discriminative performance and calibration, with large gains in performance on the minority demographics.","authors":"Chirag Nagpal (Carnegie Mellon University); Steve Yadlowsky; Negar Rostamzadeh; and Katherine Heller (Google Brain)","title":"Deep Cox Mixtures for Survival Regression"}]},"2022":{"highlights":"<div class=\"page-content live text-center\">\n<!-- Slides Live-->\n<div class=\"row p-3\">\n    <div class=\"col-12 bd-content\">\n    <h3>Day 1 - April 7th</h3>\n    </div>\n</div>\n<div id=\"slideslive-embed\" class=\"col-md-12 col-xs-12 my-auto p-2 hide\" data-activedate=\"2021-04-14T23:59:00.00\">\n  <div id=\"presentation-embed-38979174\" class=\"slp my-auto\"></div>\n  <script src='https://slideslive.com/embed_presentation.js'></script>\n  <script>\n    embed = new SlidesLiveEmbed(\"presentation-embed-38979174\", {\n        presentationId: \"38979174\",\n        autoPlay: false, // change to true to autoplay the embedded presentation\n        verticalEnabled: true,\n        verticalWhenWidthLte: 480,\n    });\n  </script>\n</div>\n<div class=\"row p-3\">\n    <div class=\"col-12 bd-content\">\n    <h3>Day 2 - April 8th</h3>\n    </div>\n</div>\n<div id=\"slideslive-embed2\" class=\"col-md-12 col-xs-12 my-auto p-2 hide\" data-activedate=\"2021-04-14T23:59:00.00\">\n  <div id=\"presentation-embed-38979175\" class=\"slp my-auto\"></div>\n  <script>\n    embed = new SlidesLiveEmbed(\"presentation-embed-38979175\", {\n        presentationId: \"38979175\",\n        autoPlay: false, // change to true to autoplay the embedded presentation\n        verticalEnabled: true,\n        verticalWhenWidthLte: 480,\n    });\n  </script>\n</div>\n</div>\n\n\n### Governing Board\n###### **General Chairs**\n- Dr. Tristan Naumann of Microsoft Research\n- Dr. Joyce Ho of Emory University\n###### **Program Chairs**\n- Dr. Sherri Rose of Stanford University\n- Matthew McDermott of MIT\n###### **Proceedings Chairs**\n- Dr. George Chen of Carnegie Mellon University\n- Dr. Tom Pollard of MIT\n- Gerardo Flores of Google\n###### **Track Chairs**\n- ###### **Models and Methods**\n    * Dr. Rahul Krishnan of University of Toronto and Vector Institute\n    * Dr. Shalmali Joshi of Harvard University\n    * Dr. Michael Hughes of Tufts University\n    * Dr. Yuyin Zhou of Stanford\n    * Dr. Uri Shalit of Technion\n- ###### **Applications and Practice**\n    * Dr. Alistair Johnson of The Hospital for Sick Children\n    * Dr. Judy Gichoya of Emory University\n    * Emma Rocheteau of University of Cambridge\n    * Dr. Lifang He of Lehigh University\n- ###### **Impact and Society**\n    * Dr. Bobak Mortazavi of Texas A&M University \n    * Dr. Stephen Pfohl of Stanford University\n    * Dr. Farzan Sasangohar of Texas A&M University\n###### **Communications Chairs**\n- Dr. Sanja \u0160\u0107epanovi\u0107 of Bell Labs Cambridge\n- Emily Alsentzer of Harvard University and MIT\n- Dr. Ayah Zirikly of Johns Hopkins University\n###### **Finance Chairs**\n- Dr. Brett Beaulieu-Jones of Harvard Medical School\n- Dr. Ahmed Alaa of Harvard University and MIT\n- Tasmie Sarker of Association for Health Learning and Inference\n###### **Tutorial Chairs**\n- Dr. Jessica Gronsbell of University of Toronto\n- Harvineet Singh of New York University\n###### **Virtual Chairs**\n- Dr. Stephanie Hyland of Microsoft Research Cambridge\n- Dr. Ioakeim Perros of HEALTH[at]SCALE\n- Brian Gow of MIT\n###### **Logistics Chair**\n- Tasmie Sarker of Association for Health Learning and Inference\n\n\n### Steering Committee\n- Dr. Yindalon Aphinyanaphongs of NYU\n- Dr. Leo Celi of MIT\n- Dr. Nigam Shah of Stanford University\n- Dr. Stephen Friend of Oxford University\n- Dr. Alan Karthikesalingam of Google Health UK\n- Dr. Ziad Obermeyer of University of California, Berkeley\n- Dr. Samantha Kleinberg of Stevens Institute of Technology\n- Dr. Anna Goldenberg of The Hospital for Sick Children Research Institute\n- Dr. Lucila Ohno-Machado of University of California, San Diego\n- Dr. Noemie Elhadad of Columbia University\n- Dr. Katherine Heller at Google Research\n- Dr. Laura Rosella of Dalla Lana School of Public Health, University of Toronto\n- Dr. Shakir Mohamed of DeepMind\n\n### Sponsors\nThank you to our 2022 sponsors: HEALTH[at]SCALE (Silver), the Vector Institute (Silver) and Microsoft (Bronze)!\n","proceedings":[],"speakers":[{"UID":"S01","abstract":"It has been shown that equalizing health disparities can avert more deaths than the number of lives saved by medical advances alone in the same time frame. Moreover, without a simultaneous focus on innovations and equity, advances in health for one group can occur at the cost of added challenges for another. In this talk I will introduce the science of health disparities and juxtapose it with the machine learning subfield of algorithmic fairness. Given the key foci and principles of health equity and health disparities within public and population health, I will show examples of how machine learning and principles of public and population health can be synergized for using data to advance the science of health disparities and sustainable health of entire populations.","bio":"Dr. Rumi Chunara is an Associate Professor at New York University, jointly appointed at the Tandon School of Engineering (in Computer Science) and the School of Global Public Health (in Biostatistics/Epidemiology). Her PhD is from the Harvard-MIT Division of Health Sciences and Technology and her BSc from Caltech. Her research group focuses on developing computational and statistical approaches for acquiring, integrating and using data to improve population and public health. She is an MIT TR35, NSF Career, Bill & Melinda Gates Foundation Grand Challenges, Facebook Research and Max Planck Sabbatical award winner.","image":"static/images/speakers/rumi_chunara.jpg","institution":"New York University","slideslive_active_date":"","slideslive_id":"","speaker":"Rumi Chunara","title":"Algorithmic fairness and the science of health disparities","website":""},{"UID":"S02","abstract":"A common goal in genome-wide association (GWA) studies is to characterize the relationship between genotypic and phenotypic variation. Linear models are widely used tools in GWA analyses, in part, because they provide significance measures which detail how individual single nucleotide polymorphisms (SNPs) are statistically associated with a trait or disease of interest. However, traditional linear regression largely ignores non-additive genetic variation, and the univariate SNP-level mapping approach has been shown to be underpowered and challenging to interpret for certain trait architectures. While machine learning (ML) methods such as neural networks are well known to account for complex data structures, these same algorithms have also been criticized as \u201cblack box\u201d since they do not naturally carry out statistical hypothesis testing like classic linear models. This limitation has prevented ML approaches from being used for association mapping tasks in GWA applications. In this talk, we present flexible and scalable classes of Bayesian feedforward models which provide interpretable probabilistic summaries such as posterior inclusion probabilities and credible sets which allows researchers to simultaneously perform (i) fine-mapping with SNPs and (ii) enrichment analyses with SNP-sets on complex traits. While analyzing real data assayed in diverse self-identified human ancestries from the UK Biobank, the Biobank Japan, and the PAGE consortium we demonstrate that interpretable ML has the power to increase the return on investment in multi-ancestry biobanks. Furthermore, we highlight that by prioritizing biological mechanism we can identify associations that are robust across ancestries---suggesting that ML can play a key role in making personalized medicine a reality for all.","bio":"Lorin Crawford is a Senior Researcher at Microsoft Research New England. He also holds a position as the RGSS Assistant Professor of Biostatistics at Brown University. His scientific research interests involve the development of novel and efficient computational methodologies to address complex problems in statistical genetics, cancer pharmacology, and radiomics (e.g., cancer imaging). Dr. Crawford has an extensive background in modeling massive data sets of high-throughput molecular information as it pertains to functional genomics and cellular-based biological processes. His most recent work has earned him a place on Forbes 30 Under 30 list, The Root 100 Most Influential African Americans list, and recognition as an Alfred P. Sloan Research Fellow and a David & Lucile Packard Foundation Fellowship for Science and Engineering. Before joining Brown, Dr. Crawford received his PhD from the Department of Statistical Science at Duke University and received his Bachelor of Science degree in Mathematics from Clark Atlanta University.","image":"static/images/speakers/lorin_crawford.jpg","institution":"Microsoft Research New England; Brown University","slideslive_active_date":"","slideslive_id":"","speaker":"Lorin Crawford","title":"Machine Learning for Human Genetics: A Multi-Scale View on Complex Traits and Disease","website":""},{"UID":"S03","abstract":"Machine learning presents an opportunity to understand the patient journey over high dimensional data in the clinical context. This is aligned to one of the foundational issues of machine learning for healthcare: how do you represent a patient state. Improving state representations allows us to (i) visualise/cluster deteriorating patients, (ii) understand the patient journey and thus heterogeneous pathways to improvement or clinical deterioration which encompasses different data modalities; and thus (iii) more quickly identify situations for intervention. In this talk, I present motivating examples of understanding heterogeneity as a route towards understanding health and personalising healthcare interventions.","bio":"Danielle Belgrave is a Senior Staff Research Scientist at DeepMind. Prior to joining DeepMind she worked in the Healthcare Intelligence group at Microsoft Research and was a tenured research fellow at Imperial College London. Her research focuses on integrating medical domain knowledge, machine learning and causal modelling frameworks to understand health. She obtained a BSc in Mathematics and Statistics from London School of Economics, an MSc in Statistics from University College London and a PhD in the area of machine learning in health applications from the University of Manchester.","image":"static/images/speakers/danielle_belgrave.jpg","institution":"DeepMind","slideslive_active_date":"","slideslive_id":"","speaker":"Danielle Belgrave","title":"Understanding Heterogeneity as a Route to Understanding Health","website":""},{"UID":"S04","abstract":"In my talk, I will describe the work that I have been doing since March 2020, leading a multi-disciplinary team of 20+ volunteer scientists working very closely with the Presidency of the Valencian Government in Spain on 4 large areas: (1) human mobility modeling; (2) computational epidemiological models (both metapopulation, individual and LSTM-based models); (3) predictive models; and (4) a large-scale, online citizen surveys called the COVID19impactsurvey (https://covid19impactsurvey.org) with over 700,000 answers worldwide. This survey has enabled us to shed light on the impact that the pandemic is having on people's lives. I will present the results obtained in each of these four areas, including winning the 500K XPRIZE Pandemic Response Challenge and obtaining a best paper award at ECML-PKDD 2021. I will share the lessons learned in this very special initiative of collaboration between the civil society at large (through the survey), the scientific community (through the Expert Group) and a public administration (through the Commissioner at the Presidency level). For those interested in knowing more, WIRED magazine published an extensive article describing our story: https://www.wired.co.uk/article/valencia-ai-covid-data.","bio":"Nuria Oliver is Co-founder and Vice-president of ELLIS (The European Laboratory for Learning and Intelligent Systems), Co-founder and Director of the ELLIS Unit Alicante, Chief Data Scientist at Data-Pop Alliance and Chief Scientific Advisor to the Vodafone Institute. Nuria earned her PhD from MIT. She is a Fellow of the ACM, IEEE and EurAI. She is the youngest member (and fourth female) in the Spanish Royal Academy of Engineering. She is also the only Spanish scientist at SIGCHI Academy. She has over 25 years of research experience in human-centric AI and is the author of over 180 widely cited scientific articles as well as an inventor of 40+ patents and a public speaker. Her work is regularly featured in the media and has received numerous recognitions, including the Spanish National Computer Science Award, the MIT TR100 (today TR35), Young Innovator Award (first Spanish scientist to receive this award); the 2020 Data Scientist of the Year by ESRI, the 2021 King Jaume I award in New Technologies and the 2021 Abie Technology Leadership Award. In March of 2020, she was appointed Commissioner to the President of the Valencian Government on AI Strategy and Data Science against COVID-19. In that role, she has recently co-led ValenciaIA4COVID, the winning team of the 500k XPRIZE Pandemic Response Challenge. Their work was featured in WIRED, among other media.","image":"static/images/speakers/nuria_oliver.jpg","institution":"ELLIS","slideslive_active_date":"","slideslive_id":"","speaker":"Nuria Oliver","title":"Data Science against COVID-19","website":""},{"UID":"S05","abstract":"Spoiler alert: No. And yes, it is much, much further. Public health has not traditionally been a data-driven field. The good news is that has been changing in recent years, accelerated significantly by the COVID epidemic. But public health and human services organizations have many more fundamental things to worry about before we will have the luxury of considering what machine learning can enable. These fundamentals include data-related facets such as electronic data capture and exchange, data quality, data governance, information technology infrastructure, and data management best practices. In addition, data literacy, workforce development, and compensation that is a fraction of what 'quants' can earn in industry are also major stumbling blocks toward advanced analytics in public health. At the start of the COVID pandemic, many communicable diseases were reporting by fax machine and then hand-entered into a database. Although there was significant interest in predictive modeling to project hospital capacity out in the future, even the most sophisticated models were of limited use to policy makers beyond basic trends and observations from the front lines. The most notable exception, where AI is in fact proving useful in public health, is in the use of 'robotic process automation' (RPA) as a band-aid for poorly designed systems that require mindless human intervention. These tools serve as workarounds for systems that lack interoperability by emulating human users to do the grunt work of data entry and wrangling. This talk will be  a reality check from the trenches of state government on the heels of the COVID-19 pandemic.","bio":"Dr. Tenenbaum serves as the Chief Data Officer (CDO) for DHHS, where she oversees data strategy across the Department enabling the use of information to inform and evaluate policy and improve the health and well-being of residents of North Carolina. Prior to taking on the role of CDO, Dr. Tenenbaum was a founding faculty member of the Division of Translational Biomedical Informatics within Duke University's Department of Biostatistics and Bioinformatics where her research focused on informatics methods to enable precision medicine, particularly in mental health. She is also interested in ethical, legal, and social issues around big data and precision medicine. Nationally, Dr. Tenenbaum has served as Associate Editor for the Journal of Biomedical Informatics and as an elected member of the Board of Directors for the American Medical Informatics Association (AMIA). She currently serves on the Board of Scientific Counselors for the National Library of Medicine. After earning her bachelor's degree in biology from Harvard, Dr. Tenenbaum was a Program Manager at Microsoft Corporation in Redmond, WA for six years before pursuing a PhD in biomedical informatics at Stanford University. Dr. Tenenbaum is a strong promoter and advocate of young women interested in STEM (science, technology, engineering, and math) careers.","image":"static/images/speakers/jessica_tenenbaum.jpg","institution":"North Carolina Department of Health and Human Services; Duke University School of Medicine","slideslive_active_date":"","slideslive_id":"","speaker":"Jessica Tenenbaum","title":"Machine Learning in Public Health: are we there yet?","website":""},{"UID":"S06","abstract":"AI systems tend to amplify biases and disparities. When we feed them data that reflects our biases, they mimic them---from antisemitic chatbots to racially biased software. In this talk I am going to discuss two examples how AI can help us reduce biases and disparities. First I am going to explain how we can use AI to understand why underserved populations experience higher levels of pain. This is true even after controlling for the objective severity of diseases like osteoarthritis, as graded by human physicians using medical images, which raises the possibility that underserved patients\u2019 pain stems from factors external to the knee, such as stress. We develop a deep learning approach to measure the severity of osteoarthritis, by using knee X-rays to predict patients\u2019 experienced pain and show that this approach dramatically reduces unexplained racial disparities in pain.","bio":"Jure Leskovec is an associate professor of Computer Science at Stanford University, the Chief Scientist at Pinterest, and an Investigator at the Chan Zuckerberg Biohub. He co-founded a machine learning startup Kosei, which was later acquired by Pinterest. Leskovec's research area is machine learning and data science for complex, richly-labeled relational structures, graphs, and networks for systems at all scales, from interactions of proteins in a cell to interactions between humans in a society. Applications include commonsense reasoning, recommender systems, social network analysis, computational social science, and computational biology with an emphasis on drug discovery. This research has won several awards including a Lagrange Prize, Microsoft Research Faculty Fellowship, the Alfred P. Sloan Fellowship, and numerous best paper and test of time awards. It has also been featured in popular press outlets such as the New York Times and the Wall Street Journal. Leskovec received his bachelor's degree in computer science from University of Ljubljana, Slovenia, PhD in machine learning from Carnegie Mellon University and postdoctoral training at Cornell University. You can follow him on Twitter at @jure.","image":"static/images/speakers/jure_leskovec.jpg","institution":"Stanford University","slideslive_active_date":"","slideslive_id":"","speaker":"Jure Leskovec","title":"Reducing bias in machine learning systems: Understanding drivers of pain","website":""}],"tutorials":[{"UID":"T01","abstract":"You\u2019ve created an awesome model that predicts with near 100 percent accuracy. Now what? In this tutorial, we will give insight into the implementation, deployment, integration, and evaluation steps following the building of a clinical model. Specifically, we will discuss each step in the context of informing design choices as you build a model. For example, aggressive feature selection is a necessary step toward integration as real time data streams of all the data points a machine learning model may consume may not be accessible or feasible. We will use our implementation and evaluation of a Covid-19 adverse event model at our institution as a representative case study. This case study will demonstrate the full lifecycle of a clinical model and how we transition from a model to affecting patient outcome and the socio-technical challenges for success.","authors":"Yindalon Aphinyanaphongs","bio":"Yindalon Aphinyanaphongs, MD, PhD (Predictive Analytics Team Lead) is a physician scientist in the Center for Healthcare Innovation and Delivery Science in the Department of Population Health at NYU Langone Health in New York City. Academically, he is an assistant professor and his lab focuses on novel applications of machine learning to clinical problems and the science behind successful translation of predictive models into clinical practice to drive value. Operationally, he is the Director of Operational Data Science and Machine Learning at NYU Langone Health. In this role, he leads a Predictive Analytics Unit composed of data scientists and engineers that build, evaluate, benchmark, and deploy predictive algorithms into the clinical enterprise.","image":"static/images/speakers/yindalon_aphinyanaphongs.jpg","rocketchat_id":"","slideslive_active_date":"2022-03-28T23:59:00.00","slideslive_id":"","title":"Changing patient trajectory: A case study exploring implementation and deployment of clinical machine learning models"},{"UID":"T02","abstract":"The growth of availability and variety of healthcare data sources has provided unique opportunities for data integration and evidence synthesis, which can potentially accelerate knowledge discovery and enable better clinical decision-making.  However, many practical and technical challenges, such as data privacy, high-dimensionality and heterogeneity across different datasets, remain to be addressed. In this talk, I will introduce several methods for the effective and efficient integration of electronic health records and other healthcare datasets. Specifically, we develop communication-efficient distributed algorithms for jointly analyzing multiple datasets without the need of sharing patient-level data. Our algorithms can account for heterogeneity across different datasets. We provide theoretical guarantees for the performance of our algorithms, and examples of implementing the algorithms to real-world clinical research networks.","authors":"Rui Duan","bio":"Dr. Duan is an Assistant Professor of Biostatistics at the Harvard T.H. Chan School of Public Health. She received her Ph.D. in Biostatistics in May 2020 from the University of Pennsylvania. Her research interests focus on three distinct areas: methods for integrating evidence from different data sources, identifying signals from high dimensional data, and accounting for suboptimality of real-world data, such as missing data and measurement errors.","image":"static/images/speakers/rui_duan.jpg","rocketchat_id":"","slideslive_active_date":"2022-03-28T23:59:00.00","slideslive_id":"","title":"Distributed Statistical Learning and Inference with Electronic Health Records Data"},{"UID":"T03","abstract":"Digital health technologies provide promising ways to deliver interventions outside of clinical settings. Wearable sensors and mobile phones provide real-time data streams that provide information about an individual\u2019s current health including both internal (e.g., mood) and external (e.g., location) contexts. This tutorial discusses the algorithms underlying mobile health clinical trials. Specifically, we introduce the micro-randomized trial (MRT), an experimental design for optimizing real time interventions. We define the causal excursion effect and discuss reasons why this effect is often considered the primary causal effect of interest in MRT analysis. We introduce statistical methods for primary and secondary analyses for MRT.  Attendees will have access to synthetic digital health experimental data to better understand online learning and experimentation algorithms, the systems underlying real time delivery of treatment, and their evaluation using collected data.","authors":"Walter Dempsey","bio":"Walter Dempsey is an Assistant Professor of Biostatistics and an Assistant Research Professor in the d3lab located in the Institute of Social Research. My research focuses on Statistical Methods for Digital and Mobile Health. My current work involves three complementary research themes: (1) experimental design and data analytic methods to inform multi-stage decision making in health; (2) statistical modeling of complex longitudinal and survival data; and (3) statistical modeling of complex relational structures such as interaction networks.","image":"static/images/speakers/walter_dempsey.jpg","rocketchat_id":"","slideslive_active_date":"2022-03-28T23:59:00.00","slideslive_id":"","title":"Challenges in Developing Online Learning and Experimentation Algorithms in Digital Health"},{"UID":"T04","abstract":"Does increasing the dosage of a drug treatment cause adverse reactions in patients? This is a causal question: did increased drug dosage cause some patients to have an adverse reaction, or would they have had the reaction anyway due to other factors? A classical approach to studying this causal question from observational data involves applying causal inference techniques to observed measurements of all the relevant clinical variables. However, there is a growing recognition that abundant text data, such as medical records, physicians' notes, or even forum posts from online medical communities, provide a rich source of information for causal inference. In this tutorial, I'll introduce causal inference and highlight the unique challenges that high-dimensional and noisy text data pose. Then, I'll use two text applications involving online forums and consumer complaints to motivate recent approaches that extend natural language processing (NLP) methods in service of causal inference. I'll discuss some new assumptions we need to introduce to bridge the gap between noisy text data and valid causal inference. I'll conclude by summarizing open research questions at the intersection of causal inference and text analysis.","authors":"Dhanya Sridhar","bio":"Dhanya Sridhar is an assistant professor at the University of Montreal and a core academic member at Mila - Quebec AI Institute. She holds a Canada CIFAR AI Chair. She was a postdoctoral researcher at Columbia University and completed her PhD at the University of California, Santa Cruz. Her research interests are at the intersection of causality and machine learning, focusing on applications to text and social network data.","image":"static/images/speakers/dhanya_sridhar.jpg","rocketchat_id":"","slideslive_active_date":"2022-03-28T23:59:00.00","slideslive_id":"","title":"Causal Inference from Text Data"},{"UID":"T05","abstract":"Data visualization is essential for analyzing biomedical and public health data and communicating the findings to key stakeholders. However, the presence of a data visualization is not enough; the choices we make when visualizing data are equally important in establishing its understandability and impact. This tutorial will discuss strategies for visualizing data and evaluating its impact with an appropriate target audience. The aim is to build an intuition for developing and assessing visualizations by drawing on theories of visualization theories together with examples from prior research and ongoing attempts to visualize the present pandemic.","authors":"Ana Crisan","bio":"Ana Crisan is currently a senior research scientist at Tableau, a Salesforce company. She conducts interdisciplinary research that integrates techniques and methods from machine learning, human computer interaction, and data visualization. Her research focuses on the intersection of Data Science and Data Visualization, especially toward the way humans can collaboratively work together with ML/AI systems through visual interfaces. She completed her Ph.D. in Computer Science at the University of British Columbia, under the joint supervision of Dr. Tamara Muzner and Dr. Jennifer L. Gardy. Prior to that, she was a research scientist at the British Columbia Centre for Disease Control and Decipher Biosciences, where she conducted research on machine learning and data visualization research toward applications in infectious disease and cancer genomics, respectively. Her research has appeared in publications of the ACM (CHI), IEEE (TVCG, CG&A), Bioinformatics, and Nature.","image":"static/images/speakers/ana_crisan.jpg","rocketchat_id":"","slideslive_active_date":"2022-03-28T:23:59:00.00","slideslive_id":"","title":"'Are log scales endemic yet?' Strategies for visualizing biomedical and public health data"}]},"2023":{"debates":[{"UID":"D01","abstract":"","bio":"Dr. Chute is the Bloomberg Distinguished Professor of Health Informatics, Professor of Medicine, Public Health, and Nursing at Johns Hopkins University, and Chief Research Information Officer for Johns Hopkins Medicine.  He is also Section Head of Biomedical Informatics and Data Science and Deputy Director of the Institute for Clinical and Translational Research. He received his undergraduate and medical training at Brown University, internal medicine residency at Dartmouth, and doctoral training in Epidemiology and Biostatistics at Harvard.  He is Board Certified in Internal Medicine and Clinical Informatics, and an elected Fellow of the American College of Physicians, the American College of Epidemiology, HL7, the American Medical Informatics Association, and the American College of Medical Informatics (ACMI), as well as a Founding Fellow of the International Academy of Health Sciences Informatics; he was president of ACMI 2017-18. He is an elected member of the Association of American Physicians. His career has focused on how we can represent clinical information to support analyses and inferencing, including comparative effectiveness analyses, decision support, best evidence discovery, and translational research.  He has had a deep interest in the semantic consistency of health data, harmonized information models, and ontology.  His current research focuses on translating basic science information to clinical practice, how we classify dysfunctional phenotypes (disease), and the harmonization and rendering of real-world clinical data including electronic health records to support data inferencing.  He became founding Chair of Biomedical Informatics at Mayo Clinic in 1988, retiring from Mayo in 2014, where he remains an emeritus Professor of Biomedical Informatics. He is presently PI on a spectrum of high-profile informatics grants from NIH spanning translational science including co-lead on the National COVID Cohort Collaborative (N3C). He has been active on many HIT standards efforts and chaired ISO Technical Committee 215 on Health Informatics and chaired the World Health Organization (WHO) International Classification of Disease Revision (ICD-11).","image":"static/images/speakers/christopher_chute.jpg","institution":"Johns Hopkins University","slideslive_active_date":"","slideslive_id":"","speaker":"Christopher Chute","title":"Network studies: As many databases as possible or enough to answer the question quickly?"},{"UID":"D02","abstract":"","bio":"Robert Platt is Professor in the Departments of Epidemiology, Biostatistics, and Occupational Health, and of Pediatrics, at McGill University. He holds the Albert Boehringer I endowed chair in Pharmacoepidemiology, and is Principal Investigator of the Canadian Network for Observational Drug Effect Studies (CNODES). His research focuses on improving statistical methods for the study of medications using administrative data, with a substantive focus on medications in pregnancy. Dr. Platt is an editor-in-chief of Statistics in Medicine and is on the editorial boards of the American Journal of Epidemiology and Pharmacoepidemiology and Drug Safety. He has published over 400 articles, one book and several book chapters on biostatistics and epidemiology.","image":"static/images/speakers/robert_platt.jpg","institution":"McGill University","slideslive_active_date":"","slideslive_id":"","speaker":"Robert Platt","title":"Network studies: As many databases as possible or enough to answer the question quickly?"},{"UID":"D03","abstract":"","bio":"Tianxi Cai is John Rock Professor of Translational Data Science at Harvard, with joint appointments in the Biostatistics Department and the Department of Biomedical Informatics. She directs the Translational Data Science Center for a Learning Health System at Harvard Medical School and co-directs the Applied Bioinformatics Core at VA MAVERIC.  She is a major player in developing analytical tools for mining multi-institutional EHR data, real world evidence, and predictive modeling with large scale biomedical data. Tianxi received her Doctor of Science in Biostatistics at Harvard and was an assistant professor at the University of Washington before returning to Harvard as a faculty member in 2002.","image":"static/images/speakers/t-cai.jpg","institution":"Harvard Medical School","slideslive_active_date":"","slideslive_id":"","speaker":"Tianxi Cai","title":"Data Heterogeneity: More Heterogeneous Data or Less Homogeneous Data?"},{"UID":"D04","abstract":"","bio":"Dr. Yong Chen is Professor of Biostatistics at the Department of Biostatistics, Epidemiology, and Informatics at the University of Pennsylvania (Penn). He directs a Computing, Inference and Learning Lab at University of Pennsylvania, which focuses on integrating fundamental principles and wisdoms of statistics into quantitative methods for tackling key challenges in modern biomedical data. Dr. Chen is an expert in synthesis of evidence from multiple data sources, including systematic review and meta-analysis, distributed algorithms, and data integration, with applications to comparative effectiveness studies, health policy, and precision medicine. He has published over 170 peer-reviewed papers in a wide spectrum of methodological and clinical areas. During the pandemic, Dr. Chen is serving as Director of Biostatistics Core for Pedatric PASC of the RECOVER COVID initiative which a national multi-center RWD-based study on Post-Acute Sequelae of SARS CoV-2 infection (PASC), involving more than 13 million patients across more than 10 health systems. He is an elected fellow of the American Statistical Association, the American Medical Informatics Association, Elected Member of the International Statistical Institute, and Elected Member of the Society for Research Synthesis Methodology.","image":"static/images/speakers/yong_chen.png","institution":"University of Pennsylvania","slideslive_active_date":"","slideslive_id":"","speaker":"Yong Chen","title":"Data Heterogeneity: More Heterogeneous Data or Less Homogeneous Data?"},{"UID":"D05","abstract":"","bio":"Dr. Khaled El Emam is the Canada Research Chair (Tier 1) in Medical AI at the University of Ottawa, where he is a Professor in the School of Epidemiology and Public Health. He is also a Senior Scientist at the Children\u2019s Hospital of Eastern Ontario Research Institute and Director of the multi-disciplinary Electronic Health Information Laboratory, conducting research on privacy enhancing technologies to enable the sharing of health data for secondary purposes, including synthetic data generation and de-identification methods.  Khaled is a co-founder of Replica Analytics, a company that develops synthetic data generation technology, which was recently acquired by Aetion. As an entrepreneur, Khaled founded or co-founded six product and services companies involved with data management and data analytics, with some having successful exits. Prior to his academic roles, he was a Senior Research Officer at the National Research Council of Canada. He also served as the head of the Quantitative Methods Group at the Fraunhofer Institute in Kaiserslautern, Germany. He participates in a number of committees, number of the European Medicines Agency Technical Anonymization Group, the Panel on Research Ethics advising on the TCPS, the Strategic Advisory Council of the Office of the Information and Privacy Commissioner of Ontario, and also is co-editor-in-chief of the JMIR AI journal. In 2003 and 2004, he was ranked as the top systems and software engineering scholar worldwide by the Journal of Systems and Software based on his research on measurement and quality evaluation and improvement. He held the Canada Research Chair in Electronic Health Information at the University of Ottawa from 2005 to 2015. Khaled has a PhD from the Department of Electrical and Electronics.","image":"static/images/speakers/khaled_el_emam.png","institution":"University of Ottawa","slideslive_active_date":"","slideslive_id":"","speaker":"Khaled El Emam","title":"Differential Privacy vs. Synthetic Data"},{"UID":"D06","abstract":"","bio":"Li Xiong is a Samuel Candler Dobbs Professor of Computer Science and Professor of Biomedical Informatics at Emory University. She held a Winship Distinguished Research Professorship from 2015-2018. She has a Ph.D. from Georgia Institute of Technology, an MS from Johns Hopkins University, and a BS from the University of Science and Technology of China. She and her research lab, Assured Information Management and Sharing (AIMS), conduct research on algorithms and methods at the intersection of data management, machine learning, and data privacy and security, with a recent focus on privacy-enhancing and robust machine learning.  She has published over 170 papers and received six best paper or runner up awards. She has served and serves as associate editor for IEEE TKDE, IEEE TDSC, and VLDBJ, general co-chair for ACM CIKM 2022, program co-chair for IEEE BigData 2020 and ACM SIGSPATIAL 2018, 2020, program vice-chair for ACM SIGMOD 2024, 2022, and IEEE ICDE 2023, 2020, and VLDB Sponsorship Ambassador.  Her research is supported by federal agencies including NSF, NIH, AFOSR, PCORI, and industry awards including Google, IBM, Cisco, AT&T, and Woodrow Wilson Foundation. She is an IEEE felllow.","image":"static/images/speakers/li_xiong.png","institution":"Emory University","slideslive_active_date":"","slideslive_id":"","speaker":"Li Xiong","title":"Differential Privacy vs. Synthetic Data"}],"highlights":"<div class=\"page-content live text-center p-3\">\n  <!-- YouTube -->\n<!--   <div class=\"row p-3\">\n    <div class=\"col-12 bd-content\">\n      <h3>Day 1 - June 22nd</h3>\n    </div>\n  </div>\n  <div id=\"youtube-embed\" class=\"col-md-12 col-xs-12 p-3\">\n    <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/HzoBULgJqsQ\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n  </div>\n  <div class=\"row p-3\">\n    <div class=\"col-12 bd-content\">\n      <h3>Day 2 - June 3rd</h3>\n    </div>\n  </div>\n  <div id=\"youtube-embed2\" class=\"col-md-12 col-xs-12 p-3\">\n    <iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/ulAayPsfj2Y\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n  </div> -->\n</div>\n\n\n##### **General Chairs**\n- Joyce Ho of Emory University\n- Andrew Beam of Harvard University\n##### **Program Chairs**\n- Matthew McDermott of Harvard University\n- Emily Alsentzer of Harvard University & Brigham and Women's Hospital\n##### **Track Chairs**\n- ##### **Track 1**\n    * Mike Hughes of Tufts University (Track Lead)\n    * Yuyin Zhou of University of California, Santa Cruz\n    * Rahul Krishnan of University of Toronto & Vector Institute\n    * Jean Feng of University of California, San Francisco\n    * Samantha Kleinberg of Stevens Institute of Technology\n- ##### **Tracks 1 & 2**\n    * Elena Sizikova of Food and Drug Administration\n- ##### **Track 2**\n    * Lifang He of Lehigh University (Track Lead)\n    * Tom Pollard of MIT\n    * Carl Yang of Emory University\n    * Yu Zhang of Lehigh University\n- ##### **Track 3**\n    * Sanja \u0160\u0107epanovi\u0107 of Nokia Bell Labs (Track Lead)\n    * Stephen Pfohl of Google\n    * Dimitris Spathis of Nokia Bell Labs & University of Cambridge\n##### **Proceedings Chair**\n- Bobak Mortazavi of Texas A&M University\n##### **Technology Chairs**\n- Huan He of Harvard University\n- Jiayu Yao of Harvard University & Gladstone Institutes\n##### **Virtual Chair**\n- Brian Gow of MIT\n##### **Communications Chairs**\n- Ioakeim Perros of HEALTH[at]SCALE\n- Anil Palepu of Harvard University & MIT\n##### **Logistics Chairs**\n- Monica Munnangi of Northeastern University\n- Tasmie Sarker of Association for Health Learning and Inference\n##### **Uncoference Chair**\n- Jessica Gronsbell of University of Toronto\n- Rui Duan of Harvard University\n##### **Finance Chairs**\n- Edward Choi of KAIST\n- Harvineet Singh of New York University\n##### **Doctoral Symposium Chair**\n- Tom Hartvigsen of MIT\n\n\n### Sponsors\nThank you to our 2023 sponsors:\n\n- ApolloMed\n- Dandelion Health\n- Genentech\n- Apple\n- Sage BioNetworks\n- AITRICS\n","invited":[{"UID":"I01","abstract":"","bio":"Suchi Saria, PhD, holds the John C. Malone endowed chair and is the Director of the Machine Learning, AI and Healthcare Lab at Johns Hopkins. She is also is the Founder and CEO of Bayesian Health. Her research has pioneered the development of next generation diagnostic and treatment planning tools that use statistical machine learning methods to individualize care. She has written several of the seminal papers in the field of ML and its use for improving patient care and has given over 300 invited keynotes and talks to organizations including the NAM, NAS, and NIH. Dr. Saria has served as an advisor to multiple Fortune 500 companies and her work has been funded by leading organizations including the NIH, FDA, NSF, DARPA and CDC.Dr. Saria\u2019s has been featured by the Atlantic, Smithsonian Magazine, Bloomberg News, Wall Street Journal, and PBS NOVA to name a few. She has won several awards for excellence in AI and care delivery. For example, for her academic work, she\u2019s been recognized as IEEE\u2019s \u201cAI\u2019s 10 to Watch\u201d, Sloan Fellow, MIT Tech Review\u2019s \u201c35 Under 35\u201d, National Academy of Medicine\u2019s list of \u201cEmerging Leaders in Health and Medicine\u201d, and DARPA\u2019s Faculty Award. For her work in industry bringing AI to healthcare, she\u2019s been recognized as World Economic Forum\u2019s 100 Brilliant Minds Under 40, Rock Health\u2019s \u201cTop 50 in Digital Health\u201d, Modern Healthcare\u2019s Top 25 Innovators, The Armstrong Award for Excellence in Quality and Safety and Society of Critical Care Medicine\u2019s Annual Scientific Award.","image":"static/images/speakers/suchi_saria.jpg","institution":"Johns Hopkins University & Bayesian Health","slideslive_active_date":"","slideslive_id":"","speaker":"Suchi Saria","title":"Invited Talk on Research and Top Recent Papers from 2020-2022"},{"UID":"I02","abstract":"","bio":"Karandeep Singh, MD, MMSc, is an Assistant Professor of Learning Health Sciences, Internal Medicine, Urology, and Information at the University of Michigan. He directs the Machine Learning for Learning Health Systems (ML4LHS) Lab, which focuses on translational issues related to the implementation of machine learning (ML) models within health systems. He serves as an Associate Chief Medical Information Officer for Artificial Intelligence for Michigan Medicine and is the Associate Director for Implementation for U-M Precision Health, a Presidential Initiative focused on bringing research discoveries to the bedside, with a focus on prediction models and genomics data. He chairs the Michigan Medicine Clinical Intelligence Committee, which oversees the governance of machine learning models across the health system. He teaches a health data science course for graduate and doctoral students, and provides clinical care for people with kidney disease. He completed his internal medicine residency at UCLA Medical Center, where he served as chief resident, and a nephrology fellowship in the combined Brigham and Women\u2019s Hospital/Massachusetts General Hospital program in Boston, MA. He completed his medical education at the University of Michigan Medical School and holds a master\u2019s degree in medical sciences in Biomedical Informatics from Harvard Medical School. He is board certified in internal medicine, nephrology, and clinical informatics.","image":"static/images/speakers/karandeep_singh.jpg","institution":"University of Michigan","slideslive_active_date":"","slideslive_id":"","speaker":"Karandeep Singh","title":"Invited Talk on Recent Deployments and Real-world Impact"},{"UID":"I03","abstract":"","bio":"Dr. Nigam Shah is Professor of Medicine at Stanford University, and Chief Data Scientist for Stanford Health Care. His research group analyzes multiple types of health data (EHR, Claims, Wearables, Weblogs, and Patient blogs), to answer clinical questions, generate insights, and build predictive models for the learning health system. At Stanford Healthcare, he leads artificial intelligence and data science efforts for advancing the scientific understanding of disease, improving the practice of clinical medicine and orchestrating the delivery of health care. Dr. Shah is an inventor on eight patents and patent applications, has authored over 200 scientific publications and has co-founded three companies. Dr. Shah was elected into the American College of Medical Informatics (ACMI) in 2015 and was inducted into the American Society for Clinical Investigation (ASCI) in 2016. He holds an MBBS from Baroda Medical College, India, a PhD from Penn State University and completed postdoctoral training at Stanford University.","image":"static/images/speakers/nigam_shah.png","institution":"Stanford University","slideslive_active_date":"","slideslive_id":"","speaker":"Nigam Shah","title":"Invited Talk on Under-explored Research Challenges and Opportunities"}],"panels":[{"UID":"P01","abstract":"","bio":"Isaac \u201cZak\u201d Kohane, MD, PhD, is the inaugural chair of Harvard Medical School\u2019s Department of Biomedical Informatics, whose mission is to develop the methods, tools, and infrastructure required for a new generation of scientists and care providers to move biomedicine rapidly forward by taking  advantage of the insight and precision offered by big data. Kohane develops and applies computational techniques to address disease at multiple scales, from whole health care systems to the functional genomics of neurodevelopment. He also has worked on AI applications in medicine since the 1990\u2019s, including automated ventilator control, pediatric growth monitoring, detection of domestic abuse, diagnosing autism from multimodal data and most recently assisting clinicians using whole genome sequence and clinical histories to diagnose rare or unknown disease patients. His most urgent question is how to enable doctors to be most effective and enjoy their profession when they enter into a substantial symbiosis with machine intelligence. He is a member of the National Academy of Medicine, the American Society for Clinical Investigation and the American College of Medical Informatics.","image":"static/images/speakers/isaac_kohane.jpg","institution":"Harvard University","slideslive_active_date":"","slideslive_id":"","speaker":"Moderator: Isaac Kohane","title":"Generalizability in Machine Learning for Health: Critical for Robustness, or a Distraction from Specific Validation?"},{"UID":"P02","abstract":"","bio":"Leo focuses on scaling clinical research to be more inclusive through open access data and software, particularly for limited resource settings; identifying bias in the data to prevent them from being encrypted in models and algorithms; and redesigning research using the principles of team science and the hive learning strategy.","image":"static/images/speakers/leo_celi.png","institution":"MIT","slideslive_active_date":"","slideslive_id":"","speaker":"Leo Celi","title":"Generalizability in Machine Learning for Health: Critical for Robustness, or a Distraction from Specific Validation?"},{"UID":"P03","abstract":"","bio":"Jason Fries is a research scientist at the Shah Lab at Stanford University. His work is centered on enabling domain experts to easily construct and modify machine learning models, particularly in the field of medicine where expert-labeled training data are hard to acquire. His research interests include weakly supervised machine learning, foundation models for medicine, and data-centric AI.","image":"static/images/speakers/jason_fries.jpg","institution":"Stanford University","slideslive_active_date":"","slideslive_id":"","speaker":"Jason Fries","title":"Generalizability in Machine Learning for Health: Critical for Robustness, or a Distraction from Specific Validation?"},{"UID":"P04","abstract":"","bio":"Lauren Oakden-Rayner is a radiologist and Senior Research Fellow at the Australian Institute for Machine Learning, University of Adelaide. Her research primarily focuses on medical AI safety, specifically addressing the issues of model robustness, generalization, evaluation, and fairness. Lauren is also involved in supervising students and working on various medical AI projects, reviewing MOOCs on her blog, and advocating for diversity in her group and Institute.","image":"static/images/speakers/lauren_oakden_rayner.jpg","institution":"University of Adelaide","slideslive_active_date":null,"slideslive_id":"","speaker":"Lauren Oakden-Rayner","title":"Generalizability in Machine Learning for Health: Critical for Robustness, or a Distraction from Specific Validation?"},{"UID":"P05","abstract":"","bio":"Maia Hightower, MD, MBA, MPH, is an accomplished healthcare IT executive and internist. She currently serves as the executive Vice President and Chief Digital & Technology Officer at the University of Chicago Medicine and the CEO and co-founder of Equality AI, a startup aimed at achieving health equity through responsible AI and machine-learning operations. Previously, she was the chief medical information officer and associate chief medical officer at University of Utah Health and served in similar roles at University of Iowa Health Care and Stanford Health Care. Dr. Hightower's work has focused on leveraging digital technology to address health inequities and promoting diversity and inclusion within healthcare IT systems. Her leadership in the field has earned her widespread recognition.","image":"static/images/speakers/maia_hightower.jpg","institution":"University of Chicago Medicine","slideslive_active_date":"","slideslive_id":"","speaker":"Maia Hightower","title":"Generalizability in Machine Learning for Health: Critical for Robustness, or a Distraction from Specific Validation?"},{"UID":"P06","abstract":"","bio":"Marzyeh Ghassemi is an assistant professor and the Hermann L. F. von Helmholtz Professor with appointments in the Department of Electrical Engineering and Computer Science and the Institute for Medical Engineering & Science at MIT. Ghassemi\u2019s research interests span representation learning, behavioral ML, healthcare ML, and healthy ML. One of her focuses is on real-world applications of machine learning, such as turning diverse clinical data into cohesive information with the ability to predict patient needs. Ghassemi has received BS degrees in computer science and electrical engineering from New Mexico State University, an MSc degree in biomedical engineering from Oxford University, and PhD in computer science from MIT.","image":"static/images/speakers/marzyeh_ghassemi.jpeg","institution":"MIT","slideslive_active_date":null,"slideslive_id":"","speaker":"Moderator: Marzyeh Ghassemi","title":"Sharing Health Data in an Age of Generative AI: Risks, Limitations, and Solutions"},{"UID":"P07","abstract":"","bio":"Ziad Obermeyer is Associate Professor and Blue Cross of California Distinguished Professor at UC Berkeley, where he works at the intersection of machine learning and health. He is a Chan Zuckerberg Biohub Investigator, a Faculty Research Fellow at the National Bureau of Economic Research, and was named an Emerging Leader by the National Academy of Medicine. Previously, he was Assistant Professor at Harvard Medical School, and continues to practice emergency medicine in underserved communities.","image":"static/images/speakers/ziad_obermeyer.jpg","institution":"UC Berkeley","slideslive_active_date":"","slideslive_id":"","speaker":"Ziad Obermeyer","title":"Sharing Health Data in an Age of Generative AI: Risks, Limitations, and Solutions"},{"UID":"P08","abstract":"","bio":"Dr. Halamka is an emergency medicine physician, medical informatics expert and president of the Mayo Clinic Platform, which is focused on transforming health care by leveraging artificial intelligence, connected health care devices and a network of partners. Dr. Halamka has been developing and implementing health care information strategy and policy for more than 25 years. Previously, he was executive director of the Health Technology Exploration Center for Beth Israel Lahey Health, chief information officer at Beth Israel Deaconess Medical Center, and International Healthcare Innovation Professor at Harvard Medical School. He is a member of the National Academy of Medicine.","image":"static/images/speakers/john_halamka.jpg","institution":"Mayo Clinic","slideslive_active_date":"","slideslive_id":"","speaker":"John Halamka","title":"Sharing Health Data in an Age of Generative AI: Risks, Limitations, and Solutions"},{"UID":"P09","abstract":"","bio":"Elaine Nsoesie is an Associate Professor at Boston University's School of Public Health and a leading voice in the use of data and technology to advance health equity. She is leads the Racial Data Tracker project at Boston University's Center for Antiracist Research and serves as a Senior Advisor to the Artificial Intelligence/Machine Learning Consortium to Advance Health Equity and Researcher Diversity (AIM-AHEAD) program at the National Institutes of Health. Dr. Nsoesie has published extensively on the use of data from social media, search engines, and cell phones for public health surveillance and is dedicated to increasing representation of underrepresented communities in data science. She completed her PhD in Computational Epidemiology from Virginia Tech and has held postdoctoral positions at Harvard Medical School and Boston Children's Hospital.","image":"static/images/speakers/elaine_nsoesie.jpg","institution":"Boston University","slideslive_active_date":"","slideslive_id":"","speaker":"Elaine Nsoesie","title":"Sharing Health Data in an Age of Generative AI: Risks, Limitations, and Solutions"},{"UID":"P10","abstract":"","bio":"Dr. Khaled El Emam is the Canada Research Chair (Tier 1) in Medical AI at the University of Ottawa, where he is a Professor in the School of Epidemiology and Public Health. He is also a Senior Scientist at the Children\u2019s Hospital of Eastern Ontario Research Institute and Director of the multi-disciplinary Electronic Health Information Laboratory, conducting research on privacy enhancing technologies to enable the sharing of health data for secondary purposes, including synthetic data generation and de-identification methods.  Khaled is a co-founder of Replica Analytics, a company that develops synthetic data generation technology, which was recently acquired by Aetion. As an entrepreneur, Khaled founded or co-founded six product and services companies involved with data management and data analytics, with some having successful exits. Prior to his academic roles, he was a Senior Research Officer at the National Research Council of Canada. He also served as the head of the Quantitative Methods Group at the Fraunhofer Institute in Kaiserslautern, Germany. He participates in a number of committees, number of the European Medicines Agency Technical Anonymization Group, the Panel on Research Ethics advising on the TCPS, the Strategic Advisory Council of the Office of the Information and Privacy Commissioner of Ontario, and also is co-editor-in-chief of the JMIR AI journal. In 2003 and 2004, he was ranked as the top systems and software engineering scholar worldwide by the Journal of Systems and Software based on his research on measurement and quality evaluation and improvement. He held the Canada Research Chair in Electronic Health Information at the University of Ottawa from 2005 to 2015. Khaled has a PhD from the Department of Electrical and Electronics Engineering, King's College, at the University of London, England.","image":"static/images/speakers/khaled_el_emam.png","institution":"University of Ottawa","slideslive_active_date":"","slideslive_id":"","speaker":"Khaled El Emam","title":"Sharing Health Data in an Age of Generative AI: Risks, Limitations, and Solutions"},{"UID":"P11","abstract":"","bio":"Byron Wallace is the Sy and Laurie Sternberg Interdisciplinary Associate Professor and Director of the BS in Data Science program at Northeastern University in the Khoury College of Computer Sciences. His research is primarily in natural language processing (NLP) methods, with an emphasis on their application in healthcare and the challenges inherent to this domain.","image":"static/images/speakers/byron_wallace.jpg","institution":"Northeastern University","slideslive_active_date":"","slideslive_id":"","speaker":"Moderator: Byron Wallace","title":"Machine Learning for Healthcare in the Era of ChatGPT"},{"UID":"P12","abstract":"","bio":"Tristan Naumann is a Principal Researcher in Microsoft Research\u2019s Health Futures working on problems related to clinical and biomedical natural language processing (NLP). His research focuses on exploring relationships in complex, unstructured healthcare data using natural language processing and unsupervised learning techniques. He is currently serving as General Chair of NeurIPS and co-organizer of the Clinical NLP workshop at ACL. Previously, he has served as General Chair and Program Chair of the AHLI Conference on Health, Inference, and Learning (CHIL) and Machine Learning for Health (ML4H). His work has appeared in KDD, AAAI, AMIA, JMIR, MLHC, ACM HEALTH, Cell Patterns, Science Translational Medicine, and Nature Translational Psychiatry.","image":"static/images/speakers/tristan_naumann.jpeg","institution":"Microsoft Research","slideslive_active_date":"","slideslive_id":"","speaker":"Tristan Naumann","title":"Machine Learning for Healthcare in the Era of ChatGPT"},{"UID":"P13","abstract":"","bio":"Karandeep Singh, MD, MMSc, is an Assistant Professor of Learning Health Sciences, Internal Medicine, Urology, and Information at the University of Michigan. He directs the Machine Learning for Learning Health Systems (ML4LHS) Lab, which focuses on translational issues related to the implementation of machine learning (ML) models within health systems. He serves as an Associate Chief Medical Information Officer for Artificial Intelligence for Michigan Medicine and is the Associate Director for Implementation for U-M Precision Health, a Presidential Initiative focused on bringing research discoveries to the bedside, with a focus on prediction models and genomics data. He chairs the Michigan Medicine Clinical Intelligence Committee, which oversees the governance of machine learning models across the health system. He teaches a health data science course for graduate and doctoral students, and provides clinical care for people with kidney disease. He completed his internal medicine residency at UCLA Medical Center, where he served as chief resident, and a nephrology fellowship in the combined Brigham and Women\u2019s Hospital/Massachusetts General Hospital program in Boston, MA. He completed his medical education at the University of Michigan Medical School and holds a master\u2019s degree in medical sciences in Biomedical Informatics from Harvard Medical School. He is board certified in internal medicine, nephrology, and clinical informatics.","image":"static/images/speakers/karandeep_singh.jpg","institution":"University of Michigan","slideslive_active_date":"","slideslive_id":"","speaker":"Karandeep Singh","title":"Machine Learning for Healthcare in the Era of ChatGPT"},{"UID":"P14","abstract":"","bio":"Dr. Nigam Shah is Professor of Medicine at Stanford University, and Chief Data Scientist for Stanford Health Care. His research group analyzes multiple types of health data (EHR, Claims, Wearables, Weblogs, and Patient blogs), to answer clinical questions, generate insights, and build predictive models for the learning health system. At Stanford Healthcare, he leads artificial intelligence and data science efforts for advancing the scientific understanding of disease, improving the practice of clinical medicine and orchestrating the delivery of health care. Dr. Shah is an inventor on eight patents and patent applications, has authored over 200 scientific publications and has co-founded three companies. Dr. Shah was elected into the American College of Medical Informatics (ACMI) in 2015 and was inducted into the American Society for Clinical Investigation (ASCI) in 2016. He holds an MBBS from Baroda Medical College, India, a PhD from Penn State University and completed postdoctoral training at Stanford University.","image":"static/images/speakers/nigam_shah.png","institution":"Stanford University","slideslive_active_date":"","slideslive_id":"","speaker":"Nigam Shah","title":"Machine Learning for Healthcare in the Era of ChatGPT"},{"UID":"P15","abstract":"","bio":"Saadia Gabriel is currently a MIT CSAIL Postdoctoral Fellow. She is also an incoming NYU Faculty Fellow and will start as an Assistant Professor at UCLA in 2024. She completed her PhD at the University of Washington, where she was advised by Prof. Yejin Choi and Prof. Franziska Roesner. Her research revolves around natural language processing and machine learning, with a particular focus on building systems for understanding how social commonsense manifests in text (i.e. how do people typically behave in social scenarios), as well as mitigating spread of false or harmful text (e.g. Covid-19 misinformation). Her work has been covered by a wide range of media outlets like Forbes and TechCrunch. It has also received a 2019 ACL best short paper nomination, a 2019 IROS RoboCup best paper nomination and won a best paper award at the 2020 WeCNLP summit. \n","image":"static/images/speakers/saadia_gabriel.jpg","institution":"MIT","slideslive_active_date":"","slideslive_id":"","speaker":"Saadia Gabriel","title":"Machine Learning for Healthcare in the Era of ChatGPT"}],"proceedings":[{"UID":"P01","abstract":"Healthcare datasets often include patient-reported values, such as mood, symptoms, and meals, which can be subject to varying levels of human error. Improving the accuracy of patient-reported data could help in several downstream tasks, such as remote patient monitoring.  In this study, we propose a novel denoising autoencoder (DAE) approach to denoise patient-reported data, drawing inspiration from recent work in computer vision. Our approach is based on the observation that noisy patient-reported data are often collected alongside higher fidelity data collected from wearable sensors. We leverage these auxiliary data to improve the accuracy of the patient-reported data. Our approach combines key ideas from DAEs with co-teaching to iteratively filter and learn from clean patient-reported samples. Applied to the task of recovering carbohydrate values for blood glucose management in diabetes, our approach reduces noise (MSE) in patient-reported carbohydrates from 72<span class=\"font-italic\">g<sup>2</sup></span> (95% CI: 54-93) to 18<span class=\"font-italic\">g<sup>2</sup></span> (13-25), outperforming the best baseline (33<span class=\"font-italic\">g<sup>2</sup></span> (27-43)). Notably, our approach achieves strong performance with only access to patient-reported target values, making it applicable to many settings where ground truth data may be unavailable.","authors":"Harry Rubin-Falcone* (University of Michigan)|Joyce Lee (University of Michigan)|Jenna Wiens (University of Michigan)","session":"B","title":"Denoising Autoencoders for Learning from Noisy Patient-Reported Data"},{"UID":"P02","abstract":"Learning multi-view data is an emerging problem in machine learning research, and nonnegative matrix factorization (NMF) is a popular dimensionality-reduction method for integrating information from multiple views. These views often provide not only consensus but also complementary information. However, most multi-view NMF algorithms assign equal weight to each view or tune the weight via line search empirically, which can be infeasible without any prior knowledge of the views or computationally expensive. In this paper, we propose a weighted multi-view NMF (WM-NMF) algorithm.  In particular, we aim to address the critical technical gap, which is to learn both view-specific weight and observation-specific reconstruction weight to quantify each view\u2019s information content. The introduced weighting scheme can alleviate unnecessary views' adverse effects and enlarge the positive effects of the important views by assigning smaller and larger weights, respectively. Experimental results confirm the effectiveness and advantages of the proposed algorithm in terms of achieving better clustering performance and dealing with the noisy data compared to the existing algorithms.","authors":"Shuo Shuo Liu* (Pennsylvania State University)|Lin Lin (Duke University)","session":"A","title":"Adaptive Weighted Multi-View Clustering"},{"UID":"P03","abstract":"Imbalanced token distributions naturally exist in text documents, leading neural language models to overfit on frequent tokens. The token imbalance may dampen the robustness of radiology report generators, as complex medical terms appear less frequently but reflect more medical information. In this study, we demonstrate how current state-of-the-art models fail to generate infrequent tokens on two standard benchmark datasets (IU X-RAY and MIMIC-CXR) of radiology report generation. To solve the challenge, we propose the <span class=\"font-weight-bold\">T</span>oken <span class=\"font-weight-bold\">Im</span>balance Adapt<span class=\"font-weight-bold\">er</span> (<span class=\"font-italic\">TIMER</span>), aiming to improve generation robustness on infrequent tokens. The model automatically leverages token imbalance by an unlikelihood loss and dynamically optimizes generation processes to augment infrequent tokens. We compare our approach with multiple state-of-the-art methods on the two benchmarks. Experiments demonstrate the effectiveness of our approach in enhancing model robustness overall and infrequent tokens. Our ablation analysis shows that our reinforcement learning method has a major effect in adapting token imbalance for radiology report generation.","authors":"Yuexin Wu* (University of Memphis)|I-Chan Huang (St. Jude Children's Research Hospital)|Xiaolei Huang (University of Memphis)","session":"A","title":"Token Imbalance Adaptation for Radiology Report Generation"},{"UID":"P04","abstract":"Federated Learning (FL) is a machine learning approach that allows the model trainer to access more data samples by training across multiple decentralized data sources while enforcing data access constraints. Such trained models can achieve significantly higher performance beyond what can be done when trained on a single data source. In a FL setting, none of the training data is ever transmitted to any central location; i.e. sensitive data remains local and private. These characteristics make FL perfectly suited for applications in healthcare, where a variety of compliance constraints restrict how data may be handled. Despite these apparent benefits in compliance and privacy, certain scenarios such as heterogeneity of the local data distributions pose significant challenges for FL. Such challenges are even more pronounced in the case of a multilingual setting. This paper presents a FL system for pre-training a large-scale multi-lingual model suitable for fine-tuning on downstream tasks such as medical entity tagging. Our work represents one of the first such production-scale systems, capable of training across multiple highly heterogeneous data providers, and achieving levels of accuracy that could not be otherwise achieved by using central training with public data only. We also show that the global model performance can be further improved by a local training step.","authors":"Andre Manoel* (Microsoft)|Mirian Del Carmen Hipolito Garcia (Microsoft)|Tal Baumel (Microsoft)|Shize Su (Microsoft)|Jialei Chen (Microsoft)|Robert Sim (Microsoft)|Dan Miller (Airbnb)|Danny Karmon (Google)|Dimitrios Dimitriadis (Amazon)","session":"B","title":"Federated Multilingual Models for Medical Transcript Analysis"},{"UID":"P05","abstract":"Rare life events significantly impact mental health, and their detection in behavioral studies is a crucial step towards health-based interventions. We envision that mobile sensing data can be used to detect these anomalies. However, the human-centered nature of the problem, combined with the infrequency and uniqueness of these events makes it challenging for unsupervised machine learning methods. In this paper, we first investigate granger-causality between life events and human behavior using sensing data. Next, we propose a multi-task framework with an unsupervised autoencoder to capture irregular behavior, and an auxiliary sequence predictor that identifies transitions in workplace performance to contextualize events. We perform experiments using data from a mobile sensing study comprising N=126 information workers from multiple industries, spanning 10106 days with 198 rare events (<2%). Through personalized inference, we detect the exact day of a rare event with an F1 of 0.34, demonstrating that our method outperforms several baselines. Finally, we discuss the implications of our work from the context of real-world deployment.","authors":"Arvind Pillai* (Dartmouth College)|Subigya Nepal (Dartmouth College)|Andrew Campbell (Dartmouth College)","session":"B","title":"Rare Life Event Detection via Mobile Sensing Using Multi-Task Learning"},{"UID":"P06","abstract":"Understanding the host-specificity of different families of viruses sheds light on the origin of, e.g., SARS-CoV-2, rabies, and other such zoonotic pathogens in humans. It enables epidemiologists, medical professionals, and policymakers to curb existing epidemics and prevent future ones promptly. In the family Coronaviridae (of which SARS-CoV-2 is a member), it is well-known that the spike protein is the point of contact between the virus and the host cell membrane. On the other hand, the two traditional mammalian orders, Carnivora (carnivores) and Chiroptera (bats) are recognized to be responsible for maintaining and spreading the Rabies Lyssavirus (RABV). We propose Virus2Vec, a feature-vector representation for viral (nucleotide or amino acid) sequences that enable vector-space-based machine learning models to identify viral hosts. Virus2Vec generates numerical feature vectors for unaligned sequences, allowing us to forego the computationally expensive sequence alignment step from the pipeline. Virus2Vec leverages the power of both the <span class=\"font-italic\">minimizer</span> and position weight matrix (PWM) to generate compact feature vectors. Using several classifiers, we empirically evaluate Virus2Vec on real-world spike sequences of Coronaviridae and rabies virus sequence data to predict the host (identifying the reservoirs of infection). Our results demonstrate that Virus2Vec outperforms the predictive accuracies of baseline and state-of-the-art methods.","authors":"Sarwan Ali* (Georgia State University)|Babatunde Bello (Georgia State University)|Prakash Chourasia (Georgia State University)|Ria Thazhe Punathil (Georgia State University)|Pin-Yu Chen (IBM Research)|Imdad Ullah Khan (Lahore University of Management Sciences)|Murray Patterson (Georgia State University)","session":"A","title":"Virus2Vec: Viral Sequence Classification Using Machine Learning"},{"UID":"P07","abstract":"We propose a general framework for visualizing any intermediate embedding representation used by any neural survival analysis model. Our framework is based on so-called <span class=\"font-italic\">anchor directions</span> in an embedding space. We show how to estimate these anchor directions using clustering or, alternatively, using user-supplied ``concepts'' defined by collections of raw inputs (e.g., feature vectors all from female patients could encode the concept ``female''). For tabular data, we present visualization strategies that reveal how anchor directions relate to raw clinical features and to survival time distributions. We then show how these visualization ideas extend to handling raw inputs that are images. Our framework is built on looking at angles between vectors in an embedding space, where there could be ``information loss'' by ignoring magnitude information. We show how this loss results in a ``clumping'' artifact that appears in our visualizations, and how to reduce this information loss in practice.","authors":"George H. Chen* (Carnegie Mellon University)","session":"B","title":"A General Framework for Visualizing Embedding Spaces of Neural Survival Analysis Models Based on Angular Information"},{"UID":"P08","abstract":"Federated learning (FL) is an active area of research. One of the most suitable areas for adopting FL is the medical domain, where patient privacy must be respected. Previous research, however, does not provide a practical guide to applying FL in the medical domain. We propose empirical benchmarks and experimental settings for three representative medical datasets with different modalities: longitudinal electronic health records, skin cancer images, and electrocardiogram signals. The likely users of FL such as medical institutions and IT companies can take these benchmarks as guides for adopting FL and minimize their trial and error. For each dataset, each client data is from a different source to preserve real-world heterogeneity. We evaluate six FL algorithms designed for addressing data heterogeneity among clients, and a hybrid algorithm combining the strengths of two representative FL algorithms. Based on experiment results from three modalities, we discover that simple FL algorithms tend to outperform more sophisticated ones, while the hybrid algorithm consistently shows good, if not the best performance. We also find that a frequent global model update leads to better performance under a fixed training iteration budget. As the number of participating clients increases, higher cost is incurred due to increased IT administrators and GPUs, but the performance consistently increases. We expect future users will refer to these empirical benchmarks to design the FL experiments in the medical domain considering their clinical tasks and obtain stronger performance with lower costs.","authors":"Hyeonji Hwang* (KAIST)|Seongjun Yang (KRAFTON)|Daeyoung Kim (KAIST)|Radhika Dua (Google Research)|Jong-Yeup Kim(Konyang University)|Eunho Yang (KAIST) |Edward Choi (KAIST)","session":"A","title":"Towards the Practical Utility of Federated Learning in the Medical Domain"},{"UID":"P09","abstract":"Most machine learning models for predicting clinical outcomes are developed using historical data. Yet, even if these models are deployed in the near future, dataset shift over time may result in less than ideal performance. To capture this phenomenon, we consider a task---that is, an outcome to be predicted at a particular time point---to be non-stationary if a historical model is no longer optimal for predicting that outcome. We build an algorithm to test for temporal shift either at the population level or within a discovered sub-population. Then, we construct a meta-algorithm to perform a retrospective scan for temporal shift on a large collection of tasks. Our algorithms enable us to perform the first comprehensive evaluation of temporal shift in healthcare to our knowledge. We create 1,010 tasks by evaluating 242 healthcare outcomes for temporal shift from 2015 to 2020 on a health insurance claims dataset. 9.7% of the tasks show temporal shifts at the population level, and 93.0% have some sub-population affected by shifts. We dive into case studies to understand the clinical implications. Our analysis highlights the widespread prevalence of temporal shifts in healthcare.","authors":"Christina X Ji (MIT CSAIL and IMES)|Ahmed Alaa (UC Berkeley and UCSF)|David Sontag (MIT CSAIL and IMES)","session":"A","title":"Large-Scale Study of Temporal Shift in Health Insurance Claims"},{"UID":"P10","abstract":"The recent spike in certified Artificial Intelligence tools for healthcare has renewed the debate around adoption of this technology. One thread of such debate concerns Explainable AI and its promise to render AI devices more transparent and trustworthy. A few voices active in the medical AI space have expressed concerns on the reliability of Explainable AI techniques and especially feature attribution methods, questioning their use and inclusion in guidelines and standards. We characterize the problem as a lack of semantic match between explanations and human understanding. To understand when feature importance can be used reliably, we introduce a distinction between feature importance of low- and high-level features. We argue that for data types where low-level features come endowed with a clear semantics, such as tabular data like Electronic Health Records, semantic match can be obtained, and thus feature attribution methods can still be employed in a meaningful and useful way. For high-level features, we sketch a procedure to test whether semantic match has been achieved.","authors":"Giovanni Cin\u00e0* (Amsterdam University Medical Center)|Tabea E. R\u00f6ber (University of Amsterdam)|Rob Goedhart (University of Amsterdam)|\u015e. \u0130lker  Birbil (University of Amsterdam)","session":"B","title":"Semantic match: Debugging feature attribution methods in XAI for healthcare"},{"UID":"P11","abstract":"Multivariate biosignals are prevalent in many medical domains, such as electroencephalography, polysomnography, and electrocardiography. Modeling spatiotemporal dependencies in multivariate biosignals is challenging due to (1) long-range temporal dependencies and (2) complex spatial correlations between the electrodes. To address these challenges, we propose representing multivariate biosignals as time-dependent graphs and introduce GRAPHS4MER, a general graph neural network (GNN) architecture that improves performance on biosignal classification tasks by modeling spatiotemporal dependencies in biosignals. Specifically, (1) we leverage the Structured State Space architecture, a state-of-the-art deep sequence model, to capture long-range temporal dependencies in biosignals and (2) we propose a graph structure learning layer in GRAPHS4MER to learn dynamically evolving graph structures in the data.  We evaluate our proposed model on three distinct biosignal classification tasks and show that GRAPHS4MER consistently improves over existing models, including (1) seizure detection from electroencephalographic signals, outperforming a previous GNN with self-supervised pre-training by 3.1 points in AUROC; (2) sleep staging from polysomnographic signals, a 4.1 points improvement in macro-F1 score compared to existing sleep staging models; and (3) 12-lead electrocardiogram classification, outperforming previous state-of-the-art models by 2.7 points in macro-F1 score.","authors":"Siyi Tang* (Stanford University)|Jared A. Dunnmon (Stanford University)|Liangqiong Qu (University of Hong Kong)|Khaled K. Saab (Stanford University)|Tina Baykaner (Stanford University)|Christopher Lee-Messer (Stanford University)|Daniel L. Rubin (Stanford University)","session":"B","title":"Modeling Multivariate Biosignals With Graph Neural Networks and Structured State Space Models"},{"UID":"P12","abstract":"Time-to-event modelling, known as survival analysis, differs from standard regression as it addresses <span class=\"font-italic\">censoring</span> in patients who do not experience the event of interest. Despite competitive performances in tackling this problem, machine learning methods often ignore other <span class=\"font-italic\">competing risks</span> that preclude the event of interest. This practice biases the survival estimation. Extensions to address this challenge often rely on parametric assumptions or numerical estimations leading to sub-optimal survival approximations. This paper leverages constrained monotonic neural networks to model each competing survival distribution. This modelling choice ensures the exact likelihood maximisation at a reduced computational cost by using automatic differentiation. The effectiveness of the solution is demonstrated on one synthetic and three medical datasets. Finally, we discuss the implications of considering competing risks when developing risk scores for medical practice.","authors":"Vincent Jeanselme* (University of Cambridge)|Chang Ho Yoon (University of Oxford)|Brian Tom (University of Cambridge)|Jessica Barrett (University of Cambridge)","session":"A","title":"Neural Fine-Gray: Monotonic neural networks for competing risks"},{"UID":"P13","abstract":"With the availability of large-scale, comprehensive, and general-purpose vision-language (VL) datasets such as MSCOCO, vision-language pre-training (VLP) has become an active area of research and proven to be effective for various VL tasks such as visual-question answering. However, studies on VLP in the medical domain have so far been scanty. To provide a comprehensive perspective on VLP for medical VL tasks, we conduct a thorough experimental analysis to study key factors that may affect the performance of VLP with a unified vision-language Transformer. To allow making sound and quick pre-training decisions, we propose RadioGraphy Captions (RGC), a high-quality, multi-modality radiographic dataset containing 18,434 image-caption pairs collected from an open-access online database MedPix. RGC can be used as a pre-training dataset or a new benchmark for medical report generation and medical image-text retrieval. By utilizing RGC and other available datasets for pre-training, we develop several key insights that can guide future medical VLP research and new strong baselines for various medical VL tasks.","authors":"Li Xu* (Hong Kong Polytechnic University)|Bo Liu (Hong Kong Polytechnic University)|Ameer Hamza Khan (Hong Kong Polytechnic University)|Lu Fan (Hong Kong Polytechnic University)|Xiao-Ming Wu (Hong Kong Polytechnic University)","session":"A","title":"Multi-modal Pre-training for Medical Vision-language Understanding and Generation: An Empirical Study with A New Benchmark"},{"UID":"P14","abstract":"Chronic kidney disease (CKD) is a life-threatening and prevalent disease. CKD patients, especially end-stage kidney disease (ESKD) patients on hemodialysis, suffer from kidney failures and are unable to remove excessive fluid, causing fluid overload and multiple morbidities including death. Current solutions for fluid overtake monitoring such as ultrasonography and biomarkers assessment are cumbersome, discontinuous, and can only be performed in the clinic. In this paper, we propose SRDA, a latent graph learning powered fluid overload detection system based on <span style=\"text-decoration:underline\">S</span>ensor <span style=\"text-decoration:underline\">R</span>elation <span style=\"text-decoration:underline\">D</span>ual <span style=\"text-decoration:underline\">A</span>utoencoder to detect excessive fluid consumption of EKSD patients based on passively collected bio-behavioral data from smartwatch sensors. Experiments using real-world mobile sensing data indicate that SRDA outperforms the state-of-the-art baselines in both F1 score and recall, and demonstrate the potential of ubiquitous sensing for ESKD fluid intake management.","authors":"Mingyue Tang (University of Virginia)|Jiechao Gao* (University of Virginia)|Guimin Dong (Amazon)|Carl Yang (Emory University)|Brad Campbell (University of Virginia)|Brendan Bowman (University of Virginia)|Jamie Marie Zoellner (University of Virginia)|Emaad Abdel-Rahman (University of Virginia)|Mehdi Boukhechba (The Janssen Pharmaceutical Companies of Johnson & Johnson)","session":"B","title":"SRDA: Mobile Sensing based Fluid Overload Detection for End Stage Kidney Disease Patients using Sensor Relation Dual Autoencoder"},{"UID":"P15","abstract":"Conflict of interest (COI) disclosure statements provide rich information to support transparency and reduce bias in research. We introduce a novel task to identify relationships between sponsoring entities and the research studies they sponsor from the disclosure statement. This task is challenging due to the complexity of recognizing all potential relationship patterns and the hierarchical nature of identifying entities first and then extracting their relationships to the study. To overcome these challenges, in this paper, we also constructed a new annotated dataset and proposed a Question Answering-based method to recognize entities and extract relationships. Our method has demonstrated robustness in handling diverse relationship patterns, and it remains effective even when trained on a low-resource dataset.","authors":"Hardy* (Universitas Mikroskil)|Derek Ruths (McGill University)|Nicholas B King (McGill University)","session":"A","title":"Who Controlled the Evidence? Question Answering for Disclosure Information Retrieval"},{"UID":"P16","abstract":"In this paper, we challenge the utility of approved drug indications as a prediction target for machine learning in drug repurposing (DR) studies. Our research highlights two major limitations of this approach: 1) the presence of strong confounding between drug indications and drug characteristics data, which results in shortcut learning, and 2) inappropriate normalization of indications in existing drug-disease association (DDA) datasets, which leads to an overestimation of model performance. We show that the collection patterns of drug characteristics data were similar within drugs of the same category and the Anatomical Therapeutic Chemical (ATC) classification of drugs could be predicted by using the data collection patterns. Furthermore, we confirm that the performance of existing DR models is significantly degraded in the realistic evaluation setting we proposed in this study. We provide realistic data split information for two benchmark datasets, Fdataset and deepDR dataset.","authors":"Siun Kim* (Seoul National University)|Jung-Hyun Won (Seoul National University)|David Seung U Lee (Seoul National University)|Renqian Luo (Microsoft Research)|Lijun Wu (Microsoft Research)|Yingce Xia (Microsoft Research)|Tao Qin (Microsoft Research)|Howard Lee (Seoul National University)","session":"A","title":"Revisiting Machine-Learning based Drug Repurposing: Drug Indications Are Not a Right Prediction Target"},{"UID":"P17","abstract":"Only about one-third of the deaths worldwide are assigned a medically-certified cause, and understanding the causes of deaths occurring outside of medical facilities is logistically and financially challenging. Verbal autopsy (VA) is a routinely used tool to collect information on cause of death in such settings. VA is a survey-based method where a structured questionnaire is conducted to family members or caregivers of a recently deceased person, and the collected information is used to infer the cause of death. As VA becomes an increasingly routine tool for cause-of-death data collection, the lengthy questionnaire has become a major challenge to the implementation and scale-up of VA interviews as they are costly and time-consuming to conduct. In this paper, we propose a novel active questionnaire design approach that optimizes the order of the questions dynamically to achieve accurate cause-of-death assignment with the smallest number of questions. We propose a fully Bayesian strategy for adaptive question selection that is compatible with any existing probabilistic cause-of-death assignment methods. We also develop an early stopping criterion that fully accounts for the uncertainty in the model parameters. We also propose a penalized score to account for constraints and preferences of existing question structures. We evaluate the performance of our active designs using both synthetic and real data, demonstrating that the proposed strategy achieves accurate cause-of-death assignment using considerably fewer questions than the traditional static VA survey instruments.","authors":"Toshiya Yoshida* (University of California Santa Cruz)|Trinity Shuxian Fan (University of Washington)|Tyler McCormick (University of Washington)|Zhenke Wu (University of Michigan)|Zehang Richard Li (University of California Santa Cruz)","session":"A","title":"Bayesian Active Questionnaire Design for Cause-of-Death Assignment Using Verbal Autopsies"},{"UID":"P18","abstract":"High blood pressure is a major risk factor for cardiovascular disease, necessitating accurate blood pressure (BP) measurement. Clinicians measure BP with an invasive arterial catheter or via a non-invasive arm or finger cuff. However, the former can cause discomfort to the patient and is unsuitable outside Intensive Care Unit (ICU). While cuff-based devices, despite being non-invasive, fails to provide continuous measurement, and they measure from peripheral blood vessels whose BP waveforms differ significantly from those proximal to the heart. Hence, there is an urgent need to develop a measurement protocol for converting easily measured non-invasive data into accurate BP values. Addressing this gap, we propose a non-invasive approach to predict BP from arterial area and blood flow velocity signals measured from a Philips ultrasound transducer (XL-143) applied to large arteries close to heart. We developed the protocol and collected data from 72 subjects. The shape of BP (relative BP) can be theoretically calculated from these waveforms, however there is no established theory to obtain <span class=\"font-italic\">absolute</span> BP values. To tackle this challenge, we further employ data-driven machine learning models to predict the Mean Arterial Blood Pressure (MAP), from which the absolute BP can be derived. Our study investigates various machine learning algorithms to optimize the prediction accuracy. We find that LSTM, Transformer, and 1D-CNN algorithms using the blood pressure shape and blood flow velocity waveforms as inputs can achieve 8.6, 8.7, and 8.8 mmHg average standard deviation of the prediction error respectively without anthropometric data such as age, sex, heart rate, height, weight. Furthermore, the 1D-CNN model can achieve 7.9mmHg when anthropometric data is added as inputs, improving upon an anthropometric-only model of 9.5mmHg. This machine learning-based approach, capable of converting ultrasound data into MAP values, presents a promising software tool for physicians in clinical decision-making regarding blood pressure management.","authors":"Jessica Zheng (MIT)|Hanrui Wang* (MIT)|Anand Chandrasekhar (MIT)|Aaron Aguirre (Massachusetts General Hospital and Harvard Medical School)|Song Han (MIT)|Hae-Seung Lee (MIT)|Charles G. Sodini (MIT)","session":"A","title":"Machine Learning for Arterial Blood Pressure Prediction"},{"UID":"P19","abstract":"High blood pressure is a major risk factor for cardiovascular disease, necessitating accurate blood pressure (BP) measurement. Clinicians measure BP with an invasive arterial catheter or via a non-invasive arm or finger cuff. However, the former can cause discomfort to the patient and is unsuitable outside Intensive Care Unit (ICU). While cuff-based devices, despite being non-invasive, fails to provide continuous measurement, and they measure from peripheral blood vessels whose BP waveforms differ significantly from those proximal to the heart. Hence, there is an urgent need to develop a measurement protocol for converting easily measured non-invasive data into accurate BP values. Addressing this gap, we propose a non-invasive approach to predict BP from arterial area and blood flow velocity signals measured from a Philips ultrasound transducer (XL-143) applied to large arteries close to heart. We developed the protocol and collected data from 72 subjects. The shape of BP (relative BP) can be theoretically calculated from these waveforms, however there is no established theory to obtain <span class=\"font-italic\">absolute</span> BP values. To tackle this challenge, we further employ data-driven machine learning models to predict the Mean Arterial Blood Pressure (MAP), from which the absolute BP can be derived. Our study investigates various machine learning algorithms to optimize the prediction accuracy. We find that LSTM, Transformer, and 1D-CNN algorithms using the blood pressure shape and blood flow velocity waveforms as inputs can achieve 8.6, 8.7, and 8.8 mmHg average standard deviation of the prediction error respectively without anthropometric data such as age, sex, heart rate, height, weight. Furthermore, the 1D-CNN model can achieve 7.9mmHg when anthropometric data is added as inputs, improving upon an anthropometric-only model of 9.5mmHg. This machine learning-based approach, capable of converting ultrasound data into MAP values, presents a promising software tool for physicians in clinical decision-making regarding blood pressure management.","authors":"Iman Deznabi* (University of Massachusetts, Amherst)|Madalina Fiterau (University of Massachusetts, Amherst)","session":"B","title":"MultiWave: Multiresolution Deep Architectures through Wavelet Decomposition for Multivariate Time Series Prediction"},{"UID":"P20","abstract":"Missing values are a fundamental problem in data science. Many datasets have missing values that must be properly handled because the way missing values are treated can have large impact on the resulting machine learning model. In medical applications, the consequences may affect healthcare decisions. There are many methods in the literature for dealing with missing values, including state-of-the-art methods which often depend on black-box models for imputation. In this work, we show how recent advances in interpretable machine learning provide a new perspective for understanding and tackling the missing value problem. We propose methods based on high-accuracy glass-box Explainable Boosting Machines (EBMs) that can help users (1) gain new insights on missingness mechanisms and better understand the causes of missingness, and (2) detect -- or even alleviate -- potential risks introduced by imputation algorithms. Experiments on real-world medical datasets illustrate the effectiveness of the proposed methods.","authors":"Zhi Chen* (Duke University)|Sarah Tan (Cornell University)|Urszula Chajewska (Microsoft Research)|Cynthia Rudin (Duke University)|Rich Caruana (Microsoft Research)","session":"B","title":"Missing Values and Imputation in Healthcare Data: Can Interpretable Machine Learning Help?"},{"UID":"P21","abstract":"Machine learning models perform well on several healthcare tasks and can help reduce the burden on the healthcare system. However, the lack of explainability is a major roadblock to their adoption in hospitals. <span class=\"font-italic\">How can the decision of an ML model be explained to a physician?</span> The explanations considered in this paper are counterfactuals (CFs), hypothetical scenarios that would have resulted in the opposite outcome. Specifically, time-series CFs are investigated, inspired by the way physicians converse and reason out decisions `I would have given the patient a vasopressor if their blood pressure was lower and falling'. Key properties of CFs that are particularly meaningful in clinical settings are outlined: physiological plausibility, relevance to the task and sparse perturbations. Past work on CF generation does not satisfy these properties, specifically plausibility in that realistic time-series CFs are not generated. A variational autoencoder (VAE)-based approach is proposed that captures these desired properties. The method produces CFs that improve on prior approaches quantitatively (more plausible CFs as evaluated by their likelihood w.r.t original data distribution, and 100x faster at generating CFs) and qualitatively (2x more plausible and relevant) as evaluated by three physicians.","authors":"Supriya Nagesh* (Amazon)|Nina Mishra (Amazon)|Yonatan Naamad (Amazon)|James M Rehg (Georgia Institute of Technology)|Mehul A Shah (Aryn)|Alexei Wagner (Harvard University)","session":"B","title":"Explaining a machine learning decision to physicians via counterfactuals"},{"UID":"P22","abstract":"Noisy training labels can hurt model performance. Most approaches that aim to address label noise assume label noise is independent from the input features. In practice, however, label noise is often feature or <span class=\"font-italic\">instance-dependent</span>, and therefore biased (i.e., some instances are more likely to be mislabeled than others). E.g., in clinical care, female patients are more likely to be under-diagnosed for cardiovascular disease compared to male patients. Approaches that ignore this dependence can produce models with poor discriminative performance, and in many healthcare settings, can exacerbate issues around health disparities. In light of these limitations, we propose a two-stage approach to learn in the presence instance-dependent label noise. Our approach utilizes <span class=\"font-italic\">alignment points</span>, a small subset of data for which we know the observed and ground truth labels. On several tasks, our approach leads to consistent improvements over the state-of-the-art in discriminative performance (AUROC) while mitigating bias (area under the equalized odds curve, AUEOC). For example, when predicting acute respiratory failure onset on the MIMIC-III dataset, our approach achieves a harmonic mean (AUROC and AUEOC) of 0.84 (SD [standard deviation] 0.01) while that of the next best baseline is 0.81 (SD 0.01).  Overall, our approach improves accuracy while mitigating potential bias compared to existing approaches in the presence of instance-dependent label noise.","authors":"Donna Tjandra* (University of Michigan)|Jenna Wiens (University of Michigan)","session":"A","title":"Leveraging an Alignment Set in Tackling Instance-Dependent Label Noise"},{"UID":"P23","abstract":"Fair calibration is a widely desirable fairness criteria in risk prediction contexts. One way to measure and achieve fair calibration is with multicalibration. Multicalibration constrains calibration error among flexibly-defined subpopulations while maintaining overall calibration. However, multicalibrated models can exhibit a higher percent calibration error among groups with lower base rates than groups with higher base rates. As a result, it is possible for a decision-maker to learn to trust or distrust model predictions for specific groups. To alleviate this, we propose <span class=\"font-italic\">proportional multicalibration</span>, a criteria that constrains the percent calibration error among groups and within prediction bins. We prove that satisfying proportional multicalibration bounds a model's multicalibration as well its <span class=\"font-italic\">differential calibration</span>, a fairness criteria that directly measures how closely a model approximates sufficiency. Therefore, proportionally calibrated models limit the ability of decision makers to distinguish between model performance on different patient groups, which may make the models more trustworthy in practice.  We provide an efficient algorithm for post-processing risk prediction models for proportional multicalibration and evaluate it empirically. We conduct simulation studies and investigate a real-world application of PMC-postprocessing to prediction of emergency department patient admissions. We observe that proportional multicalibration is a promising criteria for controlling simultaneous measures of calibration fairness of a model over intersectional groups with virtually no cost in terms of classification performance.","authors":"William La Cava* (Boston Children's Hospital and Harvard Medical School)|Elle Lett (Boston Children's Hospital and Harvard Medical School)|Guangya Wan (Boston Children's Hospital and Harvard Medical School)","session":"B","title":"Fair Admission Risk Prediction with Proportional Multicalibration"},{"UID":"P24","abstract":"Machine learning models for healthcare commonly use binary indicator variables to represent the diagnosis of specific health conditions in medical records. However, in populations with significant under-reporting, the absence of a recorded diagnosis does not rule out the presence of a condition, making it difficult to distinguish between negative and missing values. This effect,  which we refer to as latent missingness, may lead to model degradation and perpetuate existing biases in healthcare. To address this issue, we propose that healthcare providers and payers  allocate a budget towards data collection (eg. subsidies for check-ups or lab tests). However, given finite resources, only a subset of data points can be collected. Additionally, most models are unable to be re-trained after deployment. In this paper, we propose a method for efficient data collection in order to maximize a fixed model's performance on a given population. Through simulated and real-world data, we demonstrate the potential value of targeted data collection to address model degradation.","authors":"Kevin Wu* (Stanford University and Optum Labs)|Dominik Dahlem (Optum Labs)|Christopher Hane (Optum Labs)|Eran Halperin (Optum Labs)|James Zou (Stanford University)","session":"A","title":"Collecting data when missingness is unknown: a method for improving model performance given under-reporting in patient populations"},{"UID":"P25","abstract":"Detailed mobile sensing data from phones and fitness trackers offer an opportunity to quantify previously unmeasurable behavioral changes to improve individual health and accelerate responses to emerging diseases. Unlike in natural language processing and computer vision, deep learning has yet to broadly impact this domain, in which the majority of research and clinical applications still rely on manually defined features or even forgo predictive modeling altogether due to insufficient accuracy. This is due to unique challenges in the behavioral health domain, including very small datasets (~10<sup>1</sup> participants), which frequently contain missing data, consist of long time series with critical long-range dependencies (length<10<sup>4</sup>), and extreme class imbalances (>10<sup>3</sup>:1). Here, we <span class=\"font-italic\">describe</span> a neural architecture for multivariate time series classification designed to address these unique domain challenges. Our proposed behavioral representation learning approach combines novel tasks for self-supervised pretraining and transfer learning to address data scarcity, and captures long-range dependencies across long-history time series through transformer self-attention following convolutional neural network-based dimensionality reduction. We propose an evaluation framework aimed at reflecting expected real-world performance in plausible deployment scenarios. Concretely, we demonstrate (1) performance improvements over baselines of up to 0.15 ROC AUC across five influenza-related prediction tasks, (2) transfer learning-induced performance improvements <span class=\"font-italic\">including a 16% relative increase</span> in PR AUC in small data scenarios, and (3) the potential of transfer learning in novel disease scenarios through an exploratory case study of zero-shot COVID-19 prediction in an independent data set.  Finally, we discuss potential implications for medical surveillance testing.","authors":"Mike A Merrill* (University of Washington)|Tim Althoff (University of Washington)","session":"A","title":"Self-Supervised Pretraining and Transfer Learning Enable Flu and COVID-19 Predictions in Small Mobile Sensing Datasets"},{"UID":"P26","abstract":"Given the complexity of trauma presentations, particularly in those involving multiple areas of the body, overlooked injuries are common during the initial assessment by a clinician. We are motivated to develop an automated trauma pattern discovery framework for comprehensive identification of injury patterns which may eventually support diagnostic decision-making. We analyze 1,162,399 patients from the Trauma Quality Improvement Program with a disentangled variational autoencoder, weakly supervised by a latent-space classifier of auxiliary features. We also develop a novel scoring metric that serves as a proxy for clinical intuition in extracting clusters with clinically meaningful injury patterns. We validate the extracted clusters with clinical experts, and explore the patient characteristics of selected groupings. Our metric is able to perform model selection and effectively filter clusters for clinically-validated relevance.","authors":"Qixuan Jin* (Massachusetts Institute of Technology)|Jacobien Oosterhoff (Delft University of Technology)|Yepeng Huang (Harvard School of Public Health)|Marzyeh Ghassemi (Massachusetts Institute of Technology)|Gabriel A. Brat (Beth Israel Deaconess Medical Center and Harvard Medical School)","session":"B","title":"Clinical Relevance Score for Guided Trauma Injury Pattern Discovery with Weakly Supervised \u03b2-VAE"},{"UID":"P27","abstract":"Machine learning (ML) models deployed in healthcare systems must face data drawn from continually evolving environments. However, researchers proposing such models typically evaluate them in a time-agnostic manner, splitting datasets according to patients sampled randomly throughout the entire study time period. This work proposes the Evaluation on Medical Datasets Over Time (EMDOT) framework, which evaluates the performance of a model class across time. Inspired by the concept of backtesting, EMDOT simulates possible training procedures that practitioners might have been able to execute at each point in time and evaluates the resulting models on all future time points. Evaluating both linear and more complex models on six distinct medical data sources (tabular and imaging), we show how depending on the dataset, using all historical data may be ideal in many cases, whereas using a window of the most recent data could be advantageous in others. In datasets where models suffer from sudden degradations in performance, we investigate plausible explanations for these shocks. We release the EMDOT package to help facilitate further works in deployment-oriented evaluation over time.","authors":"Helen Zhou* (Carnegie Mellon University)|Yuwen Chen (Carnegie Mellon University)|Zachary Chase Lipton (Carnegie Mellon University)","session":"B","title":"Evaluating Model Performance in Medical Datasets Over Time"},{"UID":"P28","abstract":"Making the most use of abundant information in electronic health records (EHR) is rapidly becoming an important topic in the medical domain. Recent work presented a promising framework that embeds entire features in raw EHR data regardless of its form and medical code standards. The framework, however, only focuses on encoding EHR with minimal preprocessing and fails to consider how to learn efficient EHR representation in terms of computation and memory usage. In this paper, we search for a versatile encoder not only reducing the large data into a manageable size but also well preserving the core information of patients to perform diverse clinical tasks. We found that hierarchically structured Convolutional Neural Network (CNN) often outperforms the state-of-the-art model on diverse tasks such as reconstruction, prediction, and generation, even with fewer parameters and less training time. Moreover, it turns out that making use of the inherent hierarchy of EHR data can boost the performance of any kind of backbone models and clinical tasks performed. Through extensive experiments, we present concrete evidence to generalize our research findings into real-world practice. We give a clear guideline on building the encoder based on the research findings captured while exploring numerous settings.","authors":"Eunbyeol Cho* (KAIST)|Min Jae Lee (KAIST)|Kyunghoon Hur (KAIST)|Jiyoun Kim (KAIST)|Jinsung Yoon (Google Cloud AI Research)|Edward Choi (KAIST)","session":"A","title":"Rediscovery of CNN's Versatility for Text-based Encoding of Raw Electronic Health Records"},{"UID":"P29","abstract":"Despite increased interest in wearables as tools for detecting various health conditions, there are not as of yet any large public benchmarks for such mobile sensing data. The few datasets that <span class=\"font-italic\">are</span> available do not contain data from more than dozens of individuals, do not contain high-resolution raw data or do not include dataloaders for easy integration into machine learning pipelines. Here, we present Homekit2020: the first large-scale public benchmark for time series classification of wearable sensor data. Our dataset contains over 14 million hours of minute-level multimodal Fitbit data, symptom reports, and ground-truth laboratory PCR influenza test results, along with an evaluation framework that mimics realistic model deployments and efficiently characterizes statistical uncertainty in model selection in the presence of extreme class imbalance. Furthermore, we implement and evaluate nine neural and non-neural time series classification models on our benchmark across 450 total training runs in order to establish state of the art performance.","authors":"Mike A Merrill (University of Washington)|Esteban Safranchik* (University of Washington)|Arinbj\u00f6rn Kolbeinsson (Evidation Health)|Piyusha Gade (Evidation Health)|Ernesto Ramirez (Evidation Health)|Ludwig Schmidt (University of Washington)|Luca Foschini (Sage Bionetworks)|Tim Althoff (University of Washington)","session":"B","title":"Homekit2020: A Benchmark for Time Series Classification on a Large Mobile Sensing Dataset with Laboratory Tested Ground Truth of Influenza Infections"},{"UID":"P30","abstract":"The human brain is the central hub of the neurobiological system, controlling behavior and cognition in complex ways. Recent advances in neuroscience and neuroimaging analysis have shown a growing interest in the interactions between brain regions of interest (ROIs) and their impact on neural development and disorder diagnosis. As a powerful deep model for analyzing graph-structured data, Graph Neural Networks (GNNs) have been applied for brain network analysis. However, training deep models requires large amounts of labeled data, which is often scarce in brain network datasets due to the complexities of data acquisition and sharing restrictions. To make the most out of available training data, we propose PTGB, a GNN pre-training framework that captures intrinsic brain network structures, regardless of clinical outcomes, and is easily adaptable to various downstream tasks. PTGB comprises two key components: (1) an unsupervised pre-training technique designed specifically for brain networks, which enables learning from large-scale datasets without task-specific labels; (2) a data-driven parcellation atlas mapping pipeline that facilitates knowledge transfer across datasets with different ROI systems. Extensive evaluations using various GNN models have demonstrated the robust and superior performance of PTGB compared to baseline methods.","authors":"Yi Yang* (Emory University)|Hejie Cui (Emory University)|Carl Yang (Emory University)","session":"B","title":"PTGB: Pre-Train Graph Neural Networks for Brain Network Analysis"},{"UID":"P31","abstract":"Although recent advances in scaling large language models (LLMs) have resulted in improvements on many NLP tasks, it remains unclear whether these models trained primarily with general web text are the right tool in highly specialized, safety critical domains such as <span class=\"font-italic\">clinical text</span>. Recent results have suggested that LLMs encode a surprising amount of medical knowledge. This raises an important question regarding the utility of smaller domain-specific language models. With the success of general-domain LLMs, is there still a need for specialized clinical models? To investigate this question, we conduct an extensive empirical analysis of 12 language models, ranging from 220M to 175B parameters, measuring their performance on 3 different clinical tasks that test their ability to parse and reason over electronic health records. As part of our experiments, we train T5-Base and T5-Large models from scratch on clinical notes from MIMIC III and IV to directly investigate the efficiency of clinical tokens. We show that relatively small specialized clinical models substantially outperform all in-context learning approaches, even when finetuned on limited annotated data. Further, we find that pretraining on clinical tokens allows for smaller, more parameter-efficient models that either match or outperform much larger language models trained on general text. We release the code and the models used under the PhysioNet Credentialed Health Data license and data use agreement.","authors":"Eric Lehman* (MIT and Xyla)|Evan Hernandez (MIT and Xyla)|Diwakar Mahajan (IBM Research)|Jonas Wulff (Xyla)|Micah J. Smith (Xyla)|Zachary Ziegler (Xyla)|Daniel Nadler (Xyla)|Peter Szolovits (MIT)|Alistair Johnson (The Hospital for Sick Children)|Emily Alsentzer (Brigham and Women's Hospital and Harvard Medical School)","session":"A","title":"Do We Still Need Clinical Language Models?"},{"UID":"P32","abstract":"Electrodermal activity (EDA) is a biosignal that contains valuable information for monitoring health conditions related to sympathetic nervous system activity. Analyzing ambulatory EDA data is challenging because EDA measurements tend to be noisy and sparsely labeled. To address this problem, we present the first study of contrastive learning that examines approaches that are tailored to the EDA signal. We present a novel set of data augmentations that are tailored to EDA, and use them to generate positive examples for unsupervised contrastive learning. We evaluate our proposed approach on the downstream task of stress detection. We find that it outperforms baselines when used both for fine-tuning and for transfer learning, especially in regimes of high label sparsity. We verify that our novel EDA-specific augmentations add considerable value beyond those considered in prior work through a set of ablation experiments.","authors":"Katie Matton* (MIT CSAIL and MIT Media Lab)|Robert A Lewis* (MIT Media Lab)|John Guttag (MIT CSAIL)|Rosalind Picard (MIT Media Lab)","session":"B","title":"Contrastive Learning of Electrodermal Activity Representations for Stress Detection"},{"UID":"P33","abstract":"Type 2 diabetes mellitus (T2D) affects over 530 million people globally and is often difficult to manage leading to serious health complications. Continuous glucose monitoring (CGM) can help people with T2D to monitor and manage the disease. CGM devices sample an individual's glucose level at frequent intervals enabling sophisticated characterization of an individual's health. In this work, we leverage a large dataset of CGM data (5,447 individuals and 940,663 days of data) paired with health records and activity data to investigate how glucose levels in people with T2D are affected by external factors like weather conditions, extreme weather events, and temporal events including local holidays. We find temperature (p=2.37x10<sup>-8</sup>, n=3561), holidays (p=2.23x10<sup>-46</sup>, n=4079), and weekends (p=7.64x10<sup>-124</sup>, n=5429) each have a significant effect on standard glycemic metrics at a population level. Moreover, we show that we can predict whether an individual will be significantly affected by a (potentially unobserved) external event using only demographic information and a few days of CGM and activity data. Using random forest classifiers, we can predict whether an individual will be more negatively affected than a typical individual with T2D by a given external factor with respect to a given glycemic metric. We find performance (measured as ROC-AUC) is consistently above chance (across classifiers, median ROC-AUC=0.63). Performance is highest for classifiers predicting the effect of time-in-range (median ROC-AUC=0.70). These are important findings because they may enable better patient care management with day-to-day risk assessments based on external factors as well as improve algorithm development by reducing train- and test-time bias due to external factors.","authors":"Kailas Vodrahalli* (Stanford University)|Gregory D. Lyng (Optum AI Labs)|Brian L. Hill (Optum AI Labs)|Kimmo Karkkainen (Optum AI Labs)|Jeffrey Hertzberg (Optum AI Labs)|James Zou (Stanford University)|Eran Halperin (Optum AI Labs)","session":"B","title":"Understanding and Predicting the Effect of Environmental Factors on People with Type 2 Diabetes"}],"speakers":[{"UID":"S06","abstract":"The traditional knowledge-based approaches to question answering might seem irrelevant now that Neural QA, particularly Large Language Models show almost human performance in question answering. Knowing what was successful in the past and which elements are essential to getting the right answers, however, is needed to inform further developments in the neural approaches and help address the known shortcomings of LLMs. This talk, therefore, will provide an overview of the approaches to biomedical question answering as they were evolving. It will cover information needs of various stakeholders and the resources created to address these information needs through Question Answering.","bio":"Dina Demner-Fushman, MD, PhD is a Tenure Track Investigator in the Computational Health Research Branch at LHNCBC. She specializes in artificial intelligence and natural language processing, with a focus on information extraction and textual data analysis, EMR data analysis, and image and text retrieval for clinical decision support and education. Dr. Demner-Fushman's research aims to improve healthcare through the development of computational methods that can process and analyze clinical data more effectively. Her research led to the current iteration of the MEDLINE resource, which helps people navigate a plethora of NLM resources, as well as Open-i, which helps finding biomedical images.","image":"static/images/speakers/dina_demner_fushman.jpg","institution":"National Institutes of Health","slideslive_active_date":"","slideslive_id":"","speaker":"Dina Demner-Fushman","title":"Biomedical Question Answering Yesterday, Today, and Tomorrow"},{"UID":"S02","abstract":"Artificial intelligence could fundamentally transform clinical workflows in image-based diagnostics and population screening, promising more objective, accurate and effective analysis of medical images. A major hurdle for using medical imaging AI in clinical practice, however, is the assurance whether it is safe for patients and continues to be safe after deployment. Differences in patient populations and changes in the data acquisition pose challenges to today's AI algorithms. In this talk we will discuss AI safeguards from the perspective of robustness, reliability, and fairness. We will explore approaches for automatic failure detection, monitoring of performance, and analysis of bias, aiming to ensure the safe and ethical use of medical imaging AI.","bio":"Ben Glocker is Professor in Machine Learning for Imaging and Kheiron Medical Technologies / Royal Academy of Engineering Research Chair in Safe Deployment of Medical Imaging AI. He co-leads the Biomedical Image Analysis Group, leads the HeartFlow-Imperial Research Team, and is Head of ML Research at Kheiron. His research is at the intersection of medical imaging and artificial intelligence aiming to build safe and ethical computational tools for improving image-based detection and diagnosis of disease.","image":"static/images/speakers/ben_glocker.jpg","institution":"Imperial College London","slideslive_active_date":"","slideslive_id":"","speaker":"Ben Glocker","title":"Safe Deployment of Medical Imaging AI"},{"UID":"S01","abstract":"Biological sequences, like DNA and protein sequences, encode genetic information essential to life. In recent times, deep learning techniques have transformed biomedical research and applications by modeling the intricate patterns in these sequences. Successful models like AlphaFold and Enformer have paved the way for accurate end-to-end prediction of complex molecular phenotypes from sequences. Such models have profound impact on biomedical research and applications, ranging from understanding basic biology to facilitating drug discovery. This talk will provide an overview of the current techniques and status of biological sequences modeling. Additionally, specific applications of such models in genetics and immunology will be discussed.","bio":"Jun Cheng is a Senior Research Scientist at DeepMind. His research focused on developing machine learning methods to better understand the genetic code and disease mechanisms. Before that, he was a scientist at NEC Labs Europe, where he worked on personalized cancer vaccines. His work has been published in venues such as Genome Biology, Bioinformatics, and Nature Biotechnology. He received his PhD in computational biology from the Technical University of Munich.","image":"static/images/speakers/jun_cheng.jpg","institution":"DeepMind","slideslive_active_date":"","slideslive_id":"","speaker":"Jun Cheng","title":"Biological Sequence Modeling in Research and Applications"},{"UID":"S03","abstract":"Digital traces, such as social media data, supported with advances in the artificial intelligence (AI) and machine learning (ML) fields, are increasingly being used to understand the mental health of individuals, communities, and populations. However, such algorithms do not exist in a vacuum -- there is an intertwined relationship between what an algorithm does and the world it exists in. Consequently, with algorithmic approaches offering promise to change the status quo in mental health for the first time since mid-20th century, interdisciplinary collaborations are paramount. But what are some paradigms of engagement for AL/ML researchers that augment existing algorithmic capabilities while minimizing the risk of harm? Adopting a social ecological lens, this talk will describe the experiences from working with different stakeholders in research initiatives relating to digital mental health \u2013 including with healthcare providers, grassroots advocacy and public health organizations, and people with the lived experience of mental illness. The talk hopes to present some lessons learned by way of these engagements, and to reflect on a path forward that empowers us to go beyond technical innovations to envisioning contributions that center humans\u2019 needs, expectations, values, and voices within those technical artifacts.","bio":"Munmun De Choudhury is an Associate Professor of Interactive Computing at Georgia Tech. Dr. De Choudhury is best known for laying the foundation of a new line of research that develops computational techniques towards understanding and improving mental health outcomes, through ethical analysis of social media data. To do this work, she adopts a highly interdisciplinary approach, combining social computing, machine learning, and natural language analysis with insights and theories from the social, behavioral, and health sciences. Dr. De Choudhury has been recognized with the 2023 SIGCHI Societal Impact Award, the 2022 Web Science Trust Test-of-Time Award, the 2021 ACM-W Rising Star Award, the 2019 Complex Systems Society \u2013 Junior Scientific Award, numerous best paper and honorable mention awards from the ACM and AAAI, and features and coverage in popular press like the New York Times, the NPR, and the BBC. Earlier, Dr. De Choudhury was a faculty associate with the Berkman Klein Center for Internet and Society at Harvard, a postdoc at Microsoft Research, and obtained her PhD in Computer Science from Arizona State University.","image":"static/images/speakers/munmun_de_choudhury.jpg","institution":"Georgia Tech","slideslive_active_date":"","slideslive_id":"","speaker":"Munmun De Choudhury","title":"Bridging Machine Learning and Collaborative Action Research: A Tale Engaging with Diverse Stakeholders in Digital Mental Health"},{"UID":"S05","abstract":"TBD","bio":"Dina Katabi is the Thuan and Nicole Pham Professor of Electrical Engineering and Computer Science at MIT. She is also the director of the MIT\u2019s Center for Wireless Networks and Mobile Computing, a member of the National Academy of Engineering, and a recipient of the MacArthur Genius Award. Professor Katabi received her PhD and MS from MIT in 2003 and 1999, and her Bachelor of Science from Damascus University in 1995. Katabi's research focuses on innovations in digital health, applied machine learning and wireless sensors and networks. Her research has been recognized with ACM Prize in Computing, the ACM Grace Murray Hopper Award, two SIGCOMM Test-of-Time Awards, the Faculty Research Innovation Fellowship, a Sloan Fellowship, the NBX Career Development chair, and the NSF CAREER award. Her students received the ACM Best Doctoral Dissertation Award in Computer Science and Engineering twice. Further, her work was recognized by the IEEE William R. Bennett prize, three ACM SIGCOMM Best Paper awards, an NSDI Best Paper award and a TR10 award. Several start-ups have beenspun out of Katabi's lab such as PiCharging and Emerald.","image":"static/images/speakers/dina_katabi.jpg","institution":"MIT","slideslive_active_date":"","slideslive_id":"","speaker":"Dina Katabi","title":"A Healthcare Platform Powered by ML and Radio Waves"},{"UID":"S07","abstract":"Artificial intelligence tools have been touted as having performance \"on par\" with board certified dermatologists. However, these published claims have not translated to real world practice. In this talk, I will discuss the opportunities and challenges for AI in dermatology.","bio":"Dr. Roxana Daneshjou received her undergraduate degree at Rice University in Bioengineering, where she was recognized as a Goldwater Scholar for her research. She completed her MD/PhD at Stanford, where she worked in the lab of Dr. Russ Altman. During this time, she was a Howard Hughes Medical Institute Medical Scholar and a Paul and Daisy Soros Fellowship for New Americans Fellow.  She completed dermatology residency at Stanford in the research track and now practices dermatology as a Clinical Scholar in Stanford's Department of Dermatology while also conducting artificial intelligence research with Dr. James Zou as a postdoc in Biomedical Data Science. She is an incoming assistant professor of biomedical data science and dermatology at Stanford in Fall of 2023. Her research interests are in developing diverse datasets and fair algorithms for applications in precision medicine.","image":"static/images/speakers/roxana_daneshjou.jpg","institution":"Stanford University","slideslive_active_date":"","slideslive_id":"","speaker":"Roxana Daneshjou","title":"Skin in the Game: The State of AI in Dermatology"},{"UID":"S04","abstract":"Our society remains profoundly unequal. This talk discusses how data science and machine learning can be used to combat inequality in health care and public health by presenting several vignettes from domains like medical testing and cancer risk prediction.","bio":"Emma Pierson is an assistant professor of computer science at the Jacobs Technion-Cornell Institute at Cornell Tech and the Technion, and a computer science field member at Cornell University. She holds a secondary joint appointment as an Assistant Professor of Population Health Sciences at Weill Cornell Medical College. She develops data science and machine learning methods to study inequality and healthcare. Her work has been recognized by best paper, poster, and talk awards, an NSF CAREER award, a Rhodes Scholarship, Hertz Fellowship, Rising Star in EECS, MIT Technology Review 35 Innovators Under 35, and Forbes 30 Under 30 in Science. Her research has been published at venues including ICML, KDD, WWW, Nature, and Nature Medicine, and she has also written for The New York Times, FiveThirtyEight, Wired, and various other publications.","image":"static/images/speakers/emma_pierson.jpeg","institution":"Cornell Tech","slideslive_active_date":"","slideslive_id":"","speaker":"Emma Pierson","title":"Using Machine Learning to Increase Equity in Healthcare and Public Health"}]},"has_data":true,"has_summary":{"2020":true,"2021":true,"2022":true,"2023":true},"years_list":["2020","2021","2022","2023"]}
